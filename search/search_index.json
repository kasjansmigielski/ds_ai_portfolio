{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home Page","text":"Projects from the world of data, Python programming and AI technologies"},{"location":"#introduction","title":"Introduction","text":"Welcome to my website dedicated to projects in the field of data analysis, machine learning and artificial intelligence."},{"location":"#my-short-story","title":"My short story","text":"In 2019, I graduated with a degree in Mechatronics from Wroc\u0142aw University of Science and Technology, sparking my desire to explore new technologies. Over the past five years, I worked as an engineer in the manufacturing industry, where data played a crucial role in my work. By analyzing production and quality data, I was able to optimize processes and find innovative solutions to enhance productivity and efficiency.   Since the year, I have been developing a strong interest in AI, which has led me to complete a Data Scientist course and start building my portfolio. I have developed several practical projects and have more ideas that I aim to turn into commercial products.  I have also secured my dream job in a Data Science department, where I will be working on projects related to Machine Learning and Deep Learning."},{"location":"#my-current-activity","title":"My current activity","text":"Due to my growing passion for AI and Data Science, I began my master's studies in March 2025 in Artificial Intelligence and Machine Learning. I am deeply committed to advancing my academic career. My master's thesis will focus on utilizing computer vision algorithms in a project collaborating with the Medical University of Wroc\u0142aw. This project will involve detecting larvae and analyzing their behaviors under experimental conditions. Additionally, since January 2025, I have been a Student Success Manager at Gotoit, where I have the opportunity to mentor a Data Science course. I conduct weekly live sessions where we expand our knowledge in data and AI. I am also experimenting with creating tutorials on Python, SQL, and other libraries useful in the Data Science field.  I am also preparing for the AWS ML Associate exam, which will allow me to expand my knowledge of cloud services and become a specialist in the Machine Learning field."},{"location":"#about-portfolio","title":"About portfolio","text":"Here you will find many projects I have been working on recently: from domain exploration (EDA) on ready-made datasets, through creating Streamlit applications - allowing you to browse data in a simple way, and ending with AI-powered and Machine Learning-based applications - to find patterns invisible at first glance.  I invite you to familiarize yourself with the projects and I hope that everyone will find something for themselves. I encourage you to visit here regularly - I intend to expand my portfolio with new ideas on an ongoing basis."},{"location":"audio_notes/","title":"Audio Notes App","text":"<p>Date of creation: 2024-10-03</p>"},{"location":"audio_notes/#project-description","title":"Project description","text":"The goal of the project was to create the first AI-powered application. To do this, I used two LLM models from OpenAI: <code>whisper-1</code> (speech -&gt; text) and <code>text-embeddings-3-large</code> (text -&gt; embeddings)."},{"location":"audio_notes/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Recording and listening to voice notes</li> <li>Transcription of voices into text using AI</li> <li>Ability to collect notes in the QDrant database</li> <li>Semantic data search using the text processing algorithm on embeddings and finding similarities based on Cosinus Similarity</li> </ul>"},{"location":"audio_notes/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>QDrant</li> <li>OpenAI embeddings</li> <li>OpenAI whisper-1</li> <li>Streamlit</li> <li>Dotenv</li> <li>PyDub</li> <li>io</li> <li>md5</li> </ul>"},{"location":"audio_notes/#sample-photos","title":"Sample photos","text":""},{"location":"audio_notes/#application-usage","title":"Application usage","text":"The application has been deployed on the Streamlit Community App helps me generate notes more easily and most importantly enables contextual search using AI. <p>Link to repository</p>"},{"location":"cv_generator/","title":"CV Generator","text":"<p>Date of creation: 2024-11-06</p>"},{"location":"cv_generator/#project-description","title":"Project description","text":"The goal of this project was to create a CV generator that is easily editable and will allow you to generate information specific to a given company and offer. Using AI will allow you to best match your skills to the position you are applying for. This is to streamline the process of finding your dream job as a Data Scientist."},{"location":"cv_generator/#main-functionalities","title":"Main functionalities","text":"<ul> <li>the user enters information about themselves, the company and directly from the job offer</li> <li>additionally provides the most important skills (programming languages, databases or libraries learned)</li> <li>on this basis an intro is generated, which matches the skills to the individual job offer</li> <li>user can edit AI generated intro</li> <li>then the user can preview the CV content in the application (in Markdown format)</li> <li>finally the user has the option to name and download the CV in PDF format</li> </ul>"},{"location":"cv_generator/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Streamlit</li> <li>HTLM</li> <li>PDFkit</li> <li>Markdown</li> <li>Template</li> </ul>"},{"location":"cv_generator/#sample-photos","title":"Sample photos","text":""},{"location":"fashion_designer/","title":"Fashion Designer","text":"<p>Date of creation: 2024-12-15</p>"},{"location":"fashion_designer/#project-description","title":"Project description","text":"The aim of this project was to create an imitation of a fashion designer. The idea for the project came to me because of the needs of my life partner, who designs women's underwear. This application is to automate the design process and will additionally be an inspiration to create new elements from the world of fashion."},{"location":"fashion_designer/#project-architecture","title":"Project architecture","text":""},{"location":"fashion_designer/#main-functionalities","title":"Main functionalities","text":"<ul> <li>the user selects what type of underwear they want to design</li> <li>the user specifies the initial design concept - then receives visual inspiration generated by AI</li> <li>the user provides the appropriate dimensions</li> <li>the application - using appropriate construction formulas, calculates and saves the parameters related to a specific type of underwear</li> <li>then a construction drawing is created based on the parameters calculated in the previous step, which is then displayed in the application</li> <li>the drawing is properly prepared for printing</li> <li>the user has the option to download the drawing (whole or divided into parts for printing)</li> <li>finally, the AI \u200b\u200bmodel generates recommendations related to the process of creating the element designed by the user</li> </ul>"},{"location":"fashion_designer/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Streamlit</li> <li>Matplotlib</li> <li>PIL</li> <li>Zipfile</li> <li>Requests</li> </ul>"},{"location":"fashion_designer/#sample-photos","title":"Sample photos","text":""},{"location":"features_detective/","title":"Features Detective App","text":"<p>Date of creation: 2024-10-30</p>"},{"location":"features_detective/#project-description","title":"Project description","text":"The aim of the project was to create a universal application that allows for detecting the most important features in a given data set. In short - the user uploads data or loads a ready data set in the appropriate format, then selects automatic detection of the column they want to analyze or makes this selection themselves. Finally, they receive a generated graph of the significance of features that have the greatest impact on the previously selected column. The user also receives a clear description of the graph along with recommendations - what can be improved to, for example, improve the analyzed data."},{"location":"features_detective/#main-functionalities","title":"Main functionalities","text":"<ul> <li>The user can load a CSV/JSON file with data or use a ready-made sample dataset</li> <li>The user indicates the target column -&gt; additionally, they can use automatic column detection (generated by LLM)</li> <li>The application automatically recognizes whether the loaded data is related to the regression or classification problem and selects the appropriate AI model training algorithm on this basis</li> <li>Based on the trained model, a chart containing the most important features is displayed</li> <li>Finally, the user receives a clear description of the chart along with recommendations - what actions to implement to improve the results related to the analyzed target data column</li> </ul>"},{"location":"features_detective/#ml-model-training","title":"ML model training","text":"I used PyCaret tools and I have included the implementation in a notebook ready for download: Download Notebook: Model training"},{"location":"features_detective/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> <li>PyCaret (Classification &amp; Regression)</li> <li>Pandas</li> <li>Matplotlib</li> <li>Instructor</li> <li>Pydantic</li> <li>Boto3</li> </ul>"},{"location":"features_detective/#sample-photos","title":"Sample photos","text":""},{"location":"features_detective/#application-testing","title":"Application testing","text":"The application has been deployed on the Streamlit Community App and is available for public use. To use the application you need your OpenAI API Key. <p>Link to repository Go to application</p>"},{"location":"find_friends/","title":"Find Friends App","text":"<p>Data of creation: 2024-10-09</p>"},{"location":"find_friends/#project-description","title":"Project description","text":"The aim of the project was to create an application that would enable the use of a clustering model to match a user to the appropriate group from a loaded data set (data comes from an anonymized survey) - based on data provided by the user."},{"location":"find_friends/#main-functionalities","title":"Main functionalities","text":"<ul> <li>The user filters basic data, such as: age, education, gender, favorite animals, or favorite places - corresponding to their preferences</li> <li>Then the previously trained clustering model creates the appropriate number of clusters for the survey data and matches the user's preferences to the matching group</li> <li>Finally, using LLM, adequate cluster descriptions are generated</li> </ul>"},{"location":"find_friends/#ml-model-training","title":"ML model training","text":"I used Scikit-learn tools and I have included the implementation in a notebook ready for download: Download Notebook: Model training"},{"location":"find_friends/#clusters-naming","title":"Clusters naming","text":"I used the LLM model and I have included the implementation in a notebook ready for dowlonad: Download Notebook: Clusters naming"},{"location":"find_friends/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> <li>Scikit-learn</li> <li>Plotly</li> <li>PyCaret (Clustering)</li> <li>NumPy</li> <li>Matplotlib</li> </ul>"},{"location":"find_friends/#sample-photos","title":"Sample photos","text":""},{"location":"find_friends/#application-testing","title":"Application testing","text":"The application has been deployed on the Streamlit Community App and is available for public use. <p>Link to repository Go to application</p>"},{"location":"halfmarathon_estimator/","title":"Halfmarathon Estimator App","text":"<p>Date of creation: 2024-10-20</p>"},{"location":"halfmarathon_estimator/#project-description","title":"Project description","text":"The aim of the project was to create an application that would use a regression algorithm to train models and would be able to predict (based on previously trained data) the time in which a user would run a half marathon - by providing specific data."},{"location":"halfmarathon_estimator/#main-functionalities","title":"Main functionalities","text":"<ul> <li>allowing the user to enter data freely (without any appropriate conversion of the record) -&gt; the LLM model used extracts data from the user into a JSON structure and prepares it for use by the regression model</li> <li>simple functionality allows for the final estimation of the time to run a half marathon - using the trained best regression model</li> <li>the LLM model is connected to Langfuse to track the model's life cycle</li> </ul>"},{"location":"halfmarathon_estimator/#ml-model-training","title":"ML model training","text":"I used PyCaret tools and I have included the implementation in a notebook ready for download: Download Notebook: Model training"},{"location":"halfmarathon_estimator/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>PyCaret</li> <li>Machine Learning</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> <li>Pandas</li> <li>Instructor</li> <li>Pydantic</li> <li>Dotenv</li> </ul>"},{"location":"halfmarathon_estimator/#sample-photos","title":"Sample photos","text":""},{"location":"halfmarathon_estimator/#application-testing","title":"Application testing","text":"The application has been deployed on the Streamlit Community App and is available for public use. To use the application you need your OpenAI API Key. <p>Link to repository Go to application</p>"},{"location":"iris/","title":"Domain exploration (EDA) of the dataset: Irises","text":"<p>Date of creation: 2024-08-25</p>"},{"location":"iris/#introduction","title":"Introduction","text":"I invite you to familiarize yourself with my project, which takes us into the world of data analysis on Irises - using domain exploration (EDA). In this project, you will find many pertinent conclusions and interesting observations that shed new light on these beautiful flowers. Prepare yourself for a fascinating journey through data, which will certainly enrich your knowledge and inspire you to further research."},{"location":"iris/#project-download","title":"Project download","text":"Download Notebook"},{"location":"justjoinit_browser/","title":"JustJoinIT Browser","text":"<p>Project start: 2025-02-19</p>"},{"location":"justjoinit_browser/#project-description","title":"Project description","text":"JustJoinIT Browser is a Streamlit application designed for interactive browsing of the latest job offers from the JustJoinIT platform. The project involved using the Requests library to scrape job listings data, followed by exploratory data analysis (EDA) to understand the domain and categories available on JustJoinIT. The data was then processed into a suitable CSV format, which served as the foundation for building a user-friendly interface. The application leverages Geopandas to implement an interactive map of Polish voivodeships, enabling intuitive geolocation-based filtering of job opportunities. In the future the application will be developed with AI algorithms."},{"location":"justjoinit_browser/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Custom browsing of IT job offers with flexible interface customization</li> <li>Interactive map visualization for geographical filtering by regions</li> <li>Multiple filtering options based on technology, experience level, and job type</li> <li>Data visualization with charts and statistics to better understand the job market</li> <li>User-defined sorting and prioritization of job listings</li> </ul>"},{"location":"justjoinit_browser/#eda","title":"EDA","text":"I conducted a detailed exploratory data analysis (EDA) using Pandas for data analysis, as well as Plotly, Matplotlib, and Seaborn for data visualization. Below you can find files available for download containing the full analysis and the dataset: Download Notebook: Exploratory Analysis Download CSV: Job Offers"},{"location":"justjoinit_browser/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Requests</li> <li>Pandas</li> <li>Geopandas</li> <li>Shapely</li> <li>Folium</li> <li>Streamlit</li> <li>Plotly</li> <li>Pathlib</li> <li>EDA</li> </ul>"},{"location":"justjoinit_browser/#sample-photos","title":"Sample photos","text":""},{"location":"my_chatbot/","title":"My Chatbot App","text":"<p>Date of creation: 2024-09-15</p>"},{"location":"my_chatbot/#project-description","title":"Project description","text":"The aim of the project was to create own version of Chat GPT, based on the Streamlit application interface. The chatbot can take on any personality to maximize its functionality to our preferences."},{"location":"my_chatbot/#main-functionalities","title":"Main functionalities","text":"<ul> <li>the chatbot remembers conversations and saves them in a JSON file structure, and you can easily switch between conversations (without losing your chat history)</li> <li>you can choose between various models from OpenAI</li> <li>the costs of using AI are counted</li> <li>you can give the chatbot individual awareness that will guide the types of answers to the questions asked</li> </ul>"},{"location":"my_chatbot/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> </ul>"},{"location":"my_chatbot/#sample-photos","title":"Sample photos","text":""},{"location":"my_chatbot/#application-usage","title":"Application usage","text":"The application has been deployed on the Streamlit Community App helps me explore the secrets of AI and expand my programming skills on a daily basis."},{"location":"student_profiler/","title":"Student Profiler","text":"<p>Project start: 2025-03-01</p>"},{"location":"student_profiler/#project-description","title":"Project description","text":"Student Profiler is a specialized tool developed for Gotoit company to track student progress during courses. The core of the system is a Discord Bot that interacts with the Discord server to collect historical data, listen for new messages, and generate automated responses. The application streamlines the monitoring process by automatically gathering and analyzing student activity data, with the ultimate goal of creating a highly humanized mentor bot experience."},{"location":"student_profiler/#architecture-logic","title":"Architecture logic","text":""},{"location":"student_profiler/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Discord Bot integration for monitoring activity and automated messaging</li> <li>Scheduled hourly data collection from Discord channels</li> <li>Data storage system using PostgreSQL for messages and Digital Ocean Spaces for attachments</li> <li>Streamlit-based UI for easy access and analysis of Discord data</li> <li>Scalable architecture with future implementation plans for AI features (OCR, sentiment analysis, predictive models)</li> </ul>"},{"location":"student_profiler/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Requests</li> <li>Pandas</li> <li>Discord API</li> <li>Schedule</li> <li>Psycopg</li> <li>Streamlit</li> <li>Plotly</li> <li>Pydantic-settings</li> <li>SRP design</li> </ul>"},{"location":"student_profiler/#sample-photos","title":"Sample photos","text":""},{"location":"titanic/","title":"Domain exploration (EDA) of the dataset: Titanic","text":"<p>Date of creation: 2024-08-25</p>"},{"location":"titanic/#introduction","title":"Introduction","text":"I invite you to familiarize yourself with my project, which takes us into the world of data analysis regarding the world-famous Titanic disaster. In order to explore the information, I use domain exploration (EDA). In this project, you will find many relevant conclusions and interesting observations. Prepare yourself for an interesting journey with data that will broaden your horizons of looking at one of the greatest maritime disasters in history."},{"location":"titanic/#project-download","title":"Project download","text":"Download Notebook"},{"location":"welcome_survey/","title":"Welcome Survey App","text":"<p>Date of creation: 2024-09-22</p>"},{"location":"welcome_survey/#project-description","title":"Project description","text":"The aim of the project was to create an application that would allow for simple filtering and browsing of data from a sample welcome survey (the data was appropriately anonymized). The aim of the application was to consolidate components from the Streamlit library and familiarize users with the proper management of the application state (<code>st.session_state</code>) so that all buttons and interactions were responsive to each other."},{"location":"welcome_survey/#main-functionalities","title":"Main functionalities","text":"<ul> <li>the ability to browse an anonymous survey to familiarize yourself with the Streamlit interface</li> <li>various types of filters allow you to get to know the analyzed data in more detail</li> <li>visualizations are also included</li> <li>the application also contains interesting visualizations and for the most persistent - curiosities await!</li> </ul>"},{"location":"welcome_survey/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Pandas</li> <li>Matplotlib</li> <li>Seaborn</li> <li>Streamlit</li> <li>Boto3</li> </ul>"},{"location":"welcome_survey/#sample-photos","title":"Sample photos","text":""}]}