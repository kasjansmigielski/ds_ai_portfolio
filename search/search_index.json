{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"Kasjan \u015amigielski AI Engineer | Data Scientist | ML Engineer"},{"location":"#about-me","title":"About Me","text":"I am an AI Engineer and Data Scientist specializing in designing intelligent data-driven systems \u2014 from data analysis and EDA, through Machine Learning and Computer Vision models, to production-grade LLM architectures and RAG systems.  I combine engineering experience from industry with modern AI technologies, building solutions that:  - solve real business and research problems, - are scalable and production-ready, - connect AI with solid software engineering."},{"location":"#my-professional-journey","title":"My Professional Journey","text":"In 2019, I graduated with a degree in Mechatronics from Wroc\u0142aw University of Science and Technology. Over the following years, I worked as an engineer in the manufacturing industry, where quality and process data played a crucial role in optimizing processes and decision-making.  Working with real industrial data:  - sparked my interest in data analysis, - taught me systems thinking, - showed me the importance of data quality and business context.  The natural step was to transition towards Data Science and AI."},{"location":"#current-focus","title":"Current Focus","text":"I completed the Data Scientist track and started systematically building a portfolio of projects covering:  - exploratory data analysis (EDA), - analytical applications in Streamlit, - Machine Learning and Deep Learning systems, - solutions based on LLMs and semantic search.  I currently work on projects in:  - **Machine Learning and Deep Learning** - **Computer Vision** - **LLM integration and RAG** - **AI in production environments**  I hold the AWS Machine Learning Engineer \u2013 Associate certification, confirming my competencies in designing and deploying ML solutions in the cloud."},{"location":"#teaching-mentoring","title":"\ud83c\udf93 Teaching &amp; Mentoring","text":"Since January 2025, I have been a Student Success Manager at Gotoit, where I mentor a Data Science course. I conduct weekly live sessions where we expand knowledge in data and AI.  Additionally, I teach and conduct workshops for:  - **Data Science course participants** \u2014 Python, SQL, EDA, Machine Learning, Deep Learning - **High school students** (IT profile) \u2014 practical AI applications - **Teachers and pedagogical staff** \u2014 responsible and practical use of AI  My teaching philosophy focuses on understanding, not memorization, real cases instead of artificial datasets, and critical thinking about AI rather than hype."},{"location":"#academic-activity","title":"\ud83d\udcda Academic Activity","text":"In March 2025, I started master's studies in Artificial Intelligence and Machine Learning.  My master's thesis focuses on:  - applying computer vision, - analyzing object behaviors in video material, - using ML and DL algorithms in biomedical research.  The project is carried out in collaboration with the Medical University of Wroc\u0142aw."},{"location":"#about-this-portfolio","title":"About This Portfolio","text":"Here you will find many projects I have been working on recently: from domain exploration (EDA) on ready-made datasets, through creating Streamlit applications allowing you to browse data in a simple way, and ending with AI-powered and Machine Learning-based applications to find patterns invisible at first glance.  I encourage you to visit here regularly \u2014 I intend to expand my portfolio with new ideas on an ongoing basis."},{"location":"ainnouncer_studio/","title":"AInnouncer Studio","text":"<p>Project start: October 2024 \u2014 Present</p> <p>Role: Tech Lead / AI Engineer</p>"},{"location":"ainnouncer_studio/#project-description","title":"Project description","text":"AInnouncer Studio is a comprehensive AI platform for automatic audio content generation for radio stations, built on a professional LLMs and LLOps architecture.  Radio stations need regular, professional audio content: weather forecasts, music announcements, on-air messages, or advertising materials. This process is time-consuming, expensive, difficult to scale, and heavily dependent on people.  The system combines:  - text generation (LLM), - voice synthesis (TTS), - audio mixing (broadcast-ready), - automation, - monitoring and quality control.  The platform was designed as a scalable SaaS, ready for multiple clients and additional modules."},{"location":"ainnouncer_studio/#architecture-overview","title":"Architecture Overview","text":"AInnouncer Studio is an event-driven + worker-based architecture:  - **Frontend (Next.js)** \u2014 configuration of modules, prompts, voices, schedules - **Backend API (FastAPI)** \u2014 domain logic, routing, validation, orchestration - **Asynchronous workers (Dramatiq + Redis)** \u2014 content generation, TTS, mixing, upload - **LLM Layer** \u2014 OpenAI GPT-4o / GPT-4o-mini with advanced system prompts - **LLOps &amp; Observability** \u2014 Langfuse (traces, spans, cost, quality), prompt versioning, Promptfoo (prompt testing) - **Data Layer** \u2014 PostgreSQL (configurations, prompts, voices, schedules), S3-compatible storage (audio) - **Infrastructure** \u2014 Docker Compose, CI/CD, Monitoring (Prometheus + Grafana)"},{"location":"ainnouncer_studio/#key-modules","title":"Key Modules","text":""},{"location":"ainnouncer_studio/#weather-forecast-production","title":"Weather Forecast (Production)","text":"<ul> <li>weather data \u2192 LLM text \u2192 TTS voice \u2192 jingle mix \u2192 upload</li> <li>support for multiple locations and languages</li> <li>broadcast schedules</li> </ul>"},{"location":"ainnouncer_studio/#ainnouncer-dj-music-announcer","title":"AInnouncer (DJ / Music Announcer)","text":"<ul> <li>playlist parsing (.mix)</li> <li>batch text generation</li> <li>announcement frequency control</li> <li>audio ready for broadcast automation</li> </ul>"},{"location":"ainnouncer_studio/#platform-core-llops","title":"Platform Core (LLOps)","text":"<ul> <li>prompt versioning</li> <li>response quality monitoring</li> <li>LLM cost analysis</li> <li>retry &amp; fallback logic</li> <li>preparation for AI agents</li> </ul>"},{"location":"ainnouncer_studio/#what-i-did","title":"What I did","text":"<ol> <li>Designed the complete AI system architecture in production</li> <li>Built the backend in FastAPI with separation of concerns</li> <li>Implemented asynchronous pipelines (Dramatiq)</li> <li>Created the LLM layer with prompt control and validation</li> <li>Integrated Langfuse for LLM observability and monitoring</li> <li>Deployed Promptfoo for prompt testing</li> <li>Built TTS and audio mixing system to radio standards</li> <li>Designed CI/CD and cloud environment</li> <li>Prepared the platform for further AI agent development</li> </ol>"},{"location":"ainnouncer_studio/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>FastAPI</li> <li>OpenAI GPT-4o</li> <li>ElevenLabs TTS</li> <li>Langfuse</li> <li>Promptfoo</li> <li>PostgreSQL</li> <li>Redis</li> <li>Dramatiq</li> <li>Docker</li> <li>DigitalOcean</li> <li>Next.js</li> <li>TypeScript</li> <li>Prometheus</li> <li>Grafana</li> </ul>"},{"location":"ainnouncer_studio/#results","title":"Results","text":"<ul> <li>Fully automatic generation of broadcast-ready audio content</li> <li>Stable, production AI architecture (not a demo)</li> <li>Full control over LLM quality and costs</li> <li>System ready to scale as a SaaS product</li> <li>Solid foundation for:</li> <li>AI agents</li> <li>additional modules (ads, traffic, voice branding)</li> <li>international expansion</li> </ul>"},{"location":"ainnouncer_studio/#sample-photos","title":"Sample photos","text":""},{"location":"audio_notes/","title":"Audio Notes App","text":"<p>Date of creation: 2024-10-03</p>"},{"location":"audio_notes/#project-description","title":"Project description","text":"The goal of the project was to create the first AI-powered application. To do this, I used two LLM models from OpenAI: <code>whisper-1</code> (speech -&gt; text) and <code>text-embeddings-3-large</code> (text -&gt; embeddings)."},{"location":"audio_notes/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Recording and listening to voice notes</li> <li>Transcription of voices into text using AI</li> <li>Ability to collect notes in the QDrant database</li> <li>Semantic data search using the text processing algorithm on embeddings and finding similarities based on Cosinus Similarity</li> </ul>"},{"location":"audio_notes/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>QDrant</li> <li>OpenAI embeddings</li> <li>OpenAI whisper-1</li> <li>Streamlit</li> <li>Dotenv</li> <li>PyDub</li> <li>io</li> <li>md5</li> </ul>"},{"location":"audio_notes/#sample-photos","title":"Sample photos","text":""},{"location":"audio_notes/#application-usage","title":"Application usage","text":"The application has been deployed on the Streamlit Community App helps me generate notes more easily and most importantly enables contextual search using AI. <p>Link to repository</p>"},{"location":"b_roll_assistant/","title":"B-Roll Assistant","text":"<p>Project start: October 2024 \u2014 Present</p> <p>Role: AI / Backend Engineer</p>"},{"location":"b_roll_assistant/#project-description","title":"Project description","text":"B-Roll Assistant is an intelligent AI assistant that automatically catalogs video materials and enables their instant search.  In newsrooms and video production environments, time is critical. Editors and video editors must quickly find the right B-roll, often under deadline pressure. In practice:  - video materials are poorly described or not at all, - file names are ambiguous, - manual tagging is costly and unrealistic, - classic folder-based search doesn't scale.  The system:  - analyzes video without user intervention, - generates snapshots and shot descriptions using AI, - combines classic search with semantic search, - learns from editor ratings.  Thanks to this, the editor doesn't need to know *how the file was named* \u2014 just describe what they're looking for."},{"location":"b_roll_assistant/#how-it-works","title":"How It Works","text":""},{"location":"b_roll_assistant/#1-smart-catalog-setup","title":"1. Smart Catalog Setup","text":"<ul> <li>System adapts to existing file structure</li> <li>No manual organization required</li> <li>Handles large B-roll archives</li> </ul>"},{"location":"b_roll_assistant/#2-ai-shot-descriptions","title":"2. AI Shot Descriptions","text":"<ul> <li>Automatic snapshot generation (FFmpeg)</li> <li>Visual shot analysis (AI Vision)</li> <li>Text descriptions for each clip: objects, scenes, context, atmosphere</li> <li>Each clip receives a rich semantic description without manual tagging</li> </ul>"},{"location":"b_roll_assistant/#3-dual-search-continuous-learning","title":"3. Dual Search &amp; Continuous Learning","text":"<ul> <li>Keyword search (fast, precise queries)</li> <li>Semantic search (search by meaning and concepts)</li> </ul> <p>Example queries: - \"glass\" - \"transparent container\" - \"tense political rally\" - \"crowd waiting nervously\"</p> <p>The system enables rating results, which: - improves accuracy, - adjusts ranking, - increases search effectiveness over time.</p>"},{"location":"b_roll_assistant/#architecture-overview","title":"Architecture Overview","text":"B-Roll Assistant is a multimodal pipeline:  - **Video ingestion** \u2014 file structure analysis, frame extraction - **AI processing** \u2014 vision \u2192 image description, text \u2192 embeddings - **Search layer** \u2014 classic indexes, vector database - **Feedback loop** \u2014 user ratings, result ranking correction  Designed for performance and scaling in media environments."},{"location":"b_roll_assistant/#what-i-did","title":"What I did","text":"<ol> <li>Designed the B-roll analysis system architecture</li> <li>Implemented video frame extraction pipeline</li> <li>Integrated AI Vision for shot analysis</li> <li>Created automatic clip description system</li> <li>Built dual search engine (keyword + semantic)</li> <li>Deployed embedding-based search</li> <li>Designed user feedback mechanism</li> <li>Prepared backend API and data structure</li> <li>Containerized the system (Docker)</li> </ol>"},{"location":"b_roll_assistant/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenAI (Vision + LLM)</li> <li>Embeddings</li> <li>Vector Database</li> <li>FastAPI</li> <li>PostgreSQL</li> <li>FFmpeg</li> <li>Docker</li> <li>Semantic Search</li> </ul>"},{"location":"b_roll_assistant/#results","title":"Results","text":"<ul> <li>Find the right B-roll in seconds instead of minutes</li> <li>No need for manual tagging</li> <li>Better utilization of existing video archives</li> <li>System that learns along with the editorial team</li> <li>Solid foundation for: newsrooms, media houses, content platforms</li> </ul>"},{"location":"b_roll_assistant/#sample-photos","title":"Sample photos","text":""},{"location":"bitcoin_prediction/","title":"Bitcoin Price Prediction","text":"<p>Project start: 2025-02-04</p>"},{"location":"bitcoin_prediction/#project-description","title":"Project description","text":"This project focuses on developing a predictive model for Bitcoin price movements using deep learning techniques. The approach integrates comprehensive Exploratory Data Analysis (EDA) with advanced time series forecasting methods, specifically Long Short-Term Memory (LSTM) neural networks. By leveraging historical Bitcoin pricing data (from Kaggle), technical indicators, and market sentiment metrics, the model aims to forecast future price trends with meaningful accuracy. The implementation utilizes TensorFlow and Keras frameworks to build, train, and evaluate the LSTM architecture, which is particularly suited for capturing temporal dependencies in financial time series data. This project demonstrates the application of deep learning to cryptocurrency market analysis and provides insights into the factors influencing Bitcoin price volatility."},{"location":"bitcoin_prediction/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Comprehensive Exploratory Data Analysis (EDA) of historical Bitcoin price data and related market metrics</li> <li>Data preprocessing including normalization techniques to optimize model performance</li> <li>Implementation of feature engineering to extract meaningful predictors from raw market data</li> <li>Development of LSTM (Long Short-Term Memory) neural network architecture for time series forecasting</li> <li>Integration of TensorFlow and Keras frameworks for model building, training, and evaluation</li> <li>Hyperparameter tuning to optimize model accuracy and generalization capabilities</li> <li>Visualization of predicted vs. actual price movements to assess model performance</li> <li>Analysis of prediction errors to identify market conditions affecting forecast accuracy</li> </ul>"},{"location":"bitcoin_prediction/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Pandas</li> <li>EDA</li> <li>Numpy</li> <li>Sklearn</li> <li>Tensorflow</li> <li>Keras</li> <li>LSTM</li> <li>Matplotlib</li> <li>LaTeX</li> </ul>"},{"location":"bitcoin_prediction/#project-report","title":"Project Report","text":"<p>You can download and review the complete project report with detailed methodology and results here: Bitcoin Price Prediction Report</p>"},{"location":"bitcoin_prediction/#sample-photos","title":"Sample photos","text":""},{"location":"cifar10_classification/","title":"CIFAR-10 Image Classification","text":"<p>Project start: 2025-02-07</p>"},{"location":"cifar10_classification/#project-description","title":"Project description","text":"This project implements an advanced Convolutional Neural Network (CNN) architecture for image classification using the CIFAR-10 dataset. The research focuses on developing and optimizing a deep learning model capable of accurately classifying images across 10 different categories. Through systematic experimentation with various network architectures, data augmentation techniques, and hyperparameter optimization, the project demonstrates how to build a robust Computer Vision system. The implementation leverages TensorFlow and Keras frameworks, applying best practices in CNN design including convolutional layers, pooling operations, batch normalization, and dropout regularization. The project highlights the importance of cross-validation strategies and model evaluation metrics to create a generalizable classification model with high accuracy on unseen data."},{"location":"cifar10_classification/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Implementation of custom CNN architectures for image classification tasks</li> <li>Application of data augmentation techniques to enhance model robustness and prevent overfitting</li> <li>Hyperparameter optimization using RandomSearch to identify optimal model configurations</li> <li>Implementation of K-Fold cross-validation to ensure reliable model evaluation</li> <li>Utilization of early stopping and learning rate scheduling to improve training efficiency</li> <li>Comprehensive model evaluation using confusion matrices, precision, recall, and F1-score</li> <li>Visualization of model performance, feature maps, and classification results</li> <li>Comparative analysis of different model architectures and their performance metrics</li> </ul>"},{"location":"cifar10_classification/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Tensorflow</li> <li>Keras</li> <li>Augmentation</li> <li>CNN</li> <li>RandomSearch</li> <li>Sklearn</li> <li>Numpy</li> <li>KFold</li> <li>LaTeX</li> </ul>"},{"location":"cifar10_classification/#project-report","title":"Project Report","text":"<p>You can download and review the complete project report with detailed methodology and results here: CIFAR-10 Image Classification Report</p>"},{"location":"cifar10_classification/#sample-photos","title":"Sample photos","text":""},{"location":"cv_generator/","title":"CV Generator","text":"<p>Date of creation: 2024-11-06</p>"},{"location":"cv_generator/#project-description","title":"Project description","text":"The goal of this project was to create a CV generator that is easily editable and will allow you to generate information specific to a given company and offer. Using AI will allow you to best match your skills to the position you are applying for. This is to streamline the process of finding your dream job as a Data Scientist."},{"location":"cv_generator/#main-functionalities","title":"Main functionalities","text":"<ul> <li>the user enters information about themselves, the company and directly from the job offer</li> <li>additionally provides the most important skills (programming languages, databases or libraries learned)</li> <li>on this basis an intro is generated, which matches the skills to the individual job offer</li> <li>user can edit AI generated intro</li> <li>then the user can preview the CV content in the application (in Markdown format)</li> <li>finally the user has the option to name and download the CV in PDF format</li> </ul>"},{"location":"cv_generator/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Streamlit</li> <li>HTLM</li> <li>PDFkit</li> <li>Markdown</li> <li>Template</li> </ul>"},{"location":"cv_generator/#sample-photos","title":"Sample photos","text":""},{"location":"fashion_designer/","title":"Fashion Designer","text":"<p>Date of creation: 2024-12-15</p>"},{"location":"fashion_designer/#project-description","title":"Project description","text":"The aim of this project was to create an imitation of a fashion designer. The idea for the project came to me because of the needs of my life partner, who designs women's underwear. This application is to automate the design process and will additionally be an inspiration to create new elements from the world of fashion."},{"location":"fashion_designer/#project-architecture","title":"Project architecture","text":""},{"location":"fashion_designer/#main-functionalities","title":"Main functionalities","text":"<ul> <li>the user selects what type of underwear they want to design</li> <li>the user specifies the initial design concept - then receives visual inspiration generated by AI</li> <li>the user provides the appropriate dimensions</li> <li>the application - using appropriate construction formulas, calculates and saves the parameters related to a specific type of underwear</li> <li>then a construction drawing is created based on the parameters calculated in the previous step, which is then displayed in the application</li> <li>the drawing is properly prepared for printing</li> <li>the user has the option to download the drawing (whole or divided into parts for printing)</li> <li>finally, the AI \u200b\u200bmodel generates recommendations related to the process of creating the element designed by the user</li> </ul>"},{"location":"fashion_designer/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Streamlit</li> <li>Matplotlib</li> <li>PIL</li> <li>Zipfile</li> <li>Requests</li> </ul>"},{"location":"fashion_designer/#sample-photos","title":"Sample photos","text":""},{"location":"features_detective/","title":"Features Detective App","text":"<p>Date of creation: 2024-10-30</p>"},{"location":"features_detective/#project-description","title":"Project description","text":"The aim of the project was to create a universal application that allows for detecting the most important features in a given data set. In short - the user uploads data or loads a ready data set in the appropriate format, then selects automatic detection of the column they want to analyze or makes this selection themselves. Finally, they receive a generated graph of the significance of features that have the greatest impact on the previously selected column. The user also receives a clear description of the graph along with recommendations - what can be improved to, for example, improve the analyzed data."},{"location":"features_detective/#main-functionalities","title":"Main functionalities","text":"<ul> <li>The user can load a CSV/JSON file with data or use a ready-made sample dataset</li> <li>The user indicates the target column -&gt; additionally, they can use automatic column detection (generated by LLM)</li> <li>The application automatically recognizes whether the loaded data is related to the regression or classification problem and selects the appropriate AI model training algorithm on this basis</li> <li>Based on the trained model, a chart containing the most important features is displayed</li> <li>Finally, the user receives a clear description of the chart along with recommendations - what actions to implement to improve the results related to the analyzed target data column</li> </ul>"},{"location":"features_detective/#ml-model-training","title":"ML model training","text":"I used PyCaret tools and I have included the implementation in a notebook ready for download: Download Notebook: Model training"},{"location":"features_detective/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> <li>PyCaret (Classification &amp; Regression)</li> <li>Pandas</li> <li>Matplotlib</li> <li>Instructor</li> <li>Pydantic</li> <li>Boto3</li> </ul>"},{"location":"features_detective/#sample-photos","title":"Sample photos","text":""},{"location":"features_detective/#links","title":"Links","text":"<p>Link to repository</p> <p>Go to application</p>"},{"location":"find_friends/","title":"Find Friends App","text":"<p>Data of creation: 2024-10-09</p>"},{"location":"find_friends/#project-description","title":"Project description","text":"The aim of the project was to create an application that would enable the use of a clustering model to match a user to the appropriate group from a loaded data set (data comes from an anonymized survey) - based on data provided by the user."},{"location":"find_friends/#main-functionalities","title":"Main functionalities","text":"<ul> <li>The user filters basic data, such as: age, education, gender, favorite animals, or favorite places - corresponding to their preferences</li> <li>Then the previously trained clustering model creates the appropriate number of clusters for the survey data and matches the user's preferences to the matching group</li> <li>Finally, using LLM, adequate cluster descriptions are generated</li> </ul>"},{"location":"find_friends/#ml-model-training","title":"ML model training","text":"I used Scikit-learn tools and I have included the implementation in a notebook ready for download: Download Notebook: Model training"},{"location":"find_friends/#clusters-naming","title":"Clusters naming","text":"I used the LLM model and I have included the implementation in a notebook ready for dowlonad: Download Notebook: Clusters naming"},{"location":"find_friends/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> <li>Scikit-learn</li> <li>Plotly</li> <li>PyCaret (Clustering)</li> <li>NumPy</li> <li>Matplotlib</li> </ul>"},{"location":"find_friends/#sample-photos","title":"Sample photos","text":""},{"location":"find_friends/#links","title":"Links","text":"<p>Link to repository</p> <p>Go to application</p>"},{"location":"halfmarathon_estimator/","title":"Halfmarathon Estimator App","text":"<p>Date of creation: 2024-10-20</p>"},{"location":"halfmarathon_estimator/#project-description","title":"Project description","text":"The aim of the project was to create an application that would use a regression algorithm to train models and would be able to predict (based on previously trained data) the time in which a user would run a half marathon - by providing specific data."},{"location":"halfmarathon_estimator/#main-functionalities","title":"Main functionalities","text":"<ul> <li>allowing the user to enter data freely (without any appropriate conversion of the record) -&gt; the LLM model used extracts data from the user into a JSON structure and prepares it for use by the regression model</li> <li>simple functionality allows for the final estimation of the time to run a half marathon - using the trained best regression model</li> <li>the LLM model is connected to Langfuse to track the model's life cycle</li> </ul>"},{"location":"halfmarathon_estimator/#ml-model-training","title":"ML model training","text":"I used PyCaret tools and I have included the implementation in a notebook ready for download: Download Notebook: Model training"},{"location":"halfmarathon_estimator/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>PyCaret</li> <li>Machine Learning</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> <li>Pandas</li> <li>Instructor</li> <li>Pydantic</li> <li>Dotenv</li> </ul>"},{"location":"halfmarathon_estimator/#sample-photos","title":"Sample photos","text":""},{"location":"halfmarathon_estimator/#links","title":"Links","text":"<p>Link to repository</p> <p>Go to application</p>"},{"location":"heweliusz/","title":"Jan Heweliusz Disaster Analysis","text":"<p>Project: March 2024 \u2014 April 2024</p> <p>Role: Data Analyst / Research Engineer</p>"},{"location":"heweliusz/#project-description","title":"Project description","text":"The disaster of the ferry MS Jan Heweliusz (January 14, 1993) was analyzed for years mainly in a descriptive manner, without full reconstruction of meteorological conditions and their impact on vessel stability.  This project aimed to reconstruct the course of the disaster in a data-driven way, based on physics and validatable models.  I conducted a comprehensive meteorological-technical analysis combining:  - ERA5 meteorological reanalyses (ECMWF), - CMEMS wave data, - hydrodynamics and stability laws, - official commission reports and court rulings."},{"location":"heweliusz/#analysis-scope","title":"Analysis Scope","text":""},{"location":"heweliusz/#1-meteorological-conditions","title":"1. Meteorological Conditions","text":"<ul> <li>atmospheric pressure (MSLP)</li> <li>wind speed and direction</li> <li>wave height and energy</li> <li>barometric gradient analysis</li> </ul>"},{"location":"heweliusz/#2-storm-dynamics","title":"2. Storm Dynamics","text":"<ul> <li>identification of explosive cyclogenesis (Bergeron criterion: \u226520 hPa / 24h)</li> <li>rapid escalation of conditions in hours preceding the disaster</li> </ul>"},{"location":"heweliusz/#3-hydrodynamics-and-stability","title":"3. Hydrodynamics and Stability","text":"<ul> <li>Beam Sea wave analysis</li> <li>parametric rolling mechanism</li> <li>escalation of heeling leading to loss of stability</li> </ul>"},{"location":"heweliusz/#4-data-validation","title":"4. Data Validation","text":"<ul> <li>ERA5 vs CMEMS comparison</li> <li>correlation, RMSE, bias</li> <li>reconstruction reliability assessment</li> </ul>"},{"location":"heweliusz/#key-findings","title":"Key Findings","text":""},{"location":"heweliusz/#weather-conditions","title":"Weather Conditions","text":"<ul> <li>Pressure drop of 27 hPa in &lt; 24h</li> <li>Wind up to 24.2 m/s (9\u00b0B \u2013 severe gale)</li> <li>Wave energy increased nearly 5\u00d7 in 6 hours</li> </ul>"},{"location":"heweliusz/#hydrodynamics","title":"Hydrodynamics","text":"<ul> <li>Waves hit the hull at ~60\u00b0 angle</li> <li>Maximum wind force on hull: ~393 kN</li> <li>Vessel remained in Beam Sea zone</li> <li>Heel resonance (parametric rolling)</li> </ul>"},{"location":"heweliusz/#heel-escalation","title":"Heel Escalation","text":"<ul> <li>0\u00b0 \u2192 35\u00b0 in 5h 40min</li> <li>35\u00b0 \u2192 90\u00b0 in 36 minutes</li> </ul>"},{"location":"heweliusz/#validation","title":"Validation","text":"<ul> <li>ERA5 vs CMEMS: r = 0.982</li> <li>R\u00b2 = 0.964</li> <li>Energy differences result from non-linearity (E \u221d H\u00b2), not data errors</li> </ul>"},{"location":"heweliusz/#what-i-did","title":"What I did","text":"<ul> <li>Acquired and processed ERA5 and CMEMS data</li> <li>Performed temporal and spatial analyses</li> <li>Calculated wave energy and forces acting on the vessel</li> <li>Built visualizations of correlation and phenomenon escalation</li> <li>Compared scientific data with commission findings</li> <li>Developed coherent narrative based on data and physics</li> </ul>"},{"location":"heweliusz/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Pandas</li> <li>NumPy</li> <li>xarray</li> <li>ERA5 (ECMWF)</li> <li>CMEMS (Copernicus Marine)</li> <li>Scientific Visualization</li> <li>Data Validation</li> </ul>"},{"location":"heweliusz/#results","title":"Results","text":"<ul> <li>Quantitative reconstruction of disaster mechanism</li> <li>Confirmation of convergence of extreme weather phenomena and technical-operational errors</li> <li>High analysis reliability through source validation</li> <li>Example of Data Science application to historical event analysis</li> </ul>"},{"location":"heweliusz/#conclusions","title":"Conclusions","text":"The MS Jan Heweliusz disaster was a systemic culmination of:  - severe storm (9\u00b0B), - beam sea waves, - rapid cyclogenesis, - improper vessel preparation for the voyage.  The project demonstrates how data analysis, physics, and model validation enable understanding complex events in an objective and replicable way."},{"location":"heweliusz/#sample-photos","title":"Sample photos","text":""},{"location":"iris/","title":"Domain exploration (EDA) of the dataset: Irises","text":"<p>Date of creation: 2024-08-25</p>"},{"location":"iris/#introduction","title":"Introduction","text":"I invite you to familiarize yourself with my project, which takes us into the world of data analysis on Irises - using domain exploration (EDA). In this project, you will find many pertinent conclusions and interesting observations that shed new light on these beautiful flowers. Prepare yourself for a fascinating journey through data, which will certainly enrich your knowledge and inspire you to further research."},{"location":"iris/#project-download","title":"Project download","text":"<p>Download Notebook Open in new tab \u2197</p>"},{"location":"iris/#notebook-preview","title":"Notebook preview","text":""},{"location":"justjoinit_browser/","title":"JustJoinIT Browser","text":"<p>Project start: 2025-02-19</p>"},{"location":"justjoinit_browser/#project-description","title":"Project description","text":"JustJoinIT Browser is a Streamlit application designed for interactive browsing of the latest job offers from the JustJoinIT platform. The project involved using the Requests library to scrape job listings data, followed by exploratory data analysis (EDA) to understand the domain and categories available on JustJoinIT. The data was then processed into a suitable CSV format, which served as the foundation for building a user-friendly interface. The application leverages Geopandas to implement an interactive map of Polish voivodeships, enabling intuitive geolocation-based filtering of job opportunities. In the future the application will be developed with AI algorithms."},{"location":"justjoinit_browser/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Custom browsing of IT job offers with flexible interface customization</li> <li>Interactive map visualization for geographical filtering by regions</li> <li>Multiple filtering options based on technology, experience level, and job type</li> <li>Data visualization with charts and statistics to better understand the job market</li> <li>User-defined sorting and prioritization of job listings</li> </ul>"},{"location":"justjoinit_browser/#eda","title":"EDA","text":"I conducted a detailed exploratory data analysis (EDA) using Pandas for data analysis, as well as Plotly, Matplotlib, and Seaborn for data visualization. Below you can find files available for download containing the full analysis and the dataset: Download Notebook: Exploratory Analysis Download CSV: Job Offers"},{"location":"justjoinit_browser/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Requests</li> <li>Pandas</li> <li>Geopandas</li> <li>Shapely</li> <li>Folium</li> <li>Streamlit</li> <li>Plotly</li> <li>Pathlib</li> <li>EDA</li> </ul>"},{"location":"justjoinit_browser/#sample-photos","title":"Sample photos","text":""},{"location":"knowledge_seeker/","title":"Knowledge Seeker","text":"<p>Project start: April 2025 \u2014 Present</p> <p>Role: AI / ML Engineer (Project Leader)</p> <p>Status: Production</p>"},{"location":"knowledge_seeker/#project-description","title":"Project description","text":"Knowledge Seeker is an advanced tool for transcription, indexing, and information retrieval from video recordings.  Users with access to large video resources (courses, trainings, mentoring sessions) had difficulty quickly finding specific information. Manually searching through hundreds of materials was time-consuming and inefficient.  As the project leader, I coordinate the development of a system utilizing the latest AI technologies for speech-to-text processing and implementation of advanced semantic search mechanisms.  The application enables users not only to find specific information in extensive video resources but also to generate responses to queries based on accumulated knowledge using the RAG (Retrieval-Augmented Generation) architecture."},{"location":"knowledge_seeker/#solution","title":"Solution","text":"I designed a system based on RAG (Retrieval-Augmented Generation) architecture, combining automatic video transcription, semantic search in a vector database, and response generation through language models."},{"location":"knowledge_seeker/#architecture","title":"Architecture","text":""},{"location":"knowledge_seeker/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Transcription of video recordings to text with preservation of time metadata (timestamps)</li> <li>Processing transcriptions through chunking and generating embeddings</li> <li>Vector database for storing and efficiently searching embeddings</li> <li>User interface enabling both simple and semantic content searching</li> <li>RAG (Retrieval-Augmented Generation) system for generating responses to user queries</li> <li>Deployment in Digital Ocean cloud ensuring scalability and availability</li> <li>Data export in JSON formats and streaming capability to user API</li> </ul>"},{"location":"knowledge_seeker/#what-i-did","title":"What I did","text":"<ol> <li>Designed the system architecture and data processing pipeline</li> <li>Implemented audio \u2192 text transcription using Whisper</li> <li>Developed document chunking and embedding generation</li> <li>Configured Qdrant vector database</li> <li>Built backend API in FastAPI</li> <li>Created user interface in Streamlit</li> <li>Deployed the system in DigitalOcean cloud (Docker)</li> </ol>"},{"location":"knowledge_seeker/#development-roadmap","title":"Development Roadmap","text":"<ul> <li>Integration with additional data sources (documents, presentations, audio)</li> <li>Enhancement of RAG mechanisms with advanced filtering and re-ranking techniques</li> <li>Implementation of components for automatic verification and updating of the knowledge base</li> <li>Optimization of indexing and search processes for larger datasets</li> <li>Development of API interface enabling integration with external applications</li> </ul>"},{"location":"knowledge_seeker/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Whisper</li> <li>Qdrant</li> <li>FastAPI</li> <li>Streamlit</li> <li>Docker</li> <li>DigitalOcean</li> <li>LLM (Large Language Models)</li> <li>Natural Language Processing</li> <li>Vector Databases</li> <li>RAG (Retrieval-Augmented Generation)</li> <li>Microservice Architecture</li> </ul>"},{"location":"knowledge_seeker/#results","title":"Results","text":"<ul> <li>400+ video recordings searchable in real-time</li> <li>Reduced information finding time from minutes to seconds</li> <li>Production-ready, scalable AI system</li> </ul>"},{"location":"larvixon_ai/","title":"Larvixon-AI","text":"<p>Project start: April 2025 \u2014 Present</p> <p>Role: AI / Computer Vision Engineer</p> <p>Collaboration: Medical University of Wroc\u0142aw</p>"},{"location":"larvixon_ai/#project-description","title":"Project description","text":"Larvixon-AI is a system based on computer vision and deep learning that automatically analyzes movement behaviors of Galleria mellonella larvae after injection of selected bacterial pathogens.  Sepsis is one of the most serious problems in modern medicine, and rapid pathogen identification is crucial for implementing appropriate therapy. Classic diagnostic methods:  - are time-consuming (24\u201372 hours), - require advanced laboratory facilities, - don't always allow for quick clinical decisions.  The Galleria mellonella model enables observation of behavioral changes after infection. However, previous analysis was manual, difficult to standardize, and limited in scalability.  The project is carried out as a master's thesis in collaboration with the Medical University of Wroc\u0142aw."},{"location":"larvixon_ai/#how-it-works","title":"How It Works","text":"Larvixon-AI is a video analysis pipeline:  - **Video ingestion** \u2014 HD recordings (25 FPS), various lighting conditions - **Computer Vision layer** \u2014 object detection (larvae), segmentation and masking, position tracking across frames - **Analysis layer** \u2014 trajectory calculation, distance, speed, directions, activity heat maps - **Data &amp; visualization** \u2014 CSV export, statistical analysis, result visualizations  The architecture is prepared for further integration with deep learning models."},{"location":"larvixon_ai/#what-i-did","title":"What I did","text":"<ol> <li>Designed the algorithm for larvae detection and tracking in video</li> <li>Implemented image processing pipeline in OpenCV</li> <li>Handled different lighting variants (top / bottom)</li> <li>Calculated trajectories and kinematic movement parameters</li> <li>Conducted comparative analysis of groups:</li> <li>control</li> <li>PBS</li> <li>E. coli infected (various concentrations)</li> <li>Automated data export and visualization generation</li> <li>Analyzed results for behavioral differences</li> </ol>"},{"location":"larvixon_ai/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenCV</li> <li>Deep Learning</li> <li>Computer Vision</li> <li>NumPy</li> <li>Pandas</li> <li>Scientific Computing</li> <li>Video Processing</li> </ul>"},{"location":"larvixon_ai/#key-results","title":"Key Results","text":"<ul> <li>100% movement detection accuracy</li> <li>Real-time video processing (25 FPS)</li> <li>Significant differences between groups:</li> <li>control larvae: ~5 mm/s</li> <li>infected larvae: ~2.3 mm/s (high concentrations)</li> <li>Clear differences in:</li> <li>traveled distances</li> <li>spatial activity distribution</li> <li>movement patterns</li> </ul>"},{"location":"larvixon_ai/#impact-future-work","title":"Impact &amp; Future Work","text":"Larvixon-AI provides a foundation for further research on:  - automatic identification of septic pathogens, - accelerating infection diagnostics, - using deep learning in behavioral analysis.  The project connects AI engineering with biomedical research and bridges science with practical clinical applications."},{"location":"my_chatbot/","title":"My Chatbot App","text":"<p>Date of creation: 2024-09-15</p>"},{"location":"my_chatbot/#project-description","title":"Project description","text":"The aim of the project was to create own version of Chat GPT, based on the Streamlit application interface. The chatbot can take on any personality to maximize its functionality to our preferences."},{"location":"my_chatbot/#main-functionalities","title":"Main functionalities","text":"<ul> <li>the chatbot remembers conversations and saves them in a JSON file structure, and you can easily switch between conversations (without losing your chat history)</li> <li>you can choose between various models from OpenAI</li> <li>the costs of using AI are counted</li> <li>you can give the chatbot individual awareness that will guide the types of answers to the questions asked</li> </ul>"},{"location":"my_chatbot/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> </ul>"},{"location":"my_chatbot/#sample-photos","title":"Sample photos","text":""},{"location":"my_chatbot/#application-usage","title":"Application usage","text":"The application has been deployed on the Streamlit Community App helps me explore the secrets of AI and expand my programming skills on a daily basis."},{"location":"quality_management_system/","title":"Quality Management System","text":"<p>Project: February 2024 \u2014 August 2024</p> <p>Role: Data / AI Engineer</p>"},{"location":"quality_management_system/#project-description","title":"Project description","text":"In industrial organizations, quality and technical data are often scattered across multiple sources:  - quality reports in Excel, - technical documentation in PDF, - process instructions in various locations, - corrective action history in separate files.  As a result:  - finding the right document takes too much time, - data is inconsistent and difficult to compare, - there's no single place for quality analysis and decisions, - organizational knowledge is heavily dependent on specific people.  I designed the Quality Management System (QMS), whose main goal was to create one central source of truth for quality data and technical knowledge."},{"location":"quality_management_system/#solution","title":"Solution","text":"The system combines:  - classic QMS (reports, actions, metrics), - **Knowledge Management** layer, - **semantic search** enabling natural language queries.  Everything was delivered as a Streamlit application serving as an operational quality dashboard."},{"location":"quality_management_system/#architecture-overview","title":"Architecture Overview","text":"QMS was designed as a system integrating multiple data sources:  - **Data ingestion** \u2014 import from PDF and Excel files, normalization and standardization - **Central database** \u2014 relational database as single source of truth, unified quality data models - **Knowledge layer** \u2014 document content extraction, embeddings and semantic index - **Application layer** \u2014 Streamlit as user interface, dashboards, reports, search  The architecture was designed with:  - ERP / CRM integration in mind, - future expansion with additional AI modules."},{"location":"quality_management_system/#key-features","title":"Key Features","text":""},{"location":"quality_management_system/#intelligent-semantic-search","title":"Intelligent Semantic Search","text":"<ul> <li>search drawings, instructions, and reports</li> <li>natural language queries</li> <li>no need to know folder structure</li> </ul>"},{"location":"quality_management_system/#centralized-standardized-data","title":"Centralized &amp; Standardized Data","text":"<ul> <li>all quality data in one place</li> <li>consistent formats and current document versions</li> <li>elimination of duplicates and outdated files</li> </ul>"},{"location":"quality_management_system/#automated-reporting-analytics","title":"Automated Reporting &amp; Analytics","text":"<ul> <li>quality dashboards</li> <li>corrective action statuses</li> <li>quick quality KPI overview</li> </ul>"},{"location":"quality_management_system/#integration-ready-architecture","title":"Integration-Ready Architecture","text":"<ul> <li>preparation for ERP / CRM integration</li> <li>modular data structure</li> <li>readiness for further AI systems</li> </ul>"},{"location":"quality_management_system/#what-i-did","title":"What I did","text":"<ol> <li>Analyzed existing quality data sources</li> <li>Designed unified data model</li> <li>Implemented data import and transformation from PDF and Excel</li> <li>Created central database as single source of truth</li> <li>Built semantic search layer over documentation</li> <li>Developed quality dashboard in Streamlit</li> <li>Automated reporting and action monitoring</li> <li>Prepared architecture for future integrations and AI</li> </ol>"},{"location":"quality_management_system/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Streamlit</li> <li>PostgreSQL</li> <li>Pandas</li> <li>SQL</li> <li>PDF Processing</li> <li>Excel Processing</li> <li>Semantic Search</li> <li>Embeddings</li> <li>Machine Learning</li> <li>Computer Vision</li> <li>Docker</li> </ul>"},{"location":"quality_management_system/#results","title":"Results","text":"<ul> <li>Reduced document search time by up to 70%</li> <li>One consistent source of quality data</li> <li>Better process and action history transparency</li> <li>Faster quality decision-making</li> <li>Improved collaboration between:</li> <li>production</li> <li>quality</li> <li>procurement</li> <li>Solid foundation for further AI system development in the organization</li> </ul>"},{"location":"robinson_chatbot/","title":"Robinson Chatbot","text":"<p>Project start: 2025-01-31</p>"},{"location":"robinson_chatbot/#project-description","title":"Project description","text":"The Robinson Chatbot project explores the implementation of Retrieval-Augmented Generation (RAG) techniques to create an intelligent conversational agent knowledgeable about \"Robinson Crusoe.\" The system combines state-of-the-art language models from both OpenAI and Amazon Bedrock with advanced text retrieval methods to provide accurate, contextually relevant answers based on the novel's content. Through extensive experimentation with various chunking strategies, embedding models, and prompt engineering techniques, the project demonstrates how RAG architectures can effectively enhance LLM capabilities for domain-specific applications while minimizing hallucinations and improving factual accuracy."},{"location":"robinson_chatbot/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Implementation of various text chunking methods (e.g. by paragraphs, fixed token size, by chapters) to optimize information retrieval</li> <li>Experimentation with different embedding models to create semantic vector representations</li> <li>Advanced similarity search using FAISS vector database for efficient information retrieval</li> <li>Comparison of performance between OpenAI models (gpt-4o and gpt-4o-mini) and Amazon Bedrock models (Amazon Titan Text Express V1 and Amazon Titan Text Embeddings E1)</li> <li>Prompt engineering techniques to optimize context utilization and response quality</li> <li>Interactive Streamlit application for user-friendly chatbot interaction about Robinson Crusoe</li> <li>Comprehensive evaluation framework to measure accuracy, relevance, and coherence of responses</li> </ul>"},{"location":"robinson_chatbot/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Amazon Bedrock</li> <li>AWS</li> <li>Numpy</li> <li>Faiss</li> <li>RAG</li> <li>Boto3</li> <li>Nltk</li> <li>Streamlit</li> <li>Prompt Engineerning</li> <li>Embeddings</li> <li>LaTeX</li> </ul>"},{"location":"robinson_chatbot/#project-report","title":"Project Report","text":"<p>You can download and review the complete project report with detailed methodology and results here: Robinson Chatbot - RAG Implementation Report</p>"},{"location":"robinson_chatbot/#sample-photos","title":"Sample photos","text":""},{"location":"student_profiler/","title":"Student Profiler","text":"<p>Project: March 2025 \u2014 June 2025</p> <p>Role: Backend / Data Engineer</p> <p>Company: GOTOIT sp. z o.o.</p> <p>Status: Production</p>"},{"location":"student_profiler/#project-description","title":"Project description","text":"Mentors and course instructors lacked a tool for systematic monitoring of student activity on Discord.  Analysis of engagement, work regularity, and interaction history:  - was scattered across many channels, - required manual message review, - provided no basis for automatic conclusions or scaling the mentoring process.  There was no single, central system for collecting and analyzing data.  I designed and developed Student Profiler \u2014 a tool for automatic monitoring of student activity in the Discord environment."},{"location":"student_profiler/#solution","title":"Solution","text":"The core of the system is a Discord Bot that:  - fetches historical data from channels, - listens for new messages and events in real-time, - saves data in a relational database, - feeds the analytical layer and user interface.  The architecture is prepared for further development of AI-based features (humanized mentor bot, sentiment analysis, OCR, predictive models)."},{"location":"student_profiler/#architecture","title":"Architecture","text":""},{"location":"student_profiler/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Discord Bot integration for monitoring activity and automated messaging</li> <li>Scheduled hourly data collection from Discord channels</li> <li>Data storage system using PostgreSQL for messages and Digital Ocean Spaces for attachments</li> <li>Streamlit-based UI for easy access and analysis of Discord data</li> <li>Scalable architecture with future implementation plans for AI features</li> </ul>"},{"location":"student_profiler/#what-i-did","title":"What I did","text":"<ol> <li>Designed system architecture following Single Responsibility Principle</li> <li>Implemented Discord Bot for:</li> <li>fetching message history</li> <li>listening for new events</li> <li>handling automated responses</li> <li>Created hourly data collection scheduler</li> <li>Designed and deployed PostgreSQL database</li> <li>Integrated DigitalOcean Spaces for attachment storage</li> <li>Built analytical UI in Streamlit with Plotly visualizations</li> <li>Prepared Docker environment for local and cloud deployment</li> <li>Implemented application configuration using pydantic-settings</li> </ol>"},{"location":"student_profiler/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Discord API</li> <li>PostgreSQL</li> <li>Streamlit</li> <li>Docker</li> <li>DigitalOcean</li> <li>Pandas</li> <li>SQL</li> <li>Plotly</li> <li>Psycopg</li> <li>Requests</li> <li>Schedule</li> <li>Pydantic-settings</li> <li>SRP design</li> </ul>"},{"location":"student_profiler/#results","title":"Results","text":"<ul> <li>Central data source for student activity on Discord</li> <li>Automatic and regular data collection without manual mentor intervention</li> <li>Clear dashboard for engagement and trend analysis</li> <li>Stable foundation for further AI feature development:</li> <li>communication sentiment analysis</li> <li>student activity drop prediction</li> <li>humanized mentor bot</li> </ul>"},{"location":"student_profiler/#sample-photos","title":"Sample photos","text":""},{"location":"titanic/","title":"Domain exploration (EDA) of the dataset: Titanic","text":"<p>Date of creation: 2024-08-25</p>"},{"location":"titanic/#introduction","title":"Introduction","text":"I invite you to familiarize yourself with my project, which takes us into the world of data analysis regarding the world-famous Titanic disaster. In order to explore the information, I use domain exploration (EDA). In this project, you will find many relevant conclusions and interesting observations. Prepare yourself for an interesting journey with data that will broaden your horizons of looking at one of the greatest maritime disasters in history."},{"location":"titanic/#project-download","title":"Project download","text":"<p>Download Notebook Open in new tab \u2197</p>"},{"location":"titanic/#notebook-preview","title":"Notebook preview","text":""},{"location":"welcome_survey/","title":"Welcome Survey App","text":"<p>Date of creation: 2024-09-22</p>"},{"location":"welcome_survey/#project-description","title":"Project description","text":"The aim of the project was to create an application that would allow for simple filtering and browsing of data from a sample welcome survey (the data was appropriately anonymized). The aim of the application was to consolidate components from the Streamlit library and familiarize users with the proper management of the application state (<code>st.session_state</code>) so that all buttons and interactions were responsive to each other."},{"location":"welcome_survey/#main-functionalities","title":"Main functionalities","text":"<ul> <li>the ability to browse an anonymous survey to familiarize yourself with the Streamlit interface</li> <li>various types of filters allow you to get to know the analyzed data in more detail</li> <li>visualizations are also included</li> <li>the application also contains interesting visualizations and for the most persistent - curiosities await!</li> </ul>"},{"location":"welcome_survey/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Pandas</li> <li>Matplotlib</li> <li>Seaborn</li> <li>Streamlit</li> <li>Boto3</li> </ul>"},{"location":"welcome_survey/#sample-photos","title":"Sample photos","text":""},{"location":"pl/","title":"Strona g\u0142\u00f3wna","text":"Projekty ze \u015bwiata danych, programowania w Pythonie i technologii AI"},{"location":"pl/#wprowadzenie","title":"Wprowadzenie","text":"Witaj na mojej stronie po\u015bwi\u0119conej projektom z zakresu analizy danych, uczenia maszynowego i sztucznej inteligencji."},{"location":"pl/#moja-krotka-historia","title":"Moja kr\u00f3tka historia","text":"W 2019 roku uko\u0144czy\u0142em studia na kierunku Mechatronika na Politechnice Wroc\u0142awskiej, co rozbudzi\u0142o moj\u0105 ch\u0119\u0107 do eksplorowania nowych technologii. Przez ostatnie pi\u0119\u0107 lat pracowa\u0142em jako in\u017cynier w przemy\u015ble produkcyjnym, gdzie dane odgrywa\u0142y kluczow\u0105 rol\u0119 w mojej pracy. Analizuj\u0105c dane produkcyjne i jako\u015bciowe, by\u0142em w stanie optymalizowa\u0107 procesy i znajdowa\u0107 innowacyjne rozwi\u0105zania zwi\u0119kszaj\u0105ce produktywno\u015b\u0107 i efektywno\u015b\u0107.   Od pewnego czasu rozwijam silne zainteresowanie AI, co doprowadzi\u0142o mnie do uko\u0144czenia kursu Data Scientist i rozpocz\u0119cia budowania swojego portfolio. Stworzy\u0142em kilka praktycznych projekt\u00f3w i mam wi\u0119cej pomys\u0142\u00f3w, kt\u00f3re zamierzam przekszta\u0142ci\u0107 w produkty komercyjne.  Uda\u0142o mi si\u0119 r\u00f3wnie\u017c zdoby\u0107 wymarzon\u0105 prac\u0119 w dziale Data Science, gdzie pracuj\u0119 nad projektami zwi\u0105zanymi z Machine Learning i Deep Learning. Dodatkowo jestem certyfikowanym AWS Machine Learning Engineer Associate, co wzmocni\u0142o moje umiej\u0119tno\u015bci implementacji ML w chmurze."},{"location":"pl/#moja-aktualna-aktywnosc","title":"Moja aktualna aktywno\u015b\u0107","text":"Ze wzgl\u0119du na rosn\u0105c\u0105 pasj\u0119 do AI i Data Science, w marcu 2025 roku rozpocz\u0105\u0142em studia magisterskie na kierunku Sztuczna Inteligencja i Uczenie Maszynowe. Jestem g\u0142\u0119boko zaanga\u017cowany w rozw\u00f3j mojej kariery akademickiej. Moja praca magisterska b\u0119dzie skupiona na wykorzystaniu algorytm\u00f3w computer vision w projekcie we wsp\u00f3\u0142pracy z Uniwersytetem Medycznym we Wroc\u0142awiu. Projekt b\u0119dzie polega\u0142 na wykrywaniu larw i analizowaniu ich zachowa\u0144 w warunkach eksperymentalnych. Dodatkowo, od stycznia 2025 roku jestem Student Success Managerem w Gotoit, gdzie mam okazj\u0119 mentorowa\u0107 kurs Data Science. Prowadz\u0119 cotygodniowe sesje live, podczas kt\u00f3rych poszerzamy wiedz\u0119 z zakresu danych i AI. Eksperymentuj\u0119 r\u00f3wnie\u017c z tworzeniem tutoriali z Pythona, SQL i innych bibliotek przydatnych w Data Science.  Ostatnio obj\u0105\u0142em rol\u0119 lidera projektu Knowledge Seeker, innowacyjnego systemu wykorzystuj\u0105cego technologi\u0119 RAG (Retrieval-Augmented Generation) do transkrypcji, indeksowania i wydobywania informacji z tre\u015bci wideo. Ten projekt pozwala mi stosowa\u0107 najnowocze\u015bniejsze techniki AI w praktycznym kontek\u015bcie biznesowym."},{"location":"pl/#o-portfolio","title":"O portfolio","text":"Znajdziesz tutaj wiele projekt\u00f3w, nad kt\u00f3rymi pracowa\u0142em ostatnio: od eksploracji danych (EDA) na gotowych zbiorach danych, przez tworzenie aplikacji Streamlit - pozwalaj\u0105cych przegl\u0105da\u0107 dane w prosty spos\u00f3b, a\u017c po aplikacje oparte na AI i Machine Learning - do znajdowania wzorc\u00f3w niewidocznych na pierwszy rzut oka.  Zapraszam do zapoznania si\u0119 z projektami i mam nadziej\u0119, \u017ce ka\u017cdy znajdzie co\u015b dla siebie. Zach\u0119cam do regularnych odwiedzin - zamierzam na bie\u017c\u0105co rozszerza\u0107 moje portfolio o nowe pomys\u0142y."}]}