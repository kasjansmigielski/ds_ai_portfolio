{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"Kasjan \u015amigielski AWS ML Engineer &amp; Data Scientist"},{"location":"#about-me","title":"About Me","text":"I am an AI Engineer and Data Scientist specializing in designing intelligent data-driven systems \u2014 from data analysis and EDA, through Machine Learning and Computer Vision models, to production-grade LLM architectures and RAG systems.  I combine engineering experience from industry with modern AI technologies, building solutions that:  - solve real business and research problems, - are scalable and production-ready, - connect AI with solid software engineering."},{"location":"#my-professional-journey","title":"My Professional Journey","text":"In 2019, I graduated with a degree in Mechatronics from Wroc\u0142aw University of Science and Technology. Over the following years, I worked as an engineer in the manufacturing industry, where quality and process data played a crucial role in optimizing processes and decision-making.  Working with real industrial data:  - sparked my interest in data analysis, - taught me systems thinking, - showed me the importance of data quality and business context.  The natural step was to transition towards Data Science and AI."},{"location":"#current-focus","title":"Current Focus","text":"I completed the Data Scientist track and started systematically building a portfolio of projects covering:  - exploratory data analysis (EDA), - analytical applications in Streamlit, - Machine Learning and Deep Learning systems, - solutions based on LLMs and semantic search.  I currently work on projects in:  - **Machine Learning and Deep Learning** - **Computer Vision** - **LLM integration and RAG** - **AI in production environments**  I hold the AWS Machine Learning Engineer \u2013 Associate certification, confirming my competencies in designing and deploying ML solutions in the cloud."},{"location":"#teaching-mentoring","title":"\ud83c\udf93 Teaching &amp; Mentoring","text":"Since January 2025, I have been a Student Success Manager at Gotoit, where I mentor a Data Science course. I conduct weekly live sessions where we expand knowledge in data and AI.  Additionally, I teach and conduct workshops for:  - **Data Science course participants** \u2014 Python, SQL, EDA, Machine Learning, Deep Learning - **High school students** (IT profile) \u2014 practical AI applications - **Teachers and pedagogical staff** \u2014 responsible and practical use of AI  My teaching philosophy focuses on understanding, not memorization, real cases instead of artificial datasets, and critical thinking about AI rather than hype."},{"location":"#academic-activity","title":"\ud83d\udcda Academic Activity","text":"In March 2025, I started master's studies in Artificial Intelligence and Machine Learning.  My master's thesis focuses on:  - applying computer vision, - analyzing object behaviors in video material, - using ML and DL algorithms in biomedical research.  The project is carried out in collaboration with the Medical University of Wroc\u0142aw."},{"location":"#about-this-portfolio","title":"About This Portfolio","text":"Here you will find many projects I have been working on recently: from domain exploration (EDA) on ready-made datasets, through creating Streamlit applications allowing you to browse data in a simple way, and ending with AI-powered and Machine Learning-based applications to find patterns invisible at first glance.  I encourage you to visit here regularly \u2014 I intend to expand my portfolio with new ideas on an ongoing basis."},{"location":"ainnouncer_studio/","title":"AInnouncer Studio","text":"<p>Project start: October 2024 \u2014 Present</p> <p>Role: Tech Lead / AI Engineer</p>"},{"location":"ainnouncer_studio/#project-description","title":"Project description","text":"<p>AInnouncer Studio is a comprehensive AI platform for automatic audio content generation for radio stations, built on a professional LLMs and LLOps architecture.</p> <p>Radio stations need regular, professional audio content: weather forecasts, music announcements, on-air messages, or advertising materials. This process is time-consuming, expensive, difficult to scale, and heavily dependent on people.</p> <p>The system combines:</p> <ul> <li>text generation (LLM),</li> <li>voice synthesis (TTS),</li> <li>audio mixing (broadcast-ready),</li> <li>automation,</li> <li>monitoring and quality control.</li> </ul> <p>The platform was designed as a scalable SaaS, ready for multiple clients and additional modules.</p>"},{"location":"ainnouncer_studio/#architecture-overview","title":"Architecture Overview","text":"<p>AInnouncer Studio is an event-driven + worker-based architecture:</p> <ul> <li>Frontend (Next.js) \u2014 configuration of modules, prompts, voices, schedules</li> <li>Backend API (FastAPI) \u2014 domain logic, routing, validation, orchestration</li> <li>Asynchronous workers (Dramatiq + Redis) \u2014 content generation, TTS, mixing, upload</li> <li>LLM Layer \u2014 OpenAI GPT-4o / GPT-4o-mini with advanced system prompts</li> <li>LLOps &amp; Observability \u2014 Langfuse (traces, spans, cost, quality), prompt versioning, Promptfoo (prompt testing)</li> <li>Data Layer \u2014 PostgreSQL (configurations, prompts, voices, schedules), S3-compatible storage (audio)</li> <li>Infrastructure \u2014 Docker Compose, CI/CD, Monitoring (Prometheus + Grafana)</li> </ul>"},{"location":"ainnouncer_studio/#key-modules","title":"Key Modules","text":""},{"location":"ainnouncer_studio/#weather-forecast-production","title":"Weather Forecast (Production)","text":"<ul> <li>weather data \u2192 LLM text \u2192 TTS voice \u2192 jingle mix \u2192 upload</li> <li>support for multiple locations and languages</li> <li>broadcast schedules</li> </ul>"},{"location":"ainnouncer_studio/#ainnouncer-dj-music-announcer","title":"AInnouncer (DJ / Music Announcer)","text":"<ul> <li>playlist parsing (.mix)</li> <li>batch text generation</li> <li>announcement frequency control</li> <li>audio ready for broadcast automation</li> </ul>"},{"location":"ainnouncer_studio/#platform-core-llops","title":"Platform Core (LLOps)","text":"<ul> <li>prompt versioning</li> <li>response quality monitoring</li> <li>LLM cost analysis</li> <li>retry &amp; fallback logic</li> <li>preparation for AI agents</li> </ul>"},{"location":"ainnouncer_studio/#what-i-did","title":"What I did","text":"<ol> <li>Designed the complete AI system architecture in production</li> <li>Built the backend in FastAPI with separation of concerns</li> <li>Implemented asynchronous pipelines (Dramatiq)</li> <li>Created the LLM layer with prompt control and validation</li> <li>Integrated Langfuse for LLM observability and monitoring</li> <li>Deployed Promptfoo for prompt testing</li> <li>Built TTS and audio mixing system to radio standards</li> <li>Designed CI/CD and cloud environment</li> <li>Prepared the platform for further AI agent development</li> </ol>"},{"location":"ainnouncer_studio/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>FastAPI</li> <li>OpenAI GPT-4o</li> <li>ElevenLabs TTS</li> <li>Langfuse</li> <li>Promptfoo</li> <li>PostgreSQL</li> <li>Redis</li> <li>Dramatiq</li> <li>Docker</li> <li>DigitalOcean</li> <li>Next.js</li> <li>TypeScript</li> <li>Prometheus</li> <li>Grafana</li> </ul>"},{"location":"ainnouncer_studio/#results","title":"Results","text":"<ul> <li>Fully automatic generation of broadcast-ready audio content</li> <li>Stable, production AI architecture (not a demo)</li> <li>Full control over LLM quality and costs</li> <li>System ready to scale as a SaaS product</li> <li>Solid foundation for:</li> <li>AI agents</li> <li>additional modules (ads, traffic, voice branding)</li> <li>international expansion</li> </ul>"},{"location":"ainnouncer_studio/#sample-photos","title":"Sample photos","text":""},{"location":"audio_notes/","title":"Audio Notes App","text":"<p>Date of creation: 2024-10-03</p>"},{"location":"audio_notes/#project-description","title":"Project description","text":"The goal of the project was to create the first AI-powered application. To do this, I used two LLM models from OpenAI: <code>whisper-1</code> (speech -&gt; text) and <code>text-embeddings-3-large</code> (text -&gt; embeddings)."},{"location":"audio_notes/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Recording and listening to voice notes</li> <li>Transcription of voices into text using AI</li> <li>Ability to collect notes in the QDrant database</li> <li>Semantic data search using the text processing algorithm on embeddings and finding similarities based on Cosinus Similarity</li> </ul>"},{"location":"audio_notes/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>QDrant</li> <li>OpenAI embeddings</li> <li>OpenAI whisper-1</li> <li>Streamlit</li> <li>Dotenv</li> <li>PyDub</li> <li>io</li> <li>md5</li> </ul>"},{"location":"audio_notes/#sample-photos","title":"Sample photos","text":""},{"location":"audio_notes/#application-usage","title":"Application usage","text":"The application has been deployed on the Streamlit Community App helps me generate notes more easily and most importantly enables contextual search using AI. <p>Link to repository</p>"},{"location":"b_roll_assistant/","title":"B-Roll Assistant","text":"<p>Project start: October 2024 \u2014 Present</p> <p>Role: AI / Backend Engineer</p>"},{"location":"b_roll_assistant/#project-description","title":"Project description","text":"<p>B-Roll Assistant is an intelligent AI assistant that automatically catalogs video materials and enables their instant search.</p> <p>In newsrooms and video production environments, time is critical. Editors and video editors must quickly find the right B-roll, often under deadline pressure. In practice:</p> <ul> <li>video materials are poorly described or not at all,</li> <li>file names are ambiguous,</li> <li>manual tagging is costly and unrealistic,</li> <li>classic folder-based search doesn't scale.</li> </ul> <p>The system:</p> <ul> <li>analyzes video without user intervention,</li> <li>generates snapshots and shot descriptions using AI,</li> <li>combines classic search with semantic search,</li> <li>learns from editor ratings.</li> </ul> <p>Thanks to this, the editor doesn't need to know how the file was named \u2014 just describe what they're looking for.</p>"},{"location":"b_roll_assistant/#how-it-works","title":"How It Works","text":""},{"location":"b_roll_assistant/#1-smart-catalog-setup","title":"1. Smart Catalog Setup","text":"<ul> <li>System adapts to existing file structure</li> <li>No manual organization required</li> <li>Handles large B-roll archives</li> </ul>"},{"location":"b_roll_assistant/#2-ai-shot-descriptions","title":"2. AI Shot Descriptions","text":"<ul> <li>Automatic snapshot generation (FFmpeg)</li> <li>Visual shot analysis (AI Vision)</li> <li>Text descriptions for each clip: objects, scenes, context, atmosphere</li> <li>Each clip receives a rich semantic description without manual tagging</li> </ul>"},{"location":"b_roll_assistant/#3-dual-search-continuous-learning","title":"3. Dual Search &amp; Continuous Learning","text":"<ul> <li>Keyword search (fast, precise queries)</li> <li>Semantic search (search by meaning and concepts)</li> </ul> <p>Example queries:</p> <ul> <li>\"glass\"</li> <li>\"transparent container\"</li> <li>\"tense political rally\"</li> <li>\"crowd waiting nervously\"</li> </ul> <p>The system enables rating results, which:</p> <ul> <li>improves accuracy,</li> <li>adjusts ranking,</li> <li>increases search effectiveness over time.</li> </ul>"},{"location":"b_roll_assistant/#architecture-overview","title":"Architecture Overview","text":"<p>B-Roll Assistant is a multimodal pipeline:</p> <ul> <li>Video ingestion \u2014 file structure analysis, frame extraction</li> <li>AI processing \u2014 vision \u2192 image description, text \u2192 embeddings</li> <li>Search layer \u2014 classic indexes, vector database</li> <li>Feedback loop \u2014 user ratings, result ranking correction</li> </ul> <p>Designed for performance and scaling in media environments.</p>"},{"location":"b_roll_assistant/#what-i-did","title":"What I did","text":"<ol> <li>Designed the B-roll analysis system architecture</li> <li>Implemented video frame extraction pipeline</li> <li>Integrated AI Vision for shot analysis</li> <li>Created automatic clip description system</li> <li>Built dual search engine (keyword + semantic)</li> <li>Deployed embedding-based search</li> <li>Designed user feedback mechanism</li> <li>Prepared backend API and data structure</li> <li>Containerized the system (Docker)</li> </ol>"},{"location":"b_roll_assistant/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenAI (Vision + LLM)</li> <li>Embeddings</li> <li>Vector Database</li> <li>FastAPI</li> <li>PostgreSQL</li> <li>FFmpeg</li> <li>Docker</li> <li>Semantic Search</li> </ul>"},{"location":"b_roll_assistant/#results","title":"Results","text":"<ul> <li>Find the right B-roll in seconds instead of minutes</li> <li>No need for manual tagging</li> <li>Better utilization of existing video archives</li> <li>System that learns along with the editorial team</li> <li>Solid foundation for: newsrooms, media houses, content platforms</li> </ul>"},{"location":"b_roll_assistant/#sample-photos","title":"Sample photos","text":""},{"location":"bitcoin_prediction/","title":"Bitcoin Price Prediction","text":"<p>Project start: 2025-02-04</p>"},{"location":"bitcoin_prediction/#project-description","title":"Project description","text":"This project focuses on developing a predictive model for Bitcoin price movements using deep learning techniques. The approach integrates comprehensive Exploratory Data Analysis (EDA) with advanced time series forecasting methods, specifically Long Short-Term Memory (LSTM) neural networks. By leveraging historical Bitcoin pricing data (from Kaggle), technical indicators, and market sentiment metrics, the model aims to forecast future price trends with meaningful accuracy. The implementation utilizes TensorFlow and Keras frameworks to build, train, and evaluate the LSTM architecture, which is particularly suited for capturing temporal dependencies in financial time series data. This project demonstrates the application of deep learning to cryptocurrency market analysis and provides insights into the factors influencing Bitcoin price volatility."},{"location":"bitcoin_prediction/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Comprehensive Exploratory Data Analysis (EDA) of historical Bitcoin price data and related market metrics</li> <li>Data preprocessing including normalization techniques to optimize model performance</li> <li>Implementation of feature engineering to extract meaningful predictors from raw market data</li> <li>Development of LSTM (Long Short-Term Memory) neural network architecture for time series forecasting</li> <li>Integration of TensorFlow and Keras frameworks for model building, training, and evaluation</li> <li>Hyperparameter tuning to optimize model accuracy and generalization capabilities</li> <li>Visualization of predicted vs. actual price movements to assess model performance</li> <li>Analysis of prediction errors to identify market conditions affecting forecast accuracy</li> </ul>"},{"location":"bitcoin_prediction/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Pandas</li> <li>EDA</li> <li>Numpy</li> <li>Sklearn</li> <li>Tensorflow</li> <li>Keras</li> <li>LSTM</li> <li>Matplotlib</li> <li>LaTeX</li> </ul>"},{"location":"bitcoin_prediction/#project-report","title":"Project Report","text":"<p>You can download and review the complete project report with detailed methodology and results here: Bitcoin Price Prediction Report</p>"},{"location":"bitcoin_prediction/#sample-photos","title":"Sample photos","text":""},{"location":"career_guide/","title":"Career Guide","text":"<p>Project: June 2025 \u2014 November 2025</p> <p>Role: Product Owner</p> <p>Status: Completed</p>"},{"location":"career_guide/#project-description","title":"Project description","text":"<p>The job search process in the IT industry is for candidates:</p> <ul> <li>time-consuming,</li> <li>chaotic,</li> <li>based on manually matching CVs to dozens of offers.</li> </ul> <p>Candidates often:</p> <ul> <li>don't know which offers are actually suited to their profile,</li> <li>send the same CV to different companies,</li> <li>waste time on document revisions without feedback.</li> </ul> <p>The market lacked a tool that simultaneously analyzes CVs and job requirements and indicates the best matches automatically.</p>"},{"location":"career_guide/#solution","title":"Solution","text":"<p>Career Guide is an intelligent platform using AI algorithms that shortens the path from CV to a matched job offer.</p> <p>The system:</p> <ul> <li>analyzes the user's CV content,</li> <li>compares it with hundreds of job offers,</li> <li>calculates percentage match of profile to listings,</li> <li>enables generating CV tailored to a specific offer,</li> <li>supports the user through an AI assistant.</li> </ul> <p>The product was designed as a scalable tool for a broad group of IT candidates.</p>"},{"location":"career_guide/#key-features","title":"Key Features","text":""},{"location":"career_guide/#intelligent-job-offer-matching","title":"Intelligent job offer matching","text":"<ul> <li>CV and job requirements analysis</li> <li>percentage profile matching</li> <li>quick identification of best offers</li> </ul>"},{"location":"career_guide/#cv-generation-for-specific-offers","title":"CV generation for specific offers","text":"<ul> <li>automatic creation of CV tailored to a specific listing</li> <li>content optimization for position requirements</li> </ul>"},{"location":"career_guide/#ai-assistant-for-cv-improvement","title":"AI assistant for CV improvement","text":"<ul> <li>interactive conversation with AI</li> <li>language and structural change suggestions</li> <li>strengthening key CV sections</li> </ul>"},{"location":"career_guide/#personality-tests","title":"Personality tests","text":"<ul> <li>identification of candidate's strengths</li> <li>support in choosing appropriate roles</li> </ul>"},{"location":"career_guide/#examiner-module-in-development","title":"\"Examiner\" module (in development)","text":"<ul> <li>simulated recruitment interviews</li> <li>development of technical and soft skills</li> </ul>"},{"location":"career_guide/#my-role-as-product-owner","title":"My Role as Product Owner","text":"<p>As Product Owner I was responsible for:</p> <ul> <li>leading the development of the Career Guide product</li> <li>defining the vision and long-term development direction</li> <li>managing the backlog and functional priorities</li> <li>sprint planning and delivery oversight</li> <li>coordinating work of 8 project teams in various locations</li> <li>gathering and analyzing user needs</li> <li>translating business requirements into product features</li> <li>ensuring product consistency as a whole</li> </ul>"},{"location":"career_guide/#what-i-did","title":"What I did","text":"<ul> <li>Defined the product roadmap and key milestones</li> <li>Organized the functional scope of the platform</li> <li>Supported teams in making product decisions</li> <li>Moderated planning sessions and sprint reviews</li> <li>Ensured vision consistency with parallel work of multiple teams</li> <li>Introduced iterative improvements based on user feedback</li> </ul>"},{"location":"career_guide/#skills","title":"Skills","text":"<ul> <li>Product Management</li> <li>Agile / Scrum</li> <li>AI Matching Algorithms</li> <li>Natural Language Processing</li> <li>CV Parsing</li> <li>LLM-based Assistants</li> <li>Product Discovery</li> <li>User-Centric Design</li> <li>Roadmap Planning</li> <li>Stakeholder Management</li> </ul>"},{"location":"career_guide/#results","title":"Results","text":"<ul> <li>Coherent AI product vision and architecture</li> <li>Organized development process with multiple teams working in parallel</li> <li>Platform that actually shortens job search time</li> <li>Tool addressing real recruitment market problems</li> <li>Solid foundation for further development and product scaling</li> </ul>"},{"location":"career_guide/#conclusions","title":"Conclusions","text":"<p>The Career Guide project was an experience combining:</p> <ul> <li>technical understanding of AI systems,</li> <li>product thinking,</li> <li>team management,</li> <li>working with real user needs.</li> </ul> <p>It demonstrated how to effectively build an AI-powered product at the intersection of technology, business, and user experience.</p>"},{"location":"cifar10_classification/","title":"CIFAR-10 Image Classification","text":"<p>Project start: 2025-02-07</p>"},{"location":"cifar10_classification/#project-description","title":"Project description","text":"This project implements an advanced Convolutional Neural Network (CNN) architecture for image classification using the CIFAR-10 dataset. The research focuses on developing and optimizing a deep learning model capable of accurately classifying images across 10 different categories. Through systematic experimentation with various network architectures, data augmentation techniques, and hyperparameter optimization, the project demonstrates how to build a robust Computer Vision system. The implementation leverages TensorFlow and Keras frameworks, applying best practices in CNN design including convolutional layers, pooling operations, batch normalization, and dropout regularization. The project highlights the importance of cross-validation strategies and model evaluation metrics to create a generalizable classification model with high accuracy on unseen data."},{"location":"cifar10_classification/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Implementation of custom CNN architectures for image classification tasks</li> <li>Application of data augmentation techniques to enhance model robustness and prevent overfitting</li> <li>Hyperparameter optimization using RandomSearch to identify optimal model configurations</li> <li>Implementation of K-Fold cross-validation to ensure reliable model evaluation</li> <li>Utilization of early stopping and learning rate scheduling to improve training efficiency</li> <li>Comprehensive model evaluation using confusion matrices, precision, recall, and F1-score</li> <li>Visualization of model performance, feature maps, and classification results</li> <li>Comparative analysis of different model architectures and their performance metrics</li> </ul>"},{"location":"cifar10_classification/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Tensorflow</li> <li>Keras</li> <li>Augmentation</li> <li>CNN</li> <li>RandomSearch</li> <li>Sklearn</li> <li>Numpy</li> <li>KFold</li> <li>LaTeX</li> </ul>"},{"location":"cifar10_classification/#project-report","title":"Project Report","text":"<p>You can download and review the complete project report with detailed methodology and results here: CIFAR-10 Image Classification Report</p>"},{"location":"cifar10_classification/#sample-photos","title":"Sample photos","text":""},{"location":"cv_generator/","title":"CV Generator","text":"<p>Date of creation: 2024-11-06</p>"},{"location":"cv_generator/#project-description","title":"Project description","text":"The goal of this project was to create a CV generator that is easily editable and will allow you to generate information specific to a given company and offer. Using AI will allow you to best match your skills to the position you are applying for. This is to streamline the process of finding your dream job as a Data Scientist."},{"location":"cv_generator/#main-functionalities","title":"Main functionalities","text":"<ul> <li>the user enters information about themselves, the company and directly from the job offer</li> <li>additionally provides the most important skills (programming languages, databases or libraries learned)</li> <li>on this basis an intro is generated, which matches the skills to the individual job offer</li> <li>user can edit AI generated intro</li> <li>then the user can preview the CV content in the application (in Markdown format)</li> <li>finally the user has the option to name and download the CV in PDF format</li> </ul>"},{"location":"cv_generator/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Streamlit</li> <li>HTLM</li> <li>PDFkit</li> <li>Markdown</li> <li>Template</li> </ul>"},{"location":"cv_generator/#sample-photos","title":"Sample photos","text":""},{"location":"fashion_designer/","title":"Fashion Designer","text":"<p>Date of creation: 2024-12-15</p>"},{"location":"fashion_designer/#project-description","title":"Project description","text":"The aim of this project was to create an imitation of a fashion designer. The idea for the project came to me because of the needs of my life partner, who designs women's underwear. This application is to automate the design process and will additionally be an inspiration to create new elements from the world of fashion."},{"location":"fashion_designer/#project-architecture","title":"Project architecture","text":""},{"location":"fashion_designer/#main-functionalities","title":"Main functionalities","text":"<ul> <li>the user selects what type of underwear they want to design</li> <li>the user specifies the initial design concept - then receives visual inspiration generated by AI</li> <li>the user provides the appropriate dimensions</li> <li>the application - using appropriate construction formulas, calculates and saves the parameters related to a specific type of underwear</li> <li>then a construction drawing is created based on the parameters calculated in the previous step, which is then displayed in the application</li> <li>the drawing is properly prepared for printing</li> <li>the user has the option to download the drawing (whole or divided into parts for printing)</li> <li>finally, the AI \u200b\u200bmodel generates recommendations related to the process of creating the element designed by the user</li> </ul>"},{"location":"fashion_designer/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Streamlit</li> <li>Matplotlib</li> <li>PIL</li> <li>Zipfile</li> <li>Requests</li> </ul>"},{"location":"fashion_designer/#sample-photos","title":"Sample photos","text":""},{"location":"features_detective/","title":"Features Detective App","text":"<p>Date of creation: 2024-10-30</p>"},{"location":"features_detective/#project-description","title":"Project description","text":"The aim of the project was to create a universal application that allows for detecting the most important features in a given data set. In short - the user uploads data or loads a ready data set in the appropriate format, then selects automatic detection of the column they want to analyze or makes this selection themselves. Finally, they receive a generated graph of the significance of features that have the greatest impact on the previously selected column. The user also receives a clear description of the graph along with recommendations - what can be improved to, for example, improve the analyzed data."},{"location":"features_detective/#main-functionalities","title":"Main functionalities","text":"<ul> <li>The user can load a CSV/JSON file with data or use a ready-made sample dataset</li> <li>The user indicates the target column -&gt; additionally, they can use automatic column detection (generated by LLM)</li> <li>The application automatically recognizes whether the loaded data is related to the regression or classification problem and selects the appropriate AI model training algorithm on this basis</li> <li>Based on the trained model, a chart containing the most important features is displayed</li> <li>Finally, the user receives a clear description of the chart along with recommendations - what actions to implement to improve the results related to the analyzed target data column</li> </ul>"},{"location":"features_detective/#ml-model-training","title":"ML model training","text":"I used PyCaret tools and I have included the implementation in a notebook ready for download: Download Notebook: Model training"},{"location":"features_detective/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> <li>PyCaret (Classification &amp; Regression)</li> <li>Pandas</li> <li>Matplotlib</li> <li>Instructor</li> <li>Pydantic</li> <li>Boto3</li> </ul>"},{"location":"features_detective/#sample-photos","title":"Sample photos","text":""},{"location":"features_detective/#links","title":"Links","text":"<p>Link to repository</p>"},{"location":"find_friends/","title":"Find Friends App","text":"<p>Data of creation: 2024-10-09</p>"},{"location":"find_friends/#project-description","title":"Project description","text":"The aim of the project was to create an application that would enable the use of a clustering model to match a user to the appropriate group from a loaded data set (data comes from an anonymized survey) - based on data provided by the user."},{"location":"find_friends/#main-functionalities","title":"Main functionalities","text":"<ul> <li>The user filters basic data, such as: age, education, gender, favorite animals, or favorite places - corresponding to their preferences</li> <li>Then the previously trained clustering model creates the appropriate number of clusters for the survey data and matches the user's preferences to the matching group</li> <li>Finally, using LLM, adequate cluster descriptions are generated</li> </ul>"},{"location":"find_friends/#ml-model-training","title":"ML model training","text":"I used Scikit-learn tools and I have included the implementation in a notebook ready for download: Download Notebook: Model training"},{"location":"find_friends/#clusters-naming","title":"Clusters naming","text":"I used the LLM model and I have included the implementation in a notebook ready for dowlonad: Download Notebook: Clusters naming"},{"location":"find_friends/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> <li>Scikit-learn</li> <li>Plotly</li> <li>PyCaret (Clustering)</li> <li>NumPy</li> <li>Matplotlib</li> </ul>"},{"location":"find_friends/#sample-photos","title":"Sample photos","text":""},{"location":"find_friends/#links","title":"Links","text":"<p>Link to repository</p>"},{"location":"halfmarathon_estimator/","title":"Halfmarathon Estimator App","text":"<p>Date of creation: 2024-10-20</p>"},{"location":"halfmarathon_estimator/#project-description","title":"Project description","text":"The aim of the project was to create an application that would use a regression algorithm to train models and would be able to predict (based on previously trained data) the time in which a user would run a half marathon - by providing specific data."},{"location":"halfmarathon_estimator/#main-functionalities","title":"Main functionalities","text":"<ul> <li>allowing the user to enter data freely (without any appropriate conversion of the record) -&gt; the LLM model used extracts data from the user into a JSON structure and prepares it for use by the regression model</li> <li>simple functionality allows for the final estimation of the time to run a half marathon - using the trained best regression model</li> <li>the LLM model is connected to Langfuse to track the model's life cycle</li> </ul>"},{"location":"halfmarathon_estimator/#ml-model-training","title":"ML model training","text":"I used PyCaret tools and I have included the implementation in a notebook ready for download: Download Notebook: Model training"},{"location":"halfmarathon_estimator/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>PyCaret</li> <li>Machine Learning</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> <li>Pandas</li> <li>Instructor</li> <li>Pydantic</li> <li>Dotenv</li> </ul>"},{"location":"halfmarathon_estimator/#sample-photos","title":"Sample photos","text":""},{"location":"halfmarathon_estimator/#links","title":"Links","text":"<p>Link to repository</p>"},{"location":"heweliusz/","title":"Jan Heweliusz Disaster Analysis","text":"<p>Project: March 2024 \u2014 April 2024</p> <p>Role: Data Analyst / Research Engineer</p>"},{"location":"heweliusz/#project-description","title":"Project description","text":"The disaster of the ferry MS Jan Heweliusz (January 14, 1993) was analyzed for years mainly in a descriptive manner, without full reconstruction of meteorological conditions and their impact on vessel stability.  This project aimed to reconstruct the course of the disaster in a data-driven way, based on physics and validatable models.  I conducted a comprehensive meteorological-technical analysis combining:  - ERA5 meteorological reanalyses (ECMWF), - CMEMS wave data, - hydrodynamics and stability laws, - official commission reports and court rulings."},{"location":"heweliusz/#analysis-scope","title":"Analysis Scope","text":""},{"location":"heweliusz/#1-meteorological-conditions","title":"1. Meteorological Conditions","text":"<ul> <li>atmospheric pressure (MSLP)</li> <li>wind speed and direction</li> <li>wave height and energy</li> <li>barometric gradient analysis</li> </ul>"},{"location":"heweliusz/#2-storm-dynamics","title":"2. Storm Dynamics","text":"<ul> <li>identification of explosive cyclogenesis (Bergeron criterion: \u226520 hPa / 24h)</li> <li>rapid escalation of conditions in hours preceding the disaster</li> </ul>"},{"location":"heweliusz/#3-hydrodynamics-and-stability","title":"3. Hydrodynamics and Stability","text":"<ul> <li>Beam Sea wave analysis</li> <li>parametric rolling mechanism</li> <li>escalation of heeling leading to loss of stability</li> </ul>"},{"location":"heweliusz/#4-data-validation","title":"4. Data Validation","text":"<ul> <li>ERA5 vs CMEMS comparison</li> <li>correlation, RMSE, bias</li> <li>reconstruction reliability assessment</li> </ul>"},{"location":"heweliusz/#key-findings","title":"Key Findings","text":""},{"location":"heweliusz/#weather-conditions","title":"Weather Conditions","text":"<ul> <li>Pressure drop of 27 hPa in &lt; 24h</li> <li>Wind up to 24.2 m/s (9\u00b0B \u2013 severe gale)</li> <li>Wave energy increased nearly 5\u00d7 in 6 hours</li> </ul>"},{"location":"heweliusz/#hydrodynamics","title":"Hydrodynamics","text":"<ul> <li>Waves hit the hull at ~60\u00b0 angle</li> <li>Maximum wind force on hull: ~393 kN</li> <li>Vessel remained in Beam Sea zone</li> <li>Heel resonance (parametric rolling)</li> </ul>"},{"location":"heweliusz/#heel-escalation","title":"Heel Escalation","text":"<ul> <li>0\u00b0 \u2192 35\u00b0 in 5h 40min</li> <li>35\u00b0 \u2192 90\u00b0 in 36 minutes</li> </ul>"},{"location":"heweliusz/#validation","title":"Validation","text":"<ul> <li>ERA5 vs CMEMS: r = 0.982</li> <li>R\u00b2 = 0.964</li> <li>Energy differences result from non-linearity (E \u221d H\u00b2), not data errors</li> </ul>"},{"location":"heweliusz/#what-i-did","title":"What I did","text":"<ul> <li>Acquired and processed ERA5 and CMEMS data</li> <li>Performed temporal and spatial analyses</li> <li>Calculated wave energy and forces acting on the vessel</li> <li>Built visualizations of correlation and phenomenon escalation</li> <li>Compared scientific data with commission findings</li> <li>Developed coherent narrative based on data and physics</li> </ul>"},{"location":"heweliusz/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Pandas</li> <li>NumPy</li> <li>xarray</li> <li>ERA5 (ECMWF)</li> <li>CMEMS (Copernicus Marine)</li> <li>Scientific Visualization</li> <li>Data Validation</li> </ul>"},{"location":"heweliusz/#results","title":"Results","text":"<ul> <li>Quantitative reconstruction of disaster mechanism</li> <li>Confirmation of convergence of extreme weather phenomena and technical-operational errors</li> <li>High analysis reliability through source validation</li> <li>Example of Data Science application to historical event analysis</li> </ul>"},{"location":"heweliusz/#conclusions","title":"Conclusions","text":"The MS Jan Heweliusz disaster was a systemic culmination of:  - severe storm (9\u00b0B), - beam sea waves, - rapid cyclogenesis, - improper vessel preparation for the voyage.  The project demonstrates how data analysis, physics, and model validation enable understanding complex events in an objective and replicable way."},{"location":"heweliusz/#sample-photos","title":"Sample photos","text":""},{"location":"iris/","title":"Domain exploration (EDA) of the dataset: Irises","text":"<p>Date of creation: 2024-08-25</p>"},{"location":"iris/#introduction","title":"Introduction","text":"I invite you to familiarize yourself with my project, which takes us into the world of data analysis on Irises - using domain exploration (EDA). In this project, you will find many pertinent conclusions and interesting observations that shed new light on these beautiful flowers. Prepare yourself for a fascinating journey through data, which will certainly enrich your knowledge and inspire you to further research."},{"location":"iris/#project-download","title":"Project download","text":"<p>Download Notebook Open in new tab \u2197</p>"},{"location":"iris/#notebook-preview","title":"Notebook preview","text":""},{"location":"justjoinit_browser/","title":"JustJoinIT Browser","text":"<p>Project start: 2025-02-19</p>"},{"location":"justjoinit_browser/#project-description","title":"Project description","text":"JustJoinIT Browser is a Streamlit application designed for interactive browsing of the latest job offers from the JustJoinIT platform. The project involved using the Requests library to scrape job listings data, followed by exploratory data analysis (EDA) to understand the domain and categories available on JustJoinIT. The data was then processed into a suitable CSV format, which served as the foundation for building a user-friendly interface. The application leverages Geopandas to implement an interactive map of Polish voivodeships, enabling intuitive geolocation-based filtering of job opportunities. In the future the application will be developed with AI algorithms."},{"location":"justjoinit_browser/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Custom browsing of IT job offers with flexible interface customization</li> <li>Interactive map visualization for geographical filtering by regions</li> <li>Multiple filtering options based on technology, experience level, and job type</li> <li>Data visualization with charts and statistics to better understand the job market</li> <li>User-defined sorting and prioritization of job listings</li> </ul>"},{"location":"justjoinit_browser/#eda","title":"EDA","text":"I conducted a detailed exploratory data analysis (EDA) using Pandas for data analysis, as well as Plotly, Matplotlib, and Seaborn for data visualization. Below you can find files available for download containing the full analysis and the dataset: Download Notebook: Exploratory Analysis Download CSV: Job Offers"},{"location":"justjoinit_browser/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Requests</li> <li>Pandas</li> <li>Geopandas</li> <li>Shapely</li> <li>Folium</li> <li>Streamlit</li> <li>Plotly</li> <li>Pathlib</li> <li>EDA</li> </ul>"},{"location":"justjoinit_browser/#sample-photos","title":"Sample photos","text":""},{"location":"knowledge_seeker/","title":"Knowledge Seeker","text":"<p>Project start: April 2025 \u2014 Present</p> <p>Role: AI / ML Engineer (Project Leader)</p> <p>Status: Production</p>"},{"location":"knowledge_seeker/#project-description","title":"Project description","text":"Knowledge Seeker is an advanced tool for transcription, indexing, and information retrieval from video recordings.  Users with access to large video resources (courses, trainings, mentoring sessions) had difficulty quickly finding specific information. Manually searching through hundreds of materials was time-consuming and inefficient.  As the project leader, I coordinate the development of a system utilizing the latest AI technologies for speech-to-text processing and implementation of advanced semantic search mechanisms.  The application enables users not only to find specific information in extensive video resources but also to generate responses to queries based on accumulated knowledge using the RAG (Retrieval-Augmented Generation) architecture."},{"location":"knowledge_seeker/#solution","title":"Solution","text":"I designed a system based on RAG (Retrieval-Augmented Generation) architecture, combining automatic video transcription, semantic search in a vector database, and response generation through language models."},{"location":"knowledge_seeker/#architecture","title":"Architecture","text":""},{"location":"knowledge_seeker/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Transcription of video recordings to text with preservation of time metadata (timestamps)</li> <li>Processing transcriptions through chunking and generating embeddings</li> <li>Vector database for storing and efficiently searching embeddings</li> <li>User interface enabling both simple and semantic content searching</li> <li>RAG (Retrieval-Augmented Generation) system for generating responses to user queries</li> <li>Deployment in Digital Ocean cloud ensuring scalability and availability</li> <li>Data export in JSON formats and streaming capability to user API</li> </ul>"},{"location":"knowledge_seeker/#what-i-did","title":"What I did","text":"<ol> <li>Designed the system architecture and data processing pipeline</li> <li>Implemented audio \u2192 text transcription using Whisper</li> <li>Developed document chunking and embedding generation</li> <li>Configured Qdrant vector database</li> <li>Built backend API in FastAPI</li> <li>Created user interface in Streamlit</li> <li>Deployed the system in DigitalOcean cloud (Docker)</li> </ol>"},{"location":"knowledge_seeker/#development-roadmap","title":"Development Roadmap","text":"<ul> <li>Integration with additional data sources (documents, presentations, audio)</li> <li>Enhancement of RAG mechanisms with advanced filtering and re-ranking techniques</li> <li>Implementation of components for automatic verification and updating of the knowledge base</li> <li>Optimization of indexing and search processes for larger datasets</li> <li>Development of API interface enabling integration with external applications</li> </ul>"},{"location":"knowledge_seeker/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Whisper</li> <li>Qdrant</li> <li>FastAPI</li> <li>Streamlit</li> <li>Docker</li> <li>DigitalOcean</li> <li>LLM (Large Language Models)</li> <li>Natural Language Processing</li> <li>Vector Databases</li> <li>RAG (Retrieval-Augmented Generation)</li> <li>Microservice Architecture</li> </ul>"},{"location":"knowledge_seeker/#results","title":"Results","text":"<ul> <li>400+ video recordings searchable in real-time</li> <li>Reduced information finding time from minutes to seconds</li> <li>Production-ready, scalable AI system</li> </ul>"},{"location":"larvixon_ai/","title":"Larvixon-AI","text":"<p>Project start: April 2025 \u2014 Present</p> <p>Role: AI / Computer Vision Engineer</p> <p>Collaboration: Medical University of Wroc\u0142aw</p>"},{"location":"larvixon_ai/#project-description","title":"Project description","text":"<p>Larvixon-AI is a system based on computer vision and deep learning that automatically analyzes movement behaviors of Galleria mellonella larvae after injection of selected bacterial pathogens.</p> <p>Sepsis is one of the most serious problems in modern medicine, and rapid pathogen identification is crucial for implementing appropriate therapy. Classic diagnostic methods:</p> <ul> <li>are time-consuming (24\u201372 hours),</li> <li>require advanced laboratory facilities,</li> <li>don't always allow for quick clinical decisions.</li> </ul> <p>The Galleria mellonella model enables observation of behavioral changes after infection. However, previous analysis was manual, difficult to standardize, and limited in scalability.</p> <p>The project is carried out as a master's thesis in collaboration with the Medical University of Wroc\u0142aw.</p>"},{"location":"larvixon_ai/#how-it-works","title":"How It Works","text":"<p>Larvixon-AI is a video analysis pipeline:</p> <ul> <li>Video ingestion \u2014 HD recordings (25 FPS), various lighting conditions</li> <li>Computer Vision layer \u2014 object detection (larvae), segmentation and masking, position tracking across frames</li> <li>Analysis layer \u2014 trajectory calculation, distance, speed, directions, activity heat maps</li> <li>Data &amp; visualization \u2014 CSV export, statistical analysis, result visualizations</li> </ul> <p>The architecture is prepared for further integration with deep learning models.</p>"},{"location":"larvixon_ai/#what-i-did","title":"What I did","text":"<ul> <li>Designed the algorithm for larvae detection and tracking in video</li> <li>Implemented image processing pipeline in OpenCV</li> <li>Handled different lighting variants (top / bottom)</li> <li>Calculated trajectories and kinematic movement parameters</li> <li>Conducted comparative analysis of groups:<ul> <li>control</li> <li>PBS</li> <li>E. coli infected (various concentrations)</li> </ul> </li> <li>Automated data export and visualization generation</li> <li>Analyzed results for behavioral differences</li> </ul>"},{"location":"larvixon_ai/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenCV</li> <li>Deep Learning</li> <li>Computer Vision</li> <li>NumPy</li> <li>Pandas</li> <li>Scientific Computing</li> <li>Video Processing</li> </ul>"},{"location":"larvixon_ai/#key-results","title":"Key Results","text":"<ul> <li>100% movement detection accuracy</li> <li>Real-time video processing (25 FPS)</li> <li>Significant differences between groups:</li> <li>control larvae: ~5 mm/s</li> <li>infected larvae: ~2.3 mm/s (high concentrations)</li> <li>Clear differences in:</li> <li>traveled distances</li> <li>spatial activity distribution</li> <li>movement patterns</li> </ul>"},{"location":"larvixon_ai/#impact-future-work","title":"Impact &amp; Future Work","text":"<p>Larvixon-AI provides a foundation for further research on:</p> <ul> <li>automatic identification of septic pathogens,</li> <li>accelerating infection diagnostics,</li> <li>using deep learning in behavioral analysis.</li> </ul> <p>The project connects AI engineering with biomedical research and bridges science with practical clinical applications.</p>"},{"location":"my_chatbot/","title":"My Chatbot App","text":"<p>Date of creation: 2024-09-15</p>"},{"location":"my_chatbot/#project-description","title":"Project description","text":"The aim of the project was to create own version of Chat GPT, based on the Streamlit application interface. The chatbot can take on any personality to maximize its functionality to our preferences."},{"location":"my_chatbot/#main-functionalities","title":"Main functionalities","text":"<ul> <li>the chatbot remembers conversations and saves them in a JSON file structure, and you can easily switch between conversations (without losing your chat history)</li> <li>you can choose between various models from OpenAI</li> <li>the costs of using AI are counted</li> <li>you can give the chatbot individual awareness that will guide the types of answers to the questions asked</li> </ul>"},{"location":"my_chatbot/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> </ul>"},{"location":"my_chatbot/#sample-photos","title":"Sample photos","text":""},{"location":"my_chatbot/#application-usage","title":"Application usage","text":"The application has been deployed on the Streamlit Community App helps me explore the secrets of AI and expand my programming skills on a daily basis."},{"location":"quality_management_system/","title":"Quality Management System","text":"<p>Project: February 2024 \u2014 August 2024</p> <p>Role: Data / AI Engineer</p>"},{"location":"quality_management_system/#project-description","title":"Project description","text":"<p>In industrial organizations, quality and technical data are often scattered across multiple sources:</p> <ul> <li>quality reports in Excel,</li> <li>technical documentation in PDF,</li> <li>process instructions in various locations,</li> <li>corrective action history in separate files.</li> </ul> <p>As a result:</p> <ul> <li>finding the right document takes too much time,</li> <li>data is inconsistent and difficult to compare,</li> <li>there's no single place for quality analysis and decisions,</li> <li>organizational knowledge is heavily dependent on specific people.</li> </ul> <p>I designed the Quality Management System (QMS), whose main goal was to create one central source of truth for quality data and technical knowledge.</p>"},{"location":"quality_management_system/#solution","title":"Solution","text":"<p>The system combines:</p> <ul> <li>classic QMS (reports, actions, metrics),</li> <li>Knowledge Management layer,</li> <li>semantic search enabling natural language queries.</li> </ul> <p>Everything was delivered as a Streamlit application serving as an operational quality dashboard.</p>"},{"location":"quality_management_system/#architecture-overview","title":"Architecture Overview","text":"<p>QMS was designed as a system integrating multiple data sources:</p> <ul> <li>Data ingestion \u2014 import from PDF and Excel files, normalization and standardization</li> <li>Central database \u2014 relational database as single source of truth, unified quality data models</li> <li>Knowledge layer \u2014 document content extraction, embeddings and semantic index</li> <li>Application layer \u2014 Streamlit as user interface, dashboards, reports, search</li> </ul> <p>The architecture was designed with:</p> <ul> <li>ERP / CRM integration in mind,</li> <li>future expansion with additional AI modules.</li> </ul>"},{"location":"quality_management_system/#key-features","title":"Key Features","text":""},{"location":"quality_management_system/#intelligent-semantic-search","title":"Intelligent Semantic Search","text":"<ul> <li>search drawings, instructions, and reports</li> <li>natural language queries</li> <li>no need to know folder structure</li> </ul>"},{"location":"quality_management_system/#centralized-standardized-data","title":"Centralized &amp; Standardized Data","text":"<ul> <li>all quality data in one place</li> <li>consistent formats and current document versions</li> <li>elimination of duplicates and outdated files</li> </ul>"},{"location":"quality_management_system/#automated-reporting-analytics","title":"Automated Reporting &amp; Analytics","text":"<ul> <li>quality dashboards</li> <li>corrective action statuses</li> <li>quick quality KPI overview</li> </ul>"},{"location":"quality_management_system/#integration-ready-architecture","title":"Integration-Ready Architecture","text":"<ul> <li>preparation for ERP / CRM integration</li> <li>modular data structure</li> <li>readiness for further AI systems</li> </ul>"},{"location":"quality_management_system/#what-i-did","title":"What I did","text":"<ol> <li>Analyzed existing quality data sources</li> <li>Designed unified data model</li> <li>Implemented data import and transformation from PDF and Excel</li> <li>Created central database as single source of truth</li> <li>Built semantic search layer over documentation</li> <li>Developed quality dashboard in Streamlit</li> <li>Automated reporting and action monitoring</li> <li>Prepared architecture for future integrations and AI</li> </ol>"},{"location":"quality_management_system/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Streamlit</li> <li>PostgreSQL</li> <li>Pandas</li> <li>SQL</li> <li>PDF Processing</li> <li>Excel Processing</li> <li>Semantic Search</li> <li>Embeddings</li> <li>Machine Learning</li> <li>Computer Vision</li> <li>Docker</li> </ul>"},{"location":"quality_management_system/#results","title":"Results","text":"<ul> <li>Reduced document search time by up to 70%</li> <li>One consistent source of quality data</li> <li>Better process and action history transparency</li> <li>Faster quality decision-making</li> <li>Improved collaboration between:</li> <li>production</li> <li>quality</li> <li>procurement</li> <li>Solid foundation for further AI system development in the organization</li> </ul>"},{"location":"robinson_chatbot/","title":"Robinson Chatbot","text":"<p>Project start: 2025-01-31</p>"},{"location":"robinson_chatbot/#project-description","title":"Project description","text":"The Robinson Chatbot project explores the implementation of Retrieval-Augmented Generation (RAG) techniques to create an intelligent conversational agent knowledgeable about \"Robinson Crusoe.\" The system combines state-of-the-art language models from both OpenAI and Amazon Bedrock with advanced text retrieval methods to provide accurate, contextually relevant answers based on the novel's content. Through extensive experimentation with various chunking strategies, embedding models, and prompt engineering techniques, the project demonstrates how RAG architectures can effectively enhance LLM capabilities for domain-specific applications while minimizing hallucinations and improving factual accuracy."},{"location":"robinson_chatbot/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Implementation of various text chunking methods (e.g. by paragraphs, fixed token size, by chapters) to optimize information retrieval</li> <li>Experimentation with different embedding models to create semantic vector representations</li> <li>Advanced similarity search using FAISS vector database for efficient information retrieval</li> <li>Comparison of performance between OpenAI models (gpt-4o and gpt-4o-mini) and Amazon Bedrock models (Amazon Titan Text Express V1 and Amazon Titan Text Embeddings E1)</li> <li>Prompt engineering techniques to optimize context utilization and response quality</li> <li>Interactive Streamlit application for user-friendly chatbot interaction about Robinson Crusoe</li> <li>Comprehensive evaluation framework to measure accuracy, relevance, and coherence of responses</li> </ul>"},{"location":"robinson_chatbot/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Amazon Bedrock</li> <li>AWS</li> <li>Numpy</li> <li>Faiss</li> <li>RAG</li> <li>Boto3</li> <li>Nltk</li> <li>Streamlit</li> <li>Prompt Engineerning</li> <li>Embeddings</li> <li>LaTeX</li> </ul>"},{"location":"robinson_chatbot/#project-report","title":"Project Report","text":"<p>You can download and review the complete project report with detailed methodology and results here: Robinson Chatbot - RAG Implementation Report</p>"},{"location":"robinson_chatbot/#sample-photos","title":"Sample photos","text":""},{"location":"student_profiler/","title":"Student Profiler","text":"<p>Project: March 2025 \u2014 June 2025</p> <p>Role: Backend / Data Engineer</p> <p>Company: GOTOIT sp. z o.o.</p> <p>Status: Production</p>"},{"location":"student_profiler/#project-description","title":"Project description","text":"Mentors and course instructors lacked a tool for systematic monitoring of student activity on Discord.  Analysis of engagement, work regularity, and interaction history:  - was scattered across many channels, - required manual message review, - provided no basis for automatic conclusions or scaling the mentoring process.  There was no single, central system for collecting and analyzing data.  I designed and developed Student Profiler \u2014 a tool for automatic monitoring of student activity in the Discord environment."},{"location":"student_profiler/#solution","title":"Solution","text":"The core of the system is a Discord Bot that:  - fetches historical data from channels, - listens for new messages and events in real-time, - saves data in a relational database, - feeds the analytical layer and user interface.  The architecture is prepared for further development of AI-based features (humanized mentor bot, sentiment analysis, OCR, predictive models)."},{"location":"student_profiler/#architecture","title":"Architecture","text":""},{"location":"student_profiler/#main-functionalities","title":"Main functionalities","text":"<ul> <li>Discord Bot integration for monitoring activity and automated messaging</li> <li>Scheduled hourly data collection from Discord channels</li> <li>Data storage system using PostgreSQL for messages and Digital Ocean Spaces for attachments</li> <li>Streamlit-based UI for easy access and analysis of Discord data</li> <li>Scalable architecture with future implementation plans for AI features</li> </ul>"},{"location":"student_profiler/#what-i-did","title":"What I did","text":"<ol> <li>Designed system architecture following Single Responsibility Principle</li> <li>Implemented Discord Bot for:</li> <li>fetching message history</li> <li>listening for new events</li> <li>handling automated responses</li> <li>Created hourly data collection scheduler</li> <li>Designed and deployed PostgreSQL database</li> <li>Integrated DigitalOcean Spaces for attachment storage</li> <li>Built analytical UI in Streamlit with Plotly visualizations</li> <li>Prepared Docker environment for local and cloud deployment</li> <li>Implemented application configuration using pydantic-settings</li> </ol>"},{"location":"student_profiler/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Discord API</li> <li>PostgreSQL</li> <li>Streamlit</li> <li>Docker</li> <li>DigitalOcean</li> <li>Pandas</li> <li>SQL</li> <li>Plotly</li> <li>Psycopg</li> <li>Requests</li> <li>Schedule</li> <li>Pydantic-settings</li> <li>SRP design</li> </ul>"},{"location":"student_profiler/#results","title":"Results","text":"<ul> <li>Central data source for student activity on Discord</li> <li>Automatic and regular data collection without manual mentor intervention</li> <li>Clear dashboard for engagement and trend analysis</li> <li>Stable foundation for further AI feature development:</li> <li>communication sentiment analysis</li> <li>student activity drop prediction</li> <li>humanized mentor bot</li> </ul>"},{"location":"student_profiler/#sample-photos","title":"Sample photos","text":""},{"location":"titanic/","title":"Domain exploration (EDA) of the dataset: Titanic","text":"<p>Date of creation: 2024-08-25</p>"},{"location":"titanic/#introduction","title":"Introduction","text":"I invite you to familiarize yourself with my project, which takes us into the world of data analysis regarding the world-famous Titanic disaster. In order to explore the information, I use domain exploration (EDA). In this project, you will find many relevant conclusions and interesting observations. Prepare yourself for an interesting journey with data that will broaden your horizons of looking at one of the greatest maritime disasters in history."},{"location":"titanic/#project-download","title":"Project download","text":"<p>Download Notebook Open in new tab \u2197</p>"},{"location":"titanic/#notebook-preview","title":"Notebook preview","text":""},{"location":"welcome_survey/","title":"Welcome Survey App","text":"<p>Date of creation: 2024-09-22</p>"},{"location":"welcome_survey/#project-description","title":"Project description","text":"The aim of the project was to create an application that would allow for simple filtering and browsing of data from a sample welcome survey (the data was appropriately anonymized). The aim of the application was to consolidate components from the Streamlit library and familiarize users with the proper management of the application state (<code>st.session_state</code>) so that all buttons and interactions were responsive to each other."},{"location":"welcome_survey/#main-functionalities","title":"Main functionalities","text":"<ul> <li>the ability to browse an anonymous survey to familiarize yourself with the Streamlit interface</li> <li>various types of filters allow you to get to know the analyzed data in more detail</li> <li>visualizations are also included</li> <li>the application also contains interesting visualizations and for the most persistent - curiosities await!</li> </ul>"},{"location":"welcome_survey/#skills","title":"Skills","text":"<ul> <li>Python</li> <li>Pandas</li> <li>Matplotlib</li> <li>Seaborn</li> <li>Streamlit</li> <li>Boto3</li> </ul>"},{"location":"welcome_survey/#sample-photos","title":"Sample photos","text":""},{"location":"pl/","title":"Strona g\u0142\u00f3wna","text":"Kasjan \u015amigielski AWS ML Engineer &amp; Data Scientist"},{"location":"pl/#o-mnie","title":"O mnie","text":"<p>Jestem in\u017cynierem AI i Data Scientistem specjalizuj\u0105cym si\u0119 w projektowaniu inteligentnych system\u00f3w opartych o dane \u2014 od analizy danych i EDA, przez modele Machine Learning i Computer Vision, po produkcyjne architektury LLM oraz systemy RAG.</p> <p>\u0141\u0105cz\u0119 do\u015bwiadczenie in\u017cynierskie z przemys\u0142u z nowoczesnymi technologiami AI, buduj\u0105c rozwi\u0105zania, kt\u00f3re:</p> <ul> <li>rozwi\u0105zuj\u0105 realne problemy biznesowe i badawcze,</li> <li>s\u0105 skalowalne i gotowe do pracy produkcyjnej,</li> <li>\u0142\u0105cz\u0105 AI z solidn\u0105 in\u017cynieri\u0105 oprogramowania.</li> </ul>"},{"location":"pl/#moja-droga-zawodowa","title":"Moja droga zawodowa","text":"<p>W 2019 roku uko\u0144czy\u0142em studia na kierunku Mechatronika na Politechnice Wroc\u0142awskiej. Przez kolejne lata pracowa\u0142em jako in\u017cynier w przemy\u015ble produkcyjnym, gdzie dane jako\u015bciowe i procesowe odgrywa\u0142y kluczow\u0105 rol\u0119 w optymalizacji proces\u00f3w i podejmowaniu decyzji.</p> <p>Praca z rzeczywistymi danymi przemys\u0142owymi:</p> <ul> <li>rozbudzi\u0142a moje zainteresowanie analiz\u0105 danych,</li> <li>nauczy\u0142a mnie my\u015blenia systemowego,</li> <li>pokaza\u0142a znaczenie jako\u015bci danych i kontekstu biznesowego.</li> </ul> <p>Naturalnym krokiem by\u0142o przej\u015bcie w stron\u0119 Data Science i AI.</p>"},{"location":"pl/#aktualny-fokus","title":"Aktualny fokus","text":"<p>Uko\u0144czy\u0142em \u015bcie\u017ck\u0119 Data Scientist i rozpocz\u0105\u0142em systematyczne budowanie portfolio projekt\u00f3w obejmuj\u0105cych:</p> <ul> <li>eksploracj\u0119 danych (EDA),</li> <li>aplikacje analityczne w Streamlit,</li> <li>systemy Machine Learning i Deep Learning,</li> <li>rozwi\u0105zania oparte o LLM i semantic search.</li> </ul> <p>Obecnie pracuj\u0119 przy projektach z obszaru:</p> <ul> <li>Machine Learning i Deep Learning</li> <li>Computer Vision</li> <li>Integracja LLM i RAG</li> <li>AI w \u015brodowisku produkcyjnym</li> </ul> <p>Posiadam certyfikat AWS Machine Learning Engineer \u2013 Associate, co potwierdza moje kompetencje w zakresie projektowania i wdra\u017cania rozwi\u0105za\u0144 ML w chmurze.</p>"},{"location":"pl/#nauczanie-i-mentoring","title":"\ud83c\udf93 Nauczanie i mentoring","text":"<p>Od stycznia 2025 roku pe\u0142ni\u0119 rol\u0119 Student Success Managera w Gotoit, gdzie mentoruj\u0119 kurs Data Science. Prowadz\u0119 cotygodniowe sesje live, podczas kt\u00f3rych poszerzamy wiedz\u0119 z zakresu danych i AI.</p> <p>Dodatkowo prowadz\u0119 zaj\u0119cia i warsztaty dla:</p> <ul> <li>Kursant\u00f3w Data Science \u2014 Python, SQL, EDA, Machine Learning, Deep Learning</li> <li>Uczni\u00f3w szk\u00f3\u0142 \u015brednich (profil IT) \u2014 praktyczne zastosowania AI</li> <li>Nauczycieli i kadry pedagogicznej \u2014 odpowiedzialne i praktyczne wykorzystanie AI</li> </ul> <p>Moja filozofia nauczania skupia si\u0119 na zrozumieniu, nie zapami\u0119tywaniu, realnych przypadkach zamiast sztucznych dataset\u00f3w oraz krytycznym my\u015bleniu o AI zamiast hype'u.</p>"},{"location":"pl/#aktywnosc-akademicka","title":"\ud83d\udcda Aktywno\u015b\u0107 akademicka","text":"<p>W marcu 2025 roku rozpocz\u0105\u0142em studia magisterskie na kierunku Sztuczna Inteligencja i Uczenie Maszynowe.</p> <p>Moja praca magisterska koncentruje si\u0119 na:</p> <ul> <li>zastosowaniu computer vision,</li> <li>analizie zachowa\u0144 obiekt\u00f3w w materiale wideo,</li> <li>wykorzystaniu algorytm\u00f3w ML i DL w badaniach biomedycznych.</li> </ul> <p>Projekt realizowany jest we wsp\u00f3\u0142pracy z Uniwersytetem Medycznym we Wroc\u0142awiu.</p>"},{"location":"pl/#o-tym-portfolio","title":"O tym portfolio","text":"<p>Znajdziesz tutaj wiele projekt\u00f3w, nad kt\u00f3rymi pracowa\u0142em ostatnio: od eksploracji danych (EDA) na gotowych zbiorach danych, przez tworzenie aplikacji Streamlit pozwalaj\u0105cych przegl\u0105da\u0107 dane w prosty spos\u00f3b, a\u017c po aplikacje oparte na AI i Machine Learning \u2014 do znajdowania wzorc\u00f3w niewidocznych na pierwszy rzut oka.</p> <p>Zach\u0119cam do regularnych odwiedzin \u2014 zamierzam na bie\u017c\u0105co rozszerza\u0107 moje portfolio o nowe pomys\u0142y.</p>"},{"location":"pl/ainnouncer_studio/","title":"AInnouncer Studio","text":"<p>Start projektu: pa\u017adziernik 2025 \u2014 obecnie</p> <p>Rola: Tech Lead / AI Engineer</p>"},{"location":"pl/ainnouncer_studio/#opis-projektu","title":"Opis projektu","text":"<p>AInnouncer Studio to kompleksowa platforma AI do automatycznego generowania tre\u015bci audio dla stacji radiowych, zbudowana na profesjonalnej architekturze LLMs i LLOps.</p> <p>Stacje radiowe potrzebuj\u0105 regularnych, profesjonalnych tre\u015bci audio: prognoz pogody, zapowiedzi muzycznych, komunikat\u00f3w antenowych czy materia\u0142\u00f3w reklamowych. Proces ten jest czasoch\u0142onny, kosztowny, trudny do skalowania i silnie zale\u017cny od ludzi.</p> <p>System \u0142\u0105czy:</p> <ul> <li>generowanie tekstu (LLM),</li> <li>syntez\u0119 mowy (TTS),</li> <li>miksowanie audio (broadcast-ready),</li> <li>automatyzacj\u0119,</li> <li>monitoring i kontrol\u0119 jako\u015bci.</li> </ul> <p>Platforma zosta\u0142a zaprojektowana jako skalowalny SaaS, gotowy na wielu klient\u00f3w i dodatkowe modu\u0142y.</p>"},{"location":"pl/ainnouncer_studio/#architektura","title":"Architektura","text":"<p>AInnouncer Studio to architektura event-driven + worker-based:</p> <ul> <li>Frontend (Next.js) \u2014 konfiguracja modu\u0142\u00f3w, prompt\u00f3w, g\u0142os\u00f3w, harmonogram\u00f3w</li> <li>Backend API (FastAPI) \u2014 logika domenowa, routing, walidacja, orchestracja</li> <li>Asynchroniczni workerzy (Dramatiq + Redis) \u2014 generowanie tre\u015bci, TTS, miksowanie, upload</li> <li>Warstwa LLM \u2014 OpenAI GPT-4o / GPT-4o-mini z zaawansowanymi promptami systemowymi</li> <li>LLOps &amp; Observability \u2014 Langfuse (traces, spans, koszt, jako\u015b\u0107), wersjonowanie prompt\u00f3w, Promptfoo (testy prompt\u00f3w)</li> <li>Warstwa danych \u2014 PostgreSQL (konfiguracje, prompty, g\u0142osy, harmonogramy), storage S3-compatible (audio)</li> <li>Infrastruktura \u2014 Docker Compose, CI/CD, Monitoring (Prometheus + Grafana)</li> </ul>"},{"location":"pl/ainnouncer_studio/#kluczowe-moduy","title":"Kluczowe modu\u0142y","text":""},{"location":"pl/ainnouncer_studio/#prognoza-pogody-produkcja","title":"Prognoza pogody (Produkcja)","text":"<ul> <li>dane pogodowe \u2192 tekst LLM \u2192 g\u0142os TTS \u2192 miks z jinglem \u2192 upload</li> <li>obs\u0142uga wielu lokalizacji i j\u0119zyk\u00f3w</li> <li>harmonogramy emisji</li> </ul>"},{"location":"pl/ainnouncer_studio/#ainnouncer-dj-zapowiedzi-muzyczne","title":"AInnouncer (DJ / Zapowiedzi muzyczne)","text":"<ul> <li>parsowanie playlist (.mix)</li> <li>batchowe generowanie tekst\u00f3w</li> <li>kontrola cz\u0119stotliwo\u015bci zapowiedzi</li> <li>audio gotowe do wpi\u0119cia w automat emisyjny</li> </ul>"},{"location":"pl/ainnouncer_studio/#platform-core-llops","title":"Platform Core (LLOps)","text":"<ul> <li>wersjonowanie prompt\u00f3w</li> <li>monitoring jako\u015bci odpowiedzi</li> <li>analiza koszt\u00f3w LLM</li> <li>retry &amp; fallback logic</li> <li>przygotowanie pod agent\u00f3w AI</li> </ul>"},{"location":"pl/ainnouncer_studio/#co-zrobiem","title":"Co zrobi\u0142em","text":"<ol> <li>Zaprojektowa\u0142em pe\u0142n\u0105 architektur\u0119 systemu AI w produkcji</li> <li>Zbudowa\u0142em backend w FastAPI z rozdzieleniem odpowiedzialno\u015bci</li> <li>Zaimplementowa\u0142em asynchroniczne pipeline'y (Dramatiq)</li> <li>Stworzy\u0142em warstw\u0119 LLM z kontrol\u0105 prompt\u00f3w i walidacj\u0105</li> <li>Zintegrowa\u0142em Langfuse do observability i monitoringu LLM</li> <li>Wdro\u017cy\u0142em Promptfoo do testowania prompt\u00f3w</li> <li>Zbudowa\u0142em system TTS i miksowania audio pod standardy radiowe</li> <li>Zaprojektowa\u0142em CI/CD oraz \u015brodowisko chmurowe</li> <li>Przygotowa\u0142em platform\u0119 pod dalszy rozw\u00f3j agent\u00f3w AI</li> </ol>"},{"location":"pl/ainnouncer_studio/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>FastAPI</li> <li>OpenAI GPT-4o</li> <li>ElevenLabs TTS</li> <li>Langfuse</li> <li>Promptfoo</li> <li>PostgreSQL</li> <li>Redis</li> <li>Dramatiq</li> <li>Docker</li> <li>DigitalOcean</li> <li>Next.js</li> <li>TypeScript</li> <li>Prometheus</li> <li>Grafana</li> </ul>"},{"location":"pl/ainnouncer_studio/#rezultaty","title":"Rezultaty","text":"<ul> <li>W pe\u0142ni automatyczne generowanie tre\u015bci audio gotowych do emisji</li> <li>Stabilna, produkcyjna architektura AI (nie demo)</li> <li>Pe\u0142na kontrola nad jako\u015bci\u0105 i kosztami LLM</li> <li>System gotowy do skalowania jako produkt SaaS</li> <li>Solidna baza pod:</li> <li>agent\u00f3w AI</li> <li>kolejne modu\u0142y (reklamy, traffic, voice branding)</li> <li>ekspansj\u0119 mi\u0119dzynarodow\u0105</li> </ul>"},{"location":"pl/ainnouncer_studio/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/audio_notes/","title":"Audio Notes App","text":"<p>Data utworzenia: 2024-10-03</p>"},{"location":"pl/audio_notes/#opis-projektu","title":"Opis projektu","text":"<p>Celem projektu by\u0142o stworzenie pierwszej aplikacji opartej o AI. W tym celu wykorzysta\u0142em dwa modele LLM od OpenAI: <code>whisper-1</code> (mowa -&gt; tekst) i <code>text-embeddings-3-large</code> (tekst -&gt; embeddingi).</p>"},{"location":"pl/audio_notes/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>Nagrywanie i ods\u0142uchiwanie notatek g\u0142osowych</li> <li>Transkrypcja g\u0142osu na tekst przy u\u017cyciu AI</li> <li>Mo\u017cliwo\u015b\u0107 zbierania notatek w bazie danych Qdrant</li> <li>Semantyczne wyszukiwanie danych przy u\u017cyciu algorytmu przetwarzania tekstu na embeddingi i znajdowania podobie\u0144stw na podstawie Cosinus Similarity</li> </ul>"},{"location":"pl/audio_notes/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>Qdrant</li> <li>OpenAI embeddings</li> <li>OpenAI whisper-1</li> <li>Streamlit</li> <li>Dotenv</li> <li>PyDub</li> <li>io</li> <li>md5</li> </ul>"},{"location":"pl/audio_notes/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/audio_notes/#wykorzystanie-aplikacji","title":"Wykorzystanie aplikacji","text":"<p>Aplikacja zosta\u0142a wdro\u017cona na Streamlit Community App i pomaga mi \u0142atwiej generowa\u0107 notatki, a co najwa\u017cniejsze umo\u017cliwia kontekstowe wyszukiwanie przy u\u017cyciu AI.</p> <p>Link do repozytorium</p>"},{"location":"pl/b_roll_assistant/","title":"B-Roll Assistant","text":"<p>Start projektu: listopad 2025 \u2014 obecnie</p> <p>Rola: AI / Backend Engineer</p>"},{"location":"pl/b_roll_assistant/#opis-projektu","title":"Opis projektu","text":"<p>B-Roll Assistant to inteligentny asystent AI, kt\u00f3ry automatycznie kataloguje materia\u0142y wideo i umo\u017cliwia ich natychmiastowe wyszukiwanie.</p> <p>W newsroomach i \u015brodowiskach produkcji wideo czas jest kluczowy. Redaktorzy i monta\u017cy\u015bci musz\u0105 b\u0142yskawicznie znale\u017a\u0107 odpowiedni B-roll, cz\u0119sto pod presj\u0105 deadline'\u00f3w. W praktyce:</p> <ul> <li>materia\u0142y wideo s\u0105 s\u0142abo opisane lub wcale,</li> <li>nazwy plik\u00f3w s\u0105 niejednoznaczne,</li> <li>r\u0119czne tagowanie jest kosztowne i nierealne,</li> <li>klasyczne wyszukiwanie po folderach nie skaluje si\u0119.</li> </ul> <p>System:</p> <ul> <li>analizuje wideo bez ingerencji u\u017cytkownika,</li> <li>generuje snapshoty i opisy uj\u0119\u0107 przy u\u017cyciu AI,</li> <li>\u0142\u0105czy wyszukiwanie klasyczne z semantic search,</li> <li>uczy si\u0119 na podstawie ocen redaktor\u00f3w.</li> </ul> <p>Dzi\u0119ki temu redaktor nie musi wiedzie\u0107 jak nazwano plik \u2014 wystarczy opisa\u0107 to, czego szuka.</p>"},{"location":"pl/b_roll_assistant/#jak-to-dziaa","title":"Jak to dzia\u0142a","text":""},{"location":"pl/b_roll_assistant/#1-smart-catalog-setup","title":"1. Smart Catalog Setup","text":"<ul> <li>System adaptuje si\u0119 do istniej\u0105cej struktury plik\u00f3w</li> <li>Nie wymaga r\u0119cznego porz\u0105dkowania materia\u0142\u00f3w</li> <li>Obs\u0142uguje du\u017ce archiwa B-roll</li> </ul>"},{"location":"pl/b_roll_assistant/#2-ai-shot-descriptions","title":"2. AI Shot Descriptions","text":"<ul> <li>Automatyczne generowanie snapshot\u00f3w (FFmpeg)</li> <li>Analiza wizualna uj\u0119\u0107 (AI Vision)</li> <li>Opisy tekstowe dla ka\u017cdego klipu: obiekty, sceny, kontekst, atmosfera</li> <li>Ka\u017cdy klip otrzymuje bogaty opis semantyczny bez r\u0119cznego tagowania</li> </ul>"},{"location":"pl/b_roll_assistant/#3-dual-search-continuous-learning","title":"3. Dual Search &amp; Continuous Learning","text":"<ul> <li>Keyword search (szybkie, precyzyjne zapytania)</li> <li>Semantic search (wyszukiwanie po znaczeniu i koncepcjach)</li> </ul> <p>Przyk\u0142ady zapyta\u0144:</p> <ul> <li>\"szk\u0142o\"</li> <li>\"przezroczysty pojemnik\"</li> <li>\"napi\u0119ty wiec polityczny\"</li> <li>\"t\u0142um nerwowo czekaj\u0105cy\"</li> </ul> <p>System umo\u017cliwia ocen\u0119 wynik\u00f3w, co:</p> <ul> <li>poprawia trafno\u015b\u0107,</li> <li>dostosowuje ranking,</li> <li>zwi\u0119ksza skuteczno\u015b\u0107 wyszukiwania w czasie.</li> </ul>"},{"location":"pl/b_roll_assistant/#architektura","title":"Architektura","text":"<p>B-Roll Assistant to multimodalny pipeline:</p> <ul> <li>Video ingestion \u2014 analiza struktury plik\u00f3w, ekstrakcja klatek</li> <li>AI processing \u2014 vision \u2192 opis obrazu, tekst \u2192 embeddingi</li> <li>Search layer \u2014 klasyczne indeksy, wektorowa baza danych</li> <li>Feedback loop \u2014 oceny u\u017cytkownik\u00f3w, korekta rankingu wynik\u00f3w</li> </ul> <p>Zaprojektowany pod wydajno\u015b\u0107 i skalowanie w \u015brodowiskach medialnych.</p>"},{"location":"pl/b_roll_assistant/#co-zrobiem","title":"Co zrobi\u0142em","text":"<ol> <li>Zaprojektowa\u0142em architektur\u0119 systemu do analizy B-roll</li> <li>Zaimplementowa\u0142em pipeline ekstrakcji klatek wideo</li> <li>Zintegrowa\u0142em AI Vision do analizy uj\u0119\u0107</li> <li>Stworzy\u0142em system automatycznych opis\u00f3w klip\u00f3w</li> <li>Zbudowa\u0142em dual search engine (keyword + semantic)</li> <li>Wdro\u017cy\u0142em wyszukiwanie oparte o embeddingi</li> <li>Zaprojektowa\u0142em mechanizm feedbacku u\u017cytkownik\u00f3w</li> <li>Przygotowa\u0142em backend API i struktur\u0119 danych</li> <li>Opakowa\u0142em system w \u015brodowisko kontenerowe (Docker)</li> </ol>"},{"location":"pl/b_roll_assistant/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>OpenAI (Vision + LLM)</li> <li>Embeddings</li> <li>Vector Database</li> <li>FastAPI</li> <li>PostgreSQL</li> <li>FFmpeg</li> <li>Docker</li> <li>Semantic Search</li> </ul>"},{"location":"pl/b_roll_assistant/#rezultaty","title":"Rezultaty","text":"<ul> <li>Odnalezienie w\u0142a\u015bciwego B-roll w sekundy zamiast minut</li> <li>Brak potrzeby r\u0119cznego tagowania materia\u0142\u00f3w</li> <li>Lepsze wykorzystanie istniej\u0105cych archiw\u00f3w wideo</li> <li>System, kt\u00f3ry uczy si\u0119 razem z zespo\u0142em redakcyjnym</li> <li>Solidna baza pod: newsroomy, media houses, platformy contentowe</li> </ul>"},{"location":"pl/b_roll_assistant/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/bitcoin_prediction/","title":"Predykcja ceny Bitcoina","text":"<p>Data utworzenia: 2025-02-04</p>"},{"location":"pl/bitcoin_prediction/#opis-projektu","title":"Opis projektu","text":"<p>Ten projekt koncentruje si\u0119 na rozwoju modelu predykcyjnego dla ruch\u00f3w cen Bitcoina przy u\u017cyciu technik deep learning. Podej\u015bcie integruje kompleksow\u0105 Eksploracyjn\u0105 Analiz\u0119 Danych (EDA) z zaawansowanymi metodami prognozowania szereg\u00f3w czasowych, w szczeg\u00f3lno\u015bci sieciami neuronowymi Long Short-Term Memory (LSTM). Wykorzystuj\u0105c historyczne dane cenowe Bitcoina (z Kaggle), wska\u017aniki techniczne i metryki sentymentu rynkowego, model ma na celu prognozowanie przysz\u0142ych trend\u00f3w cenowych ze znacz\u0105c\u0105 dok\u0142adno\u015bci\u0105. Implementacja wykorzystuje frameworki TensorFlow i Keras do budowy, trenowania i ewaluacji architektury LSTM, kt\u00f3ra jest szczeg\u00f3lnie odpowiednia do wychwytywania zale\u017cno\u015bci czasowych w finansowych szeregach czasowych. Projekt demonstruje zastosowanie deep learning do analizy rynku kryptowalut i dostarcza wgl\u0105du w czynniki wp\u0142ywaj\u0105ce na zmienno\u015b\u0107 cen Bitcoina.</p>"},{"location":"pl/bitcoin_prediction/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>Kompleksowa Eksploracyjna Analiza Danych (EDA) historycznych danych cenowych Bitcoina i powi\u0105zanych metryk rynkowych</li> <li>Preprocessing danych wraz z technikami normalizacji do optymalizacji wydajno\u015bci modelu</li> <li>Implementacja feature engineering do ekstrakcji znacz\u0105cych predyktor\u00f3w z surowych danych rynkowych</li> <li>Rozw\u00f3j architektury sieci neuronowej LSTM (Long Short-Term Memory) do prognozowania szereg\u00f3w czasowych</li> <li>Integracja framework\u00f3w TensorFlow i Keras do budowy, trenowania i ewaluacji modelu</li> <li>Dostrajanie hiperparametr\u00f3w w celu optymalizacji dok\u0142adno\u015bci i zdolno\u015bci generalizacji modelu</li> <li>Wizualizacja przewidywanych vs rzeczywistych ruch\u00f3w cen do oceny wydajno\u015bci modelu</li> <li>Analiza b\u0142\u0119d\u00f3w predykcji w celu identyfikacji warunk\u00f3w rynkowych wp\u0142ywaj\u0105cych na dok\u0142adno\u015b\u0107 prognozy</li> </ul>"},{"location":"pl/bitcoin_prediction/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>Pandas</li> <li>EDA</li> <li>NumPy</li> <li>Scikit-learn</li> <li>TensorFlow</li> <li>Keras</li> <li>LSTM</li> <li>Matplotlib</li> <li>LaTeX</li> </ul>"},{"location":"pl/bitcoin_prediction/#raport-projektu","title":"Raport projektu","text":"<p>Mo\u017cesz pobra\u0107 i przejrze\u0107 kompletny raport projektu ze szczeg\u00f3\u0142ow\u0105 metodologi\u0105 i wynikami tutaj: Raport predykcji ceny Bitcoina</p>"},{"location":"pl/bitcoin_prediction/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/career_guide/","title":"Career Guide","text":"<p>Projekt: czerwiec 2025 \u2014 listopad 2025</p> <p>Rola: Product Owner</p> <p>Status: Zako\u0144czony</p>"},{"location":"pl/career_guide/#opis-projektu","title":"Opis projektu","text":"<p>Proces poszukiwania pracy w bran\u017cy IT jest dla kandydat\u00f3w:</p> <ul> <li>czasoch\u0142onny,</li> <li>chaotyczny,</li> <li>oparty na r\u0119cznym dopasowywaniu CV do dziesi\u0105tek ofert.</li> </ul> <p>Kandydaci cz\u0119sto:</p> <ul> <li>nie wiedz\u0105, kt\u00f3re oferty s\u0105 realnie dopasowane do ich profilu,</li> <li>wysy\u0142aj\u0105 to samo CV do r\u00f3\u017cnych firm,</li> <li>trac\u0105 czas na poprawki dokument\u00f3w bez informacji zwrotnej.</li> </ul> <p>Na rynku brakowa\u0142o narz\u0119dzia, kt\u00f3re jednocze\u015bnie analizuje CV i wymagania ofert oraz wskazuje najlepsze dopasowania w spos\u00f3b automatyczny.</p>"},{"location":"pl/career_guide/#rozwiazanie","title":"Rozwi\u0105zanie","text":"<p>Career Guide to inteligentna platforma wykorzystuj\u0105ca algorytmy AI, kt\u00f3ra skraca drog\u0119 od CV do dopasowanej oferty pracy.</p> <p>System:</p> <ul> <li>analizuje tre\u015b\u0107 CV u\u017cytkownika,</li> <li>por\u00f3wnuje j\u0105 z setkami ofert pracy,</li> <li>wylicza procentowe dopasowanie profilu do og\u0142osze\u0144,</li> <li>umo\u017cliwia generowanie CV pod konkretn\u0105 ofert\u0119,</li> <li>wspiera u\u017cytkownika poprzez asystenta AI.</li> </ul> <p>Produkt zosta\u0142 zaprojektowany jako skalowalne narz\u0119dzie dla szerokiej grupy kandydat\u00f3w IT.</p>"},{"location":"pl/career_guide/#kluczowe-funkcjonalnosci","title":"Kluczowe funkcjonalno\u015bci","text":""},{"location":"pl/career_guide/#inteligentne-dopasowanie-ofert-pracy","title":"Inteligentne dopasowanie ofert pracy","text":"<ul> <li>analiza CV i wymaga\u0144 ofert</li> <li>procentowe dopasowanie profilu</li> <li>szybka identyfikacja najlepszych ofert</li> </ul>"},{"location":"pl/career_guide/#generowanie-cv-pod-oferte","title":"Generowanie CV pod ofert\u0119","text":"<ul> <li>automatyczne tworzenie CV dopasowanego do konkretnego og\u0142oszenia</li> <li>optymalizacja tre\u015bci pod wymagania stanowiska</li> </ul>"},{"location":"pl/career_guide/#asystent-ai-do-poprawy-cv","title":"Asystent AI do poprawy CV","text":"<ul> <li>interaktywna rozmowa z AI</li> <li>sugestie zmian j\u0119zykowych i strukturalnych</li> <li>wzmacnianie kluczowych sekcji CV</li> </ul>"},{"location":"pl/career_guide/#testy-osobowosci","title":"Testy osobowo\u015bci","text":"<ul> <li>identyfikacja mocnych stron kandydata</li> <li>wsparcie w wyborze odpowiednich r\u00f3l</li> </ul>"},{"location":"pl/career_guide/#modu-egzaminator-w-rozwoju","title":"Modu\u0142 \u201eEgzaminator\" (w rozwoju)","text":"<ul> <li>symulowane rozmowy rekrutacyjne</li> <li>rozw\u00f3j kompetencji technicznych i mi\u0119kkich</li> </ul>"},{"location":"pl/career_guide/#moja-rola-jako-product-owner","title":"Moja rola jako Product Owner","text":"<p>Jako Product Owner odpowiada\u0142em za:</p> <ul> <li>prowadzenie rozwoju produktu Career Guide</li> <li>definiowanie wizji i d\u0142ugoterminowego kierunku rozwoju</li> <li>zarz\u0105dzanie backlogiem i priorytetami funkcjonalnymi</li> <li>planowanie sprint\u00f3w i nadz\u00f3r nad delivery</li> <li>koordynacj\u0119 pracy 8 zespo\u0142\u00f3w projektowych w r\u00f3\u017cnych lokalizacjach</li> <li>zbieranie i analiz\u0119 potrzeb u\u017cytkownik\u00f3w</li> <li>przek\u0142adanie wymaga\u0144 biznesowych na funkcjonalno\u015bci produktowe</li> <li>dbanie o sp\u00f3jno\u015b\u0107 produktu jako ca\u0142o\u015bci</li> </ul>"},{"location":"pl/career_guide/#co-zrobiem","title":"Co zrobi\u0142em","text":"<ul> <li>Zdefiniowa\u0142em roadmap\u0119 produktu i kluczowe milestone'y</li> <li>Uporz\u0105dkowa\u0142em zakres funkcjonalny platformy</li> <li>Wspiera\u0142em zespo\u0142y w podejmowaniu decyzji produktowych</li> <li>Moderowa\u0142em sesje planistyczne i przegl\u0105dy sprint\u00f3w</li> <li>Dba\u0142em o sp\u00f3jno\u015b\u0107 wizji przy r\u00f3wnoleg\u0142ej pracy wielu zespo\u0142\u00f3w</li> <li>Wprowadza\u0142em iteracyjne usprawnienia oparte o feedback u\u017cytkownik\u00f3w</li> </ul>"},{"location":"pl/career_guide/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Product Management</li> <li>Agile / Scrum</li> <li>AI Matching Algorithms</li> <li>Natural Language Processing</li> <li>CV Parsing</li> <li>LLM-based Assistants</li> <li>Product Discovery</li> <li>User-Centric Design</li> <li>Roadmap Planning</li> <li>Stakeholder Management</li> </ul>"},{"location":"pl/career_guide/#rezultaty","title":"Rezultaty","text":"<ul> <li>Sp\u00f3jna wizja i architektura produktu AI</li> <li>Uporz\u0105dkowany proces rozwoju przy pracy wielu zespo\u0142\u00f3w</li> <li>Platforma realnie skracaj\u0105ca czas poszukiwania pracy</li> <li>Narz\u0119dzie odpowiadaj\u0105ce na faktyczny problem rynku rekrutacyjnego</li> <li>Solidna baza pod dalszy rozw\u00f3j i skalowanie produktu</li> </ul>"},{"location":"pl/career_guide/#wnioski","title":"Wnioski","text":"<p>Projekt Career Guide by\u0142 dla mnie do\u015bwiadczeniem \u0142\u0105cz\u0105cym:</p> <ul> <li>techniczne zrozumienie system\u00f3w AI,</li> <li>product thinking,</li> <li>zarz\u0105dzanie zespo\u0142ami,</li> <li>prac\u0119 z realnymi potrzebami u\u017cytkownik\u00f3w.</li> </ul> <p>Pokaza\u0142, jak skutecznie budowa\u0107 AI-powered product na styku technologii, biznesu i do\u015bwiadczenia u\u017cytkownika.</p>"},{"location":"pl/cifar10_classification/","title":"Klasyfikacja obraz\u00f3w CIFAR-10","text":"<p>Data utworzenia: 2025-02-07</p>"},{"location":"pl/cifar10_classification/#opis-projektu","title":"Opis projektu","text":"<p>Ten projekt implementuje zaawansowan\u0105 architektur\u0119 Konwolucyjnej Sieci Neuronowej (CNN) do klasyfikacji obraz\u00f3w przy u\u017cyciu zbioru danych CIFAR-10. Badanie koncentruje si\u0119 na rozwoju i optymalizacji modelu deep learning zdolnego do dok\u0142adnej klasyfikacji obraz\u00f3w w 10 r\u00f3\u017cnych kategoriach. Poprzez systematyczne eksperymenty z r\u00f3\u017cnymi architekturami sieci, technikami augmentacji danych i optymalizacj\u0105 hiperparametr\u00f3w, projekt demonstruje jak zbudowa\u0107 solidny system Computer Vision. Implementacja wykorzystuje frameworki TensorFlow i Keras, stosuj\u0105c najlepsze praktyki w projektowaniu CNN, w tym warstwy konwolucyjne, operacje pooling, batch normalization i regularyzacj\u0119 dropout. Projekt podkre\u015bla znaczenie strategii cross-validation i metryk ewaluacji modelu do tworzenia uog\u00f3lnialnego modelu klasyfikacji z wysok\u0105 dok\u0142adno\u015bci\u0105 na niewidzianych danych.</p>"},{"location":"pl/cifar10_classification/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>Implementacja niestandardowych architektur CNN do zada\u0144 klasyfikacji obraz\u00f3w</li> <li>Zastosowanie technik augmentacji danych w celu zwi\u0119kszenia odporno\u015bci modelu i zapobiegania overfittingowi</li> <li>Optymalizacja hiperparametr\u00f3w przy u\u017cyciu RandomSearch do identyfikacji optymalnych konfiguracji modelu</li> <li>Implementacja K-Fold cross-validation dla zapewnienia wiarygodnej ewaluacji modelu</li> <li>Wykorzystanie early stopping i planowania learning rate dla poprawy efektywno\u015bci treningu</li> <li>Kompleksowa ewaluacja modelu przy u\u017cyciu macierzy pomy\u0142ek, precision, recall i F1-score</li> <li>Wizualizacja wydajno\u015bci modelu, map cech i wynik\u00f3w klasyfikacji</li> <li>Analiza por\u00f3wnawcza r\u00f3\u017cnych architektur modeli i ich metryk wydajno\u015bci</li> </ul>"},{"location":"pl/cifar10_classification/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>TensorFlow</li> <li>Keras</li> <li>Augmentation</li> <li>CNN</li> <li>RandomSearch</li> <li>Scikit-learn</li> <li>NumPy</li> <li>KFold</li> <li>LaTeX</li> </ul>"},{"location":"pl/cifar10_classification/#raport-projektu","title":"Raport projektu","text":"<p>Mo\u017cesz pobra\u0107 i przejrze\u0107 kompletny raport projektu ze szczeg\u00f3\u0142ow\u0105 metodologi\u0105 i wynikami tutaj: Raport klasyfikacji obraz\u00f3w CIFAR-10</p>"},{"location":"pl/cifar10_classification/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/cv_generator/","title":"Generator CV","text":"<p>Data utworzenia: 2024-11-06</p>"},{"location":"pl/cv_generator/#opis-projektu","title":"Opis projektu","text":"<p>Celem tego projektu by\u0142o stworzenie generatora CV, kt\u00f3ry jest \u0142atwo edytowalny i pozwoli na generowanie informacji dopasowanych do danej firmy i oferty. Wykorzystanie AI pozwoli najlepiej dopasowa\u0107 Twoje umiej\u0119tno\u015bci do stanowiska, o kt\u00f3re si\u0119 ubiegasz. Ma to usprawni\u0107 proces znajdowania wymarzonej pracy jako Data Scientist.</p>"},{"location":"pl/cv_generator/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>U\u017cytkownik wprowadza informacje o sobie, firmie i bezpo\u015brednio z oferty pracy</li> <li>Dodatkowo podaje najwa\u017cniejsze umiej\u0119tno\u015bci (j\u0119zyki programowania, bazy danych lub poznane biblioteki)</li> <li>Na tej podstawie generowane jest intro, kt\u00f3re dopasowuje umiej\u0119tno\u015bci do indywidualnej oferty pracy</li> <li>U\u017cytkownik mo\u017ce edytowa\u0107 wygenerowane przez AI intro</li> <li>Nast\u0119pnie u\u017cytkownik mo\u017ce podgl\u0105da\u0107 zawarto\u015b\u0107 CV w aplikacji (w formacie Markdown)</li> <li>Na koniec u\u017cytkownik ma mo\u017cliwo\u015b\u0107 nazwania i pobrania CV w formacie PDF</li> </ul>"},{"location":"pl/cv_generator/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Streamlit</li> <li>HTML</li> <li>PDFkit</li> <li>Markdown</li> <li>Template</li> </ul>"},{"location":"pl/cv_generator/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/fashion_designer/","title":"Fashion Designer","text":"<p>Data utworzenia: 2024-12-15</p>"},{"location":"pl/fashion_designer/#opis-projektu","title":"Opis projektu","text":"<p>Celem tego projektu by\u0142o stworzenie imitacji projektanta mody. Pomys\u0142 na projekt przyszed\u0142 mi ze wzgl\u0119du na potrzeby mojej partnerki \u017cyciowej, kt\u00f3ra projektuje bielizn\u0119 damsk\u0105. Ta aplikacja ma zautomatyzowa\u0107 proces projektowania i dodatkowo b\u0119dzie inspiracj\u0105 do tworzenia nowych element\u00f3w ze \u015bwiata mody.</p>"},{"location":"pl/fashion_designer/#architektura-projektu","title":"Architektura projektu","text":""},{"location":"pl/fashion_designer/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>U\u017cytkownik wybiera, jaki typ bielizny chce zaprojektowa\u0107</li> <li>U\u017cytkownik okre\u015bla pocz\u0105tkow\u0105 koncepcj\u0119 projektu - nast\u0119pnie otrzymuje wizualn\u0105 inspiracj\u0119 wygenerowan\u0105 przez AI</li> <li>U\u017cytkownik podaje odpowiednie wymiary</li> <li>Aplikacja - wykorzystuj\u0105c odpowiednie wzory konstrukcyjne, oblicza i zapisuje parametry zwi\u0105zane z konkretnym typem bielizny</li> <li>Nast\u0119pnie na podstawie parametr\u00f3w obliczonych w poprzednim kroku tworzony jest rysunek konstrukcyjny, kt\u00f3ry jest wy\u015bwietlany w aplikacji</li> <li>Rysunek jest odpowiednio przygotowany do druku</li> <li>U\u017cytkownik ma mo\u017cliwo\u015b\u0107 pobrania rysunku (ca\u0142ego lub podzielonego na cz\u0119\u015bci do druku)</li> <li>Na koniec model AI generuje rekomendacje zwi\u0105zane z procesem tworzenia elementu zaprojektowanego przez u\u017cytkownika</li> </ul>"},{"location":"pl/fashion_designer/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Streamlit</li> <li>Matplotlib</li> <li>PIL</li> <li>Zipfile</li> <li>Requests</li> </ul>"},{"location":"pl/fashion_designer/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/features_detective/","title":"Features Detective App","text":"<p>Data utworzenia: 2024-10-30</p>"},{"location":"pl/features_detective/#opis-projektu","title":"Opis projektu","text":"<p>Celem projektu by\u0142o stworzenie uniwersalnej aplikacji pozwalaj\u0105cej na wykrywanie najwa\u017cniejszych cech w danym zbiorze danych. W skr\u00f3cie - u\u017cytkownik wgrywa dane lub \u0142aduje gotowy zbi\u00f3r danych w odpowiednim formacie, nast\u0119pnie wybiera automatyczn\u0105 detekcj\u0119 kolumny, kt\u00f3r\u0105 chce analizowa\u0107, lub dokonuje tego wyboru samodzielnie. Na koniec otrzymuje wygenerowany wykres istotno\u015bci cech, kt\u00f3re maj\u0105 najwi\u0119kszy wp\u0142yw na wcze\u015bniej wybran\u0105 kolumn\u0119. U\u017cytkownik otrzymuje r\u00f3wnie\u017c czytelny opis wykresu wraz z rekomendacjami - co mo\u017cna poprawi\u0107, aby np. ulepszy\u0107 analizowane dane.</p>"},{"location":"pl/features_detective/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>U\u017cytkownik mo\u017ce za\u0142adowa\u0107 plik CSV/JSON z danymi lub u\u017cy\u0107 gotowego przyk\u0142adowego zbioru danych</li> <li>U\u017cytkownik wskazuje kolumn\u0119 docelow\u0105 \u2192 dodatkowo mo\u017ce skorzysta\u0107 z automatycznej detekcji kolumny (generowanej przez LLM)</li> <li>Aplikacja automatycznie rozpoznaje, czy za\u0142adowane dane dotycz\u0105 problemu regresji czy klasyfikacji i na tej podstawie dobiera odpowiedni algorytm treningu modelu AI</li> <li>Na podstawie wytrenowanego modelu wy\u015bwietlany jest wykres zawieraj\u0105cy najwa\u017cniejsze cechy</li> <li>Na koniec u\u017cytkownik otrzymuje czytelny opis wykresu wraz z rekomendacjami - jakie dzia\u0142ania wdro\u017cy\u0107, aby poprawi\u0107 wyniki zwi\u0105zane z analizowan\u0105 kolumn\u0105 docelow\u0105</li> </ul>"},{"location":"pl/features_detective/#trening-modelu-ml","title":"Trening modelu ML","text":"<p>Wykorzysta\u0142em narz\u0119dzia PyCaret i zawar\u0142em implementacj\u0119 w notatniku gotowym do pobrania:</p> <p>Pobierz Notebook: Trening modelu</p>"},{"location":"pl/features_detective/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> <li>PyCaret (Classification &amp; Regression)</li> <li>Pandas</li> <li>Matplotlib</li> <li>Instructor</li> <li>Pydantic</li> <li>Boto3</li> </ul>"},{"location":"pl/features_detective/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/features_detective/#linki","title":"Linki","text":"<p>Link do repozytorium</p>"},{"location":"pl/find_friends/","title":"Find Friends App","text":"<p>Data utworzenia: 2024-10-09</p>"},{"location":"pl/find_friends/#opis-projektu","title":"Opis projektu","text":"<p>Celem projektu by\u0142o stworzenie aplikacji, kt\u00f3ra umo\u017cliwia\u0142aby wykorzystanie modelu klastrowania do dopasowania u\u017cytkownika do odpowiedniej grupy z za\u0142adowanego zbioru danych (dane pochodz\u0105 z anonimowej ankiety) - na podstawie danych podanych przez u\u017cytkownika.</p>"},{"location":"pl/find_friends/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>U\u017cytkownik filtruje podstawowe dane, takie jak: wiek, wykszta\u0142cenie, p\u0142e\u0107, ulubione zwierz\u0119ta lub ulubione miejsca - odpowiadaj\u0105ce jego preferencjom</li> <li>Nast\u0119pnie wcze\u015bniej wytrenowany model klastrowania tworzy odpowiedni\u0105 liczb\u0119 klastr\u00f3w dla danych ankietowych i dopasowuje preferencje u\u017cytkownika do pasuj\u0105cej grupy</li> <li>Na koniec, przy u\u017cyciu LLM, generowane s\u0105 odpowiednie opisy klastr\u00f3w</li> </ul>"},{"location":"pl/find_friends/#trening-modelu-ml","title":"Trening modelu ML","text":"<p>Wykorzysta\u0142em narz\u0119dzia Scikit-learn i zawar\u0142em implementacj\u0119 w notatniku gotowym do pobrania:</p> <p>Pobierz Notebook: Trening modelu</p>"},{"location":"pl/find_friends/#nazewnictwo-klastrow","title":"Nazewnictwo klastr\u00f3w","text":"<p>Wykorzysta\u0142em model LLM i zawar\u0142em implementacj\u0119 w notatniku gotowym do pobrania:</p> <p>Pobierz Notebook: Nazewnictwo klastr\u00f3w</p>"},{"location":"pl/find_friends/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> <li>Scikit-learn</li> <li>Plotly</li> <li>PyCaret (Clustering)</li> <li>NumPy</li> <li>Matplotlib</li> </ul>"},{"location":"pl/find_friends/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/find_friends/#linki","title":"Linki","text":"<p>Link do repozytorium</p>"},{"location":"pl/halfmarathon_estimator/","title":"Estymator P\u00f3\u0142maratonu","text":"<p>Data utworzenia: 2024-10-20</p>"},{"location":"pl/halfmarathon_estimator/#opis-projektu","title":"Opis projektu","text":"<p>Celem projektu by\u0142o stworzenie aplikacji, kt\u00f3ra wykorzystuj\u0105c algorytm regresji do trenowania modeli, by\u0142aby w stanie przewidzie\u0107 (na podstawie wcze\u015bniej wytrenowanych danych) czas, w jakim u\u017cytkownik przebiegnie p\u00f3\u0142maraton - poprzez podanie konkretnych danych.</p>"},{"location":"pl/halfmarathon_estimator/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>Umo\u017cliwienie u\u017cytkownikowi swobodnego wprowadzania danych (bez odpowiedniej konwersji zapisu) \u2192 wykorzystany model LLM ekstrahuje dane od u\u017cytkownika do struktury JSON i przygotowuje je do u\u017cycia przez model regresji</li> <li>Prosta funkcjonalno\u015b\u0107 pozwala na ostateczn\u0105 estymacj\u0119 czasu przebiegni\u0119cia p\u00f3\u0142maratonu - przy u\u017cyciu wytrenowanego najlepszego modelu regresji</li> <li>Model LLM jest po\u0142\u0105czony z Langfuse do \u015bledzenia cyklu \u017cycia modelu</li> </ul>"},{"location":"pl/halfmarathon_estimator/#trening-modelu-ml","title":"Trening modelu ML","text":"<p>Wykorzysta\u0142em narz\u0119dzia PyCaret i zawar\u0142em implementacj\u0119 w notatniku gotowym do pobrania:</p> <p>Pobierz Notebook: Trening modelu</p>"},{"location":"pl/halfmarathon_estimator/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>PyCaret</li> <li>Machine Learning</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> <li>Pandas</li> <li>Instructor</li> <li>Pydantic</li> <li>Dotenv</li> </ul>"},{"location":"pl/halfmarathon_estimator/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/halfmarathon_estimator/#linki","title":"Linki","text":"<p>Link do repozytorium</p>"},{"location":"pl/heweliusz/","title":"Analiza katastrofy promu Jan Heweliusz","text":"<p>Projekt: listopad 2025</p> <p>Rola: Data Scientist</p>"},{"location":"pl/heweliusz/#opis-projektu","title":"Opis projektu","text":"<p>Katastrofa promu MS Jan Heweliusz (14 stycznia 1993 r.) przez lata by\u0142a analizowana g\u0142\u00f3wnie w spos\u00f3b opisowy, bez pe\u0142nej rekonstrukcji warunk\u00f3w meteorologicznych i ich wp\u0142ywu na stateczno\u015b\u0107 jednostki.</p> <p>Celem projektu by\u0142o odtworzenie przebiegu katastrofy w spos\u00f3b oparty na danych, fizyce i walidowalnych modelach.</p> <p>Przeprowadzi\u0142em kompleksow\u0105 analiz\u0119 meteorologiczno-techniczn\u0105 \u0142\u0105cz\u0105c\u0105:</p> <ul> <li>reanalizy meteorologiczne ERA5 (ECMWF),</li> <li>dane falowe CMEMS,</li> <li>prawa hydrodynamiki i stateczno\u015bci,</li> <li>oficjalne raporty komisji i orzeczenia s\u0105dowe.</li> </ul>"},{"location":"pl/heweliusz/#zakres-analizy","title":"Zakres analizy","text":""},{"location":"pl/heweliusz/#1-warunki-meteorologiczne","title":"1. Warunki meteorologiczne","text":"<ul> <li>ci\u015bnienie atmosferyczne (MSLP)</li> <li>pr\u0119dko\u015b\u0107 i kierunek wiatru</li> <li>wysoko\u015b\u0107 i energia fal</li> <li>analiza gradientu barycznego</li> </ul>"},{"location":"pl/heweliusz/#2-dynamika-sztormu","title":"2. Dynamika sztormu","text":"<ul> <li>identyfikacja explosive cyclogenesis (kryterium Bergerona: \u226520 hPa / 24h)</li> <li>gwa\u0142towna eskalacja warunk\u00f3w w godzinach poprzedzaj\u0105cych katastrof\u0119</li> </ul>"},{"location":"pl/heweliusz/#3-hydrodynamika-i-statecznosc","title":"3. Hydrodynamika i stateczno\u015b\u0107","text":"<ul> <li>analiza fali bocznej (Beam Sea)</li> <li>mechanizm parametric rolling</li> <li>eskalacja przechy\u0142\u00f3w prowadz\u0105ca do utraty stateczno\u015bci</li> </ul>"},{"location":"pl/heweliusz/#4-walidacja-danych","title":"4. Walidacja danych","text":"<ul> <li>por\u00f3wnanie ERA5 vs CMEMS</li> <li>korelacja, RMSE, bias</li> <li>ocena wiarygodno\u015bci rekonstrukcji</li> </ul>"},{"location":"pl/heweliusz/#kluczowe-ustalenia","title":"Kluczowe ustalenia","text":""},{"location":"pl/heweliusz/#warunki-pogodowe","title":"Warunki pogodowe","text":"<ul> <li>Spadek ci\u015bnienia o 27 hPa w &lt; 24h</li> <li>Wiatr do 24.2 m/s (9\u00b0B \u2013 silny sztorm)</li> <li>Energia fal wzros\u0142a niemal 5\u00d7 w ci\u0105gu 6 godzin</li> </ul>"},{"location":"pl/heweliusz/#hydrodynamika","title":"Hydrodynamika","text":"<ul> <li>Fale uderza\u0142y w burt\u0119 pod k\u0105tem ~60\u00b0</li> <li>Maksymalna si\u0142a wiatru na burt\u0119: ~393 kN</li> <li>Jednostka pozostawa\u0142a w strefie Beam Sea</li> <li>Rezonans przechy\u0142\u00f3w (parametric rolling)</li> </ul>"},{"location":"pl/heweliusz/#eskalacja-przechyow","title":"Eskalacja przechy\u0142\u00f3w","text":"<ul> <li>0\u00b0 \u2192 35\u00b0 w 5h 40min</li> <li>35\u00b0 \u2192 90\u00b0 w 36 minut</li> </ul>"},{"location":"pl/heweliusz/#walidacja","title":"Walidacja","text":"<ul> <li>ERA5 vs CMEMS: r = 0.982</li> <li>R\u00b2 = 0.964</li> <li>R\u00f3\u017cnice w energii fal wynikaj\u0105 z nieliniowo\u015bci (E \u221d H\u00b2), a nie z b\u0142\u0119d\u00f3w danych</li> </ul>"},{"location":"pl/heweliusz/#co-zrobiem","title":"Co zrobi\u0142em","text":"<ul> <li>Pozyska\u0142em i przetworzy\u0142em dane ERA5 i CMEMS</li> <li>Wykona\u0142em analizy czasowe i przestrzenne</li> <li>Obliczy\u0142em energi\u0119 fal i si\u0142y dzia\u0142aj\u0105ce na jednostk\u0119</li> <li>Zbudowa\u0142em wizualizacje korelacji i eskalacji zjawisk</li> <li>Zestawi\u0142em dane naukowe z ustaleniami komisji</li> <li>Opracowa\u0142em sp\u00f3jn\u0105 narracj\u0119 opart\u0105 na danych i fizyce</li> </ul>"},{"location":"pl/heweliusz/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>Pandas</li> <li>NumPy</li> <li>xarray</li> <li>ERA5 (ECMWF)</li> <li>CMEMS (Copernicus Marine)</li> <li>Scientific Visualization</li> <li>Data Validation</li> </ul>"},{"location":"pl/heweliusz/#rezultaty","title":"Rezultaty","text":"<ul> <li>Ilo\u015bciowa rekonstrukcja mechanizmu katastrofy</li> <li>Potwierdzenie zbie\u017cno\u015bci ekstremalnych zjawisk pogodowych i b\u0142\u0119d\u00f3w techniczno-operacyjnych</li> <li>Wysoka wiarygodno\u015b\u0107 analizy dzi\u0119ki walidacji \u017ar\u00f3de\u0142</li> <li>Przyk\u0142ad zastosowania Data Science do analizy zdarze\u0144 historycznych</li> </ul>"},{"location":"pl/heweliusz/#wnioski-koncowe","title":"Wnioski ko\u0144cowe","text":"<p>Katastrofa MS Jan Heweliusz by\u0142a systemow\u0105 kulminacj\u0105:</p> <ul> <li>silnego sztormu (9\u00b0B),</li> <li>fali bocznej (Beam Sea),</li> <li>gwa\u0142townej cyklogenezy,</li> <li>niew\u0142a\u015bciwego przygotowania jednostki do rejsu.</li> </ul> <p>Projekt pokazuje, jak analiza danych, fizyka i walidacja modeli pozwalaj\u0105 zrozumie\u0107 z\u0142o\u017cone zdarzenia w spos\u00f3b obiektywny i replikowalny.</p>"},{"location":"pl/heweliusz/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/iris/","title":"Eksploracja domeny (EDA) zbioru danych: Irysy","text":"<p>Data utworzenia: 2024-08-25</p>"},{"location":"pl/iris/#wprowadzenie","title":"Wprowadzenie","text":"<p>Zapraszam do zapoznania si\u0119 z moim projektem, kt\u00f3ry zabiera nas w \u015bwiat analizy danych o Irysach - wykorzystuj\u0105c eksploracj\u0119 domeny (EDA). W tym projekcie znajdziesz wiele trafnych wniosk\u00f3w i ciekawych obserwacji, kt\u00f3re rzucaj\u0105 nowe \u015bwiat\u0142o na te pi\u0119kne kwiaty. Przygotuj si\u0119 na fascynuj\u0105c\u0105 podr\u00f3\u017c przez dane, kt\u00f3ra z pewno\u015bci\u0105 wzbogaci Twoj\u0105 wiedz\u0119 i zainspiruje do dalszych bada\u0144.</p>"},{"location":"pl/iris/#pobierz-projekt","title":"Pobierz projekt","text":"<p>Pobierz Notebook Otw\u00f3rz w nowej karcie \u2197</p>"},{"location":"pl/iris/#podglad-notatnika","title":"Podgl\u0105d notatnika","text":""},{"location":"pl/justjoinit_browser/","title":"JustJoinIT Browser","text":"<p>Start projektu: 2025-02-19</p>"},{"location":"pl/justjoinit_browser/#opis-projektu","title":"Opis projektu","text":"<p>JustJoinIT Browser to aplikacja Streamlit zaprojektowana do interaktywnego przegl\u0105dania najnowszych ofert pracy z platformy JustJoinIT. Projekt obejmowa\u0142 u\u017cycie biblioteki Requests do scrapowania danych o ofertach pracy, a nast\u0119pnie eksploracyjn\u0105 analiz\u0119 danych (EDA) w celu zrozumienia domeny i kategorii dost\u0119pnych na JustJoinIT. Dane zosta\u0142y nast\u0119pnie przetworzone do odpowiedniego formatu CSV, kt\u00f3ry pos\u0142u\u017cy\u0142 jako podstawa do budowy przyjaznego interfejsu u\u017cytkownika. Aplikacja wykorzystuje Geopandas do implementacji interaktywnej mapy polskich wojew\u00f3dztw, umo\u017cliwiaj\u0105c intuicyjne filtrowanie ofert pracy na podstawie geolokalizacji. W przysz\u0142o\u015bci aplikacja b\u0119dzie rozwijana o algorytmy AI.</p>"},{"location":"pl/justjoinit_browser/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>Niestandardowe przegl\u0105danie ofert pracy IT z elastyczn\u0105 konfiguracj\u0105 interfejsu</li> <li>Interaktywna wizualizacja mapy do filtrowania geograficznego wed\u0142ug region\u00f3w</li> <li>Wiele opcji filtrowania na podstawie technologii, poziomu do\u015bwiadczenia i typu pracy</li> <li>Wizualizacja danych z wykresami i statystykami do lepszego zrozumienia rynku pracy</li> <li>Sortowanie i priorytetyzacja ofert pracy zdefiniowane przez u\u017cytkownika</li> </ul>"},{"location":"pl/justjoinit_browser/#eda","title":"EDA","text":"<p>Przeprowadzi\u0142em szczeg\u00f3\u0142ow\u0105 eksploracyjn\u0105 analiz\u0119 danych (EDA) u\u017cywaj\u0105c Pandas do analizy danych, a tak\u017ce Plotly, Matplotlib i Seaborn do wizualizacji danych. Poni\u017cej znajdziesz pliki dost\u0119pne do pobrania zawieraj\u0105ce pe\u0142n\u0105 analiz\u0119 i zbi\u00f3r danych:</p> <p>Pobierz Notebook: Analiza eksploracyjna Pobierz CSV: Oferty pracy</p>"},{"location":"pl/justjoinit_browser/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>Requests</li> <li>Pandas</li> <li>Geopandas</li> <li>Shapely</li> <li>Folium</li> <li>Streamlit</li> <li>Plotly</li> <li>Pathlib</li> <li>EDA</li> </ul>"},{"location":"pl/justjoinit_browser/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/knowledge_seeker/","title":"Knowledge Seeker","text":"<p>Start projektu: kwiecie\u0144 2025 \u2014 sierpie\u0144 2025</p> <p>Rola: Tech Lead / Architekt</p> <p>Firma: GOTOIT sp. z o.o.</p> <p>Status: Produkcja</p>"},{"location":"pl/knowledge_seeker/#opis-projektu","title":"Opis projektu","text":"<p>Knowledge Seeker to zaawansowane narz\u0119dzie do transkrypcji, indeksowania i wyszukiwania informacji w nagraniach wideo.</p> <p>U\u017cytkownicy posiadaj\u0105cy dost\u0119p do du\u017cych zasob\u00f3w nagra\u0144 wideo (kursy, szkolenia, sesje mentoringowe) mieli trudno\u015bci z szybkim odnajdywaniem konkretnych informacji. Manualne przeszukiwanie setek materia\u0142\u00f3w by\u0142o czasoch\u0142onne i nieefektywne.</p> <p>Jako lider projektu koordynuj\u0119 rozw\u00f3j systemu wykorzystuj\u0105cego najnowsze technologie AI do przetwarzania mowy na tekst i implementacji zaawansowanych mechanizm\u00f3w wyszukiwania semantycznego.</p> <p>Aplikacja umo\u017cliwia u\u017cytkownikom nie tylko znajdowanie konkretnych informacji w obszernych zasobach wideo, ale tak\u017ce generowanie odpowiedzi na zapytania w oparciu o zgromadzon\u0105 wiedz\u0119 przy u\u017cyciu architektury RAG (Retrieval-Augmented Generation).</p>"},{"location":"pl/knowledge_seeker/#rozwiazanie","title":"Rozwi\u0105zanie","text":"<p>Zaprojektowa\u0142em system oparty o architektur\u0119 RAG (Retrieval-Augmented Generation), \u0142\u0105cz\u0105cy automatyczn\u0105 transkrypcj\u0119 nagra\u0144 wideo, wyszukiwanie semantyczne w bazie wektorowej oraz generowanie odpowiedzi przez modele j\u0119zykowe.</p>"},{"location":"pl/knowledge_seeker/#architektura","title":"Architektura","text":""},{"location":"pl/knowledge_seeker/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>Transkrypcja nagra\u0144 wideo na tekst z zachowaniem metadanych czasowych (timestampy)</li> <li>Przetwarzanie transkrypcji poprzez chunking i generowanie embedding\u00f3w</li> <li>Baza wektorowa do przechowywania i efektywnego wyszukiwania embedding\u00f3w</li> <li>Interfejs u\u017cytkownika umo\u017cliwiaj\u0105cy zar\u00f3wno proste, jak i semantyczne wyszukiwanie tre\u015bci</li> <li>System RAG (Retrieval-Augmented Generation) do generowania odpowiedzi na zapytania u\u017cytkownik\u00f3w</li> <li>Wdro\u017cenie w chmurze Digital Ocean zapewniaj\u0105ce skalowalno\u015b\u0107 i dost\u0119pno\u015b\u0107</li> <li>Eksport danych w formatach JSON i mo\u017cliwo\u015b\u0107 streamingu do API u\u017cytkownika</li> </ul>"},{"location":"pl/knowledge_seeker/#co-zrobiem","title":"Co zrobi\u0142em","text":"<ol> <li>Zaprojektowa\u0142em architektur\u0119 systemu oraz pipeline przetwarzania danych</li> <li>Zaimplementowa\u0142em transkrypcj\u0119 audio \u2192 tekst z u\u017cyciem Whisper</li> <li>Opracowa\u0142em chunking dokument\u00f3w oraz generowanie embedding\u00f3w</li> <li>Skonfigurowa\u0142em baz\u0119 wektorow\u0105 Qdrant</li> <li>Zbudowa\u0142em backend API w FastAPI</li> <li>Stworzy\u0142em interfejs u\u017cytkownika w Streamlit</li> <li>Wdro\u017cy\u0142em system w chmurze DigitalOcean (Docker)</li> </ol>"},{"location":"pl/knowledge_seeker/#plan-rozwoju","title":"Plan rozwoju","text":"<ul> <li>Integracja z dodatkowymi \u017ar\u00f3d\u0142ami danych (dokumenty, prezentacje, audio)</li> <li>Rozbudowa mechanizm\u00f3w RAG o zaawansowane techniki filtrowania i re-rankingu</li> <li>Implementacja komponent\u00f3w do automatycznej weryfikacji i aktualizacji bazy wiedzy</li> <li>Optymalizacja proces\u00f3w indeksowania i wyszukiwania dla wi\u0119kszych zbior\u00f3w danych</li> <li>Rozw\u00f3j interfejsu API umo\u017cliwiaj\u0105cego integracj\u0119 z zewn\u0119trznymi aplikacjami</li> </ul>"},{"location":"pl/knowledge_seeker/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Whisper</li> <li>Qdrant</li> <li>FastAPI</li> <li>Streamlit</li> <li>Docker</li> <li>DigitalOcean</li> <li>LLM (Large Language Models)</li> <li>Natural Language Processing</li> <li>Vector Databases</li> <li>RAG (Retrieval-Augmented Generation)</li> <li>Microservice Architecture</li> </ul>"},{"location":"pl/knowledge_seeker/#rezultaty","title":"Rezultaty","text":"<ul> <li>400+ nagra\u0144 wideo przeszukiwalnych w czasie rzeczywistym</li> <li>Skr\u00f3cenie czasu odnajdywania informacji z minut do sekund</li> <li>Gotowy do skalowania, produkcyjny system AI</li> </ul>"},{"location":"pl/larvixon_ai/","title":"Larvixon-AI","text":"<p>Start projektu: kwiecie\u0144 2025 \u2014 obecnie</p> <p>Rola: AI / Computer Vision Engineer</p> <p>Wsp\u00f3\u0142praca: Uniwersytet Medyczny we Wroc\u0142awiu</p>"},{"location":"pl/larvixon_ai/#opis-projektu","title":"Opis projektu","text":"<p>Larvixon-AI to system oparty o computer vision i deep learning, kt\u00f3ry automatycznie analizuje zachowania ruchowe larw Galleria mellonella po iniekcji wybranych patogen\u00f3w bakteryjnych.</p> <p>Sepsa jest jednym z najpowa\u017cniejszych problem\u00f3w wsp\u00f3\u0142czesnej medycyny, a szybka identyfikacja patogenu ma kluczowe znaczenie dla wdro\u017cenia odpowiedniej terapii. Klasyczne metody diagnostyczne:</p> <ul> <li>s\u0105 czasoch\u0142onne (24\u201372 godziny),</li> <li>wymagaj\u0105 zaawansowanego zaplecza laboratoryjnego,</li> <li>nie zawsze pozwalaj\u0105 na szybkie podj\u0119cie decyzji klinicznej.</li> </ul> <p>Model Galleria mellonella umo\u017cliwia obserwacj\u0119 zmian behawioralnych po zaka\u017ceniu. Jednak dotychczasowa analiza by\u0142a manualna, trudna do standaryzacji i ograniczona skalowalno\u015bci\u0105.</p> <p>Projekt realizowany jest jako praca magisterska we wsp\u00f3\u0142pracy z Uniwersytetem Medycznym we Wroc\u0142awiu.</p>"},{"location":"pl/larvixon_ai/#jak-to-dziaa","title":"Jak to dzia\u0142a","text":"<p>Larvixon-AI to pipeline analizy wideo:</p> <ul> <li>Video ingestion \u2014 nagrania HD (25 FPS), r\u00f3\u017cne warunki o\u015bwietleniowe</li> <li>Warstwa Computer Vision \u2014 detekcja obiekt\u00f3w (larw), segmentacja i maskowanie, \u015bledzenie pozycji w kolejnych klatkach</li> <li>Warstwa analizy \u2014 obliczanie trajektorii, dystans, pr\u0119dko\u015b\u0107, kierunki, mapy ciep\u0142a aktywno\u015bci</li> <li>Dane i wizualizacje \u2014 eksport CSV, analiza statystyczna, wizualizacje wynik\u00f3w</li> </ul> <p>Architektura zosta\u0142a przygotowana pod dalsz\u0105 integracj\u0119 z modelami deep learning.</p>"},{"location":"pl/larvixon_ai/#co-zrobiem","title":"Co zrobi\u0142em","text":"<ul> <li>Zaprojektowa\u0142em algorytm detekcji i \u015bledzenia larw w wideo</li> <li>Zaimplementowa\u0142em pipeline przetwarzania obrazu w OpenCV</li> <li>Obs\u0142u\u017cy\u0142em r\u00f3\u017cne warianty o\u015bwietlenia (g\u00f3ra / d\u00f3\u0142)</li> <li>Wyznacza\u0142em trajektorie i parametry kinematyczne ruchu</li> <li>Przeprowadzi\u0142em analiz\u0119 por\u00f3wnawcz\u0105 grup:<ul> <li>kontrolnych</li> <li>PBS</li> <li>zaka\u017conych E. coli (r\u00f3\u017cne st\u0119\u017cenia)</li> </ul> </li> <li>Zautomatyzowa\u0142em zapis danych i generowanie wizualizacji</li> <li>Przeanalizowa\u0142em wyniki pod k\u0105tem r\u00f3\u017cnic behawioralnych</li> </ul>"},{"location":"pl/larvixon_ai/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>OpenCV</li> <li>Deep Learning</li> <li>Computer Vision</li> <li>NumPy</li> <li>Pandas</li> <li>Scientific Computing</li> <li>Video Processing</li> </ul>"},{"location":"pl/larvixon_ai/#kluczowe-rezultaty","title":"Kluczowe rezultaty","text":"<ul> <li>100% skuteczno\u015bci detekcji ruchu larw</li> <li>Przetwarzanie nagra\u0144 wideo w czasie rzeczywistym (25 FPS)</li> <li>Istotne r\u00f3\u017cnice pomi\u0119dzy grupami:</li> <li>larwy kontrolne: ~5 mm/s</li> <li>larwy zaka\u017cone: ~2.3 mm/s (wysokie st\u0119\u017cenia)</li> <li>Wyra\u017ane r\u00f3\u017cnice w:</li> <li>przebytych dystansach</li> <li>rozk\u0142adzie przestrzennym aktywno\u015bci</li> <li>wzorcach ruchu</li> </ul>"},{"location":"pl/larvixon_ai/#wpyw-i-przysze-prace","title":"Wp\u0142yw i przysz\u0142e prace","text":"<p>Larvixon-AI stanowi podstaw\u0119 do dalszych bada\u0144 nad:</p> <ul> <li>automatyczn\u0105 identyfikacj\u0105 patogen\u00f3w septycznych,</li> <li>przyspieszeniem diagnostyki zaka\u017ce\u0144,</li> <li>wykorzystaniem deep learning w analizie behawioralnej.</li> </ul> <p>Projekt \u0142\u0105czy AI engineering z badaniami biomedycznymi i stanowi most pomi\u0119dzy nauk\u0105 a praktycznymi zastosowaniami klinicznymi.</p>"},{"location":"pl/my_chatbot/","title":"M\u00f3j Chatbot","text":"<p>Data utworzenia: 2024-09-15</p>"},{"location":"pl/my_chatbot/#opis-projektu","title":"Opis projektu","text":"<p>Celem projektu by\u0142o stworzenie w\u0142asnej wersji Chat GPT, opartej na interfejsie aplikacji Streamlit. Chatbot mo\u017ce przyj\u0105\u0107 dowoln\u0105 osobowo\u015b\u0107, aby maksymalizowa\u0107 funkcjonalno\u015b\u0107 wed\u0142ug naszych preferencji.</p>"},{"location":"pl/my_chatbot/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>Chatbot pami\u0119ta rozmowy i zapisuje je w strukturze plik\u00f3w JSON, a Ty mo\u017cesz \u0142atwo prze\u0142\u0105cza\u0107 si\u0119 mi\u0119dzy rozmowami (bez utraty historii czatu)</li> <li>Mo\u017cesz wybiera\u0107 mi\u0119dzy r\u00f3\u017cnymi modelami od OpenAI</li> <li>Koszty korzystania z AI s\u0105 liczone</li> <li>Mo\u017cesz nada\u0107 chatbotowi indywidualn\u0105 \u015bwiadomo\u015b\u0107, kt\u00f3ra b\u0119dzie kierowa\u0107 typami odpowiedzi na zadawane pytania</li> </ul>"},{"location":"pl/my_chatbot/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>Langfuse</li> <li>OpenAI</li> <li>Streamlit</li> </ul>"},{"location":"pl/my_chatbot/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/my_chatbot/#wykorzystanie-aplikacji","title":"Wykorzystanie aplikacji","text":"<p>Aplikacja zosta\u0142a wdro\u017cona na Streamlit Community App i pomaga mi na co dzie\u0144 eksplorowa\u0107 sekrety AI i rozwija\u0107 moje umiej\u0119tno\u015bci programistyczne.</p>"},{"location":"pl/quality_management_system/","title":"Quality Management System","text":"<p>Projekt: czerwiec 2025 \u2014 pa\u017adziernik 2025</p> <p>Rola: Data Scientist / Software Engineer</p> <p>Firma: Agroment \"ZEHS\" Luba\u0144</p> <p>Status: Produkcja</p>"},{"location":"pl/quality_management_system/#opis-projektu","title":"Opis projektu","text":"<p>W organizacjach przemys\u0142owych dane jako\u015bciowe i techniczne s\u0105 cz\u0119sto rozproszone pomi\u0119dzy wieloma \u017ar\u00f3d\u0142ami:</p> <ul> <li>raporty jako\u015bci w Excelu,</li> <li>dokumentacja techniczna w PDF,</li> <li>instrukcje procesowe w r\u00f3\u017cnych lokalizacjach,</li> <li>historia dzia\u0142a\u0144 koryguj\u0105cych w osobnych plikach.</li> </ul> <p>W efekcie:</p> <ul> <li>znalezienie w\u0142a\u015bciwego dokumentu zajmuje zbyt du\u017co czasu,</li> <li>dane s\u0105 niesp\u00f3jne i trudne do por\u00f3wnania,</li> <li>brak jednego miejsca do analizy jako\u015bci i decyzji,</li> <li>wiedza organizacyjna jest silnie zale\u017cna od konkretnych os\u00f3b.</li> </ul> <p>Zaprojektowa\u0142em Quality Management System (QMS), kt\u00f3rego g\u0142\u00f3wnym celem by\u0142o stworzenie jednego, centralnego \u017ar\u00f3d\u0142a prawdy dla danych jako\u015bciowych i wiedzy technicznej.</p>"},{"location":"pl/quality_management_system/#rozwiazanie","title":"Rozwi\u0105zanie","text":"<p>System \u0142\u0105czy:</p> <ul> <li>klasyczny QMS (raporty, dzia\u0142ania, metryki),</li> <li>warstw\u0119 Knowledge Management,</li> <li>semantic search umo\u017cliwiaj\u0105cy wyszukiwanie w j\u0119zyku naturalnym.</li> </ul> <p>Ca\u0142o\u015b\u0107 zosta\u0142a udost\u0119pniona jako aplikacja Streamlit pe\u0142ni\u0105ca rol\u0119 operacyjnego dashboardu jako\u015bci.</p>"},{"location":"pl/quality_management_system/#architektura","title":"Architektura","text":"<p>QMS zosta\u0142 zaprojektowany jako system integruj\u0105cy wiele \u017ar\u00f3de\u0142 danych:</p> <ul> <li>Data ingestion \u2014 import danych z plik\u00f3w PDF i Excel, normalizacja i standaryzacja</li> <li>Centralna baza danych \u2014 relacyjna baza jako single source of truth, ujednolicone modele danych jako\u015bciowych</li> <li>Warstwa wiedzy \u2014 ekstrakcja tre\u015bci dokument\u00f3w, embeddingi i indeks semantyczny</li> <li>Warstwa aplikacyjna \u2014 Streamlit jako interfejs u\u017cytkownika, dashboardy, raporty, wyszukiwanie</li> </ul> <p>Architektura zosta\u0142a zaprojektowana z my\u015bl\u0105 o:</p> <ul> <li>integracji z systemami ERP / CRM,</li> <li>przysz\u0142ym rozszerzeniu o kolejne modu\u0142y AI.</li> </ul>"},{"location":"pl/quality_management_system/#kluczowe-funkcje","title":"Kluczowe funkcje","text":""},{"location":"pl/quality_management_system/#inteligentne-wyszukiwanie-semantyczne","title":"Inteligentne wyszukiwanie semantyczne","text":"<ul> <li>wyszukiwanie rysunk\u00f3w, instrukcji i raport\u00f3w</li> <li>zapytania w j\u0119zyku naturalnym</li> <li>brak potrzeby znajomo\u015bci struktury folder\u00f3w</li> </ul>"},{"location":"pl/quality_management_system/#scentralizowane-i-ustandaryzowane-dane","title":"Scentralizowane i ustandaryzowane dane","text":"<ul> <li>wszystkie dane jako\u015bciowe w jednym miejscu</li> <li>sp\u00f3jne formaty i aktualne wersje dokument\u00f3w</li> <li>eliminacja duplikat\u00f3w i nieaktualnych plik\u00f3w</li> </ul>"},{"location":"pl/quality_management_system/#automatyczne-raportowanie-i-analityka","title":"Automatyczne raportowanie i analityka","text":"<ul> <li>dashboardy jako\u015bciowe</li> <li>statusy dzia\u0142a\u0144 koryguj\u0105cych</li> <li>szybki przegl\u0105d KPI jako\u015bci</li> </ul>"},{"location":"pl/quality_management_system/#architektura-gotowa-na-integracje","title":"Architektura gotowa na integracj\u0119","text":"<ul> <li>przygotowanie pod integracj\u0119 z ERP / CRM</li> <li>modularna struktura danych</li> <li>gotowo\u015b\u0107 pod dalsze systemy AI</li> </ul>"},{"location":"pl/quality_management_system/#co-zrobiem","title":"Co zrobi\u0142em","text":"<ol> <li>Przeanalizowa\u0142em istniej\u0105ce \u017ar\u00f3d\u0142a danych jako\u015bciowych</li> <li>Zaprojektowa\u0142em ujednolicony model danych</li> <li>Zaimplementowa\u0142em import i transformacj\u0119 danych z PDF i Excel</li> <li>Stworzy\u0142em centraln\u0105 baz\u0119 danych jako single source of truth</li> <li>Zbudowa\u0142em warstw\u0119 semantic search nad dokumentacj\u0105</li> <li>Opracowa\u0142em dashboard jako\u015bci w Streamlit</li> <li>Zautomatyzowa\u0142em raportowanie i monitoring dzia\u0142a\u0144</li> <li>Przygotowa\u0142em architektur\u0119 pod przysz\u0142e integracje i AI</li> </ol>"},{"location":"pl/quality_management_system/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>Streamlit</li> <li>PostgreSQL</li> <li>Pandas</li> <li>SQL</li> <li>PDF Processing</li> <li>Excel Processing</li> <li>Semantic Search</li> <li>Embeddings</li> <li>Machine Learning</li> <li>Computer Vision</li> <li>Docker</li> </ul>"},{"location":"pl/quality_management_system/#rezultaty","title":"Rezultaty","text":"<ul> <li>Redukcja czasu wyszukiwania dokument\u00f3w nawet o 70%</li> <li>Jedno, sp\u00f3jne \u017ar\u00f3d\u0142o danych jako\u015bciowych</li> <li>Lepsza przejrzysto\u015b\u0107 proces\u00f3w i historii dzia\u0142a\u0144</li> <li>Szybsze podejmowanie decyzji jako\u015bciowych</li> <li>Usprawniona wsp\u00f3\u0142praca mi\u0119dzy:</li> <li>produkcj\u0105</li> <li>jako\u015bci\u0105</li> <li>zakupami</li> <li>Solidna baza pod dalszy rozw\u00f3j system\u00f3w AI w organizacji</li> </ul>"},{"location":"pl/robinson_chatbot/","title":"Robinson Chatbot","text":"<p>Data utworzenia: 2025-01-31</p>"},{"location":"pl/robinson_chatbot/#opis-projektu","title":"Opis projektu","text":"<p>Projekt Robinson Chatbot eksploruje implementacj\u0119 technik Retrieval-Augmented Generation (RAG) do stworzenia inteligentnego agenta konwersacyjnego posiadaj\u0105cego wiedz\u0119 o \"Robinsonie Crusoe\". System \u0142\u0105czy najnowocze\u015bniejsze modele j\u0119zykowe zar\u00f3wno od OpenAI, jak i Amazon Bedrock z zaawansowanymi metodami wyszukiwania tekstu, aby zapewni\u0107 dok\u0142adne, kontekstowo istotne odpowiedzi oparte na tre\u015bci powie\u015bci. Poprzez intensywne eksperymenty z r\u00f3\u017cnymi strategiami chunkingu, modelami embedding\u00f3w i technikami prompt engineering, projekt demonstruje jak architektury RAG mog\u0105 skutecznie rozszerza\u0107 mo\u017cliwo\u015bci LLM dla aplikacji domenowych, jednocze\u015bnie minimalizuj\u0105c halucynacje i poprawiaj\u0105c dok\u0142adno\u015b\u0107 faktyczn\u0105.</p>"},{"location":"pl/robinson_chatbot/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>Implementacja r\u00f3\u017cnych metod chunkingu tekstu (np. po paragrafach, sta\u0142y rozmiar token\u00f3w, po rozdzia\u0142ach) do optymalizacji wyszukiwania informacji</li> <li>Eksperymenty z r\u00f3\u017cnymi modelami embedding\u00f3w do tworzenia semantycznych reprezentacji wektorowych</li> <li>Zaawansowane wyszukiwanie podobie\u0144stwa przy u\u017cyciu bazy wektorowej FAISS dla efektywnego wyszukiwania informacji</li> <li>Por\u00f3wnanie wydajno\u015bci mi\u0119dzy modelami OpenAI (gpt-4o i gpt-4o-mini) a modelami Amazon Bedrock (Amazon Titan Text Express V1 i Amazon Titan Text Embeddings E1)</li> <li>Techniki prompt engineering do optymalizacji wykorzystania kontekstu i jako\u015bci odpowiedzi</li> <li>Interaktywna aplikacja Streamlit do przyjaznej u\u017cytkownikowi interakcji z chatbotem o Robinsonie Crusoe</li> <li>Kompleksowy framework ewaluacyjny do mierzenia dok\u0142adno\u015bci, trafno\u015bci i sp\u00f3jno\u015bci odpowiedzi</li> </ul>"},{"location":"pl/robinson_chatbot/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>OpenAI</li> <li>Amazon Bedrock</li> <li>AWS</li> <li>NumPy</li> <li>FAISS</li> <li>RAG</li> <li>Boto3</li> <li>NLTK</li> <li>Streamlit</li> <li>Prompt Engineering</li> <li>Embeddings</li> <li>LaTeX</li> </ul>"},{"location":"pl/robinson_chatbot/#raport-projektu","title":"Raport projektu","text":"<p>Mo\u017cesz pobra\u0107 i przejrze\u0107 kompletny raport projektu ze szczeg\u00f3\u0142ow\u0105 metodologi\u0105 i wynikami tutaj: Robinson Chatbot - Raport implementacji RAG</p>"},{"location":"pl/robinson_chatbot/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/student_profiler/","title":"Student Profiler","text":"<p>Projekt: marzec 2025 \u2014 czerwiec 2025</p> <p>Rola: Backend / Data Engineer</p> <p>Firma: GOTOIT sp. z o.o.</p> <p>Status: Produkcja</p>"},{"location":"pl/student_profiler/#opis-projektu","title":"Opis projektu","text":"<p>Mentorzy i prowadz\u0105cy kursy nie mieli narz\u0119dzia umo\u017cliwiaj\u0105cego systematyczne monitorowanie aktywno\u015bci student\u00f3w na Discordzie.</p> <p>Analiza zaanga\u017cowania, regularno\u015bci pracy oraz historii interakcji:</p> <ul> <li>by\u0142a rozproszona po wielu kana\u0142ach,</li> <li>wymaga\u0142a r\u0119cznego przegl\u0105dania wiadomo\u015bci,</li> <li>nie dawa\u0142a podstaw do automatycznych wniosk\u00f3w ani skalowania procesu mentoringu.</li> </ul> <p>Brakowa\u0142o jednego, centralnego systemu do zbierania i analizy danych.</p> <p>Zaprojektowa\u0142em i rozwijam Student Profiler \u2014 narz\u0119dzie do automatycznego monitorowania aktywno\u015bci student\u00f3w w \u015brodowisku Discord.</p>"},{"location":"pl/student_profiler/#rozwiazanie","title":"Rozwi\u0105zanie","text":"<p>Rdzeniem systemu jest Discord Bot, kt\u00f3ry:</p> <ul> <li>pobiera dane historyczne z kana\u0142\u00f3w,</li> <li>nas\u0142uchuje nowych wiadomo\u015bci i zdarze\u0144 w czasie rzeczywistym,</li> <li>zapisuje dane w relacyjnej bazie danych,</li> <li>zasila warstw\u0119 analityczn\u0105 i interfejs u\u017cytkownika.</li> </ul> <p>Architektura zosta\u0142a przygotowana pod dalszy rozw\u00f3j funkcji opartych o AI (humanizowany mentor bot, analiza sentymentu, OCR, modele predykcyjne).</p>"},{"location":"pl/student_profiler/#architektura","title":"Architektura","text":""},{"location":"pl/student_profiler/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>Integracja Discord Bot do monitorowania aktywno\u015bci i automatycznego wysy\u0142ania wiadomo\u015bci</li> <li>Cykliczne zbieranie danych z kana\u0142\u00f3w Discord (co godzin\u0119)</li> <li>System przechowywania danych: PostgreSQL dla wiadomo\u015bci, Digital Ocean Spaces dla za\u0142\u0105cznik\u00f3w</li> <li>UI oparte na Streamlit do \u0142atwego dost\u0119pu i analizy danych z Discorda</li> <li>Skalowalna architektura z planami implementacji funkcji AI</li> </ul>"},{"location":"pl/student_profiler/#co-zrobiem","title":"Co zrobi\u0142em","text":"<ol> <li>Zaprojektowa\u0142em architektur\u0119 systemu zgodnie z zasadami Single Responsibility Principle</li> <li>Zaimplementowa\u0142em Discord Bota do:</li> <li>pobierania historii wiadomo\u015bci</li> <li>nas\u0142uchiwania nowych zdarze\u0144</li> <li>obs\u0142ugi automatycznych odpowiedzi</li> <li>Stworzy\u0142em mechanizm cyklicznego zbierania danych (scheduler hourly)</li> <li>Zaprojektowa\u0142em i wdro\u017cy\u0142em baz\u0119 danych PostgreSQL</li> <li>Zintegrowa\u0142em DigitalOcean Spaces do przechowywania za\u0142\u0105cznik\u00f3w</li> <li>Zbudowa\u0142em UI analityczne w Streamlit z wizualizacjami Plotly</li> <li>Przygotowa\u0142em \u015brodowisko Docker do lokalnego i chmurowego uruchamiania</li> <li>Zaimplementowa\u0142em konfiguracj\u0119 aplikacji z u\u017cyciem pydantic-settings</li> </ol>"},{"location":"pl/student_profiler/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>Discord API</li> <li>PostgreSQL</li> <li>Streamlit</li> <li>Docker</li> <li>DigitalOcean</li> <li>Pandas</li> <li>SQL</li> <li>Plotly</li> <li>Psycopg</li> <li>Requests</li> <li>Schedule</li> <li>Pydantic-settings</li> <li>SRP design</li> </ul>"},{"location":"pl/student_profiler/#rezultaty","title":"Rezultaty","text":"<ul> <li>Centralne \u017ar\u00f3d\u0142o danych o aktywno\u015bci student\u00f3w na Discordzie</li> <li>Automatyczne i regularne zbieranie danych bez r\u0119cznej ingerencji mentora</li> <li>Czytelny dashboard do analizy zaanga\u017cowania i trend\u00f3w</li> <li>Stabilna baza pod dalszy rozw\u00f3j funkcji AI:</li> <li>analiza sentymentu komunikacji</li> <li>predykcja spadku aktywno\u015bci kursant\u00f3w</li> <li>humanizowany mentor bot</li> </ul>"},{"location":"pl/student_profiler/#zdjecia","title":"Zdj\u0119cia","text":""},{"location":"pl/titanic/","title":"Eksploracja domeny (EDA) zbioru danych: Titanic","text":"<p>Data utworzenia: 2024-08-25</p>"},{"location":"pl/titanic/#wprowadzenie","title":"Wprowadzenie","text":"<p>Zapraszam do zapoznania si\u0119 z moim projektem, kt\u00f3ry zabiera nas w \u015bwiat analizy danych dotycz\u0105cych s\u0142ynnej na ca\u0142ym \u015bwiecie katastrofy Titanica. W celu eksploracji informacji wykorzystuj\u0119 eksploracj\u0119 domeny (EDA). W tym projekcie znajdziesz wiele istotnych wniosk\u00f3w i ciekawych obserwacji. Przygotuj si\u0119 na interesuj\u0105c\u0105 podr\u00f3\u017c z danymi, kt\u00f3ra poszerzy Twoje horyzonty spojrzenia na jedn\u0105 z najwi\u0119kszych katastrof morskich w historii.</p>"},{"location":"pl/titanic/#pobierz-projekt","title":"Pobierz projekt","text":"<p>Pobierz Notebook Otw\u00f3rz w nowej karcie \u2197</p>"},{"location":"pl/titanic/#podglad-notatnika","title":"Podgl\u0105d notatnika","text":""},{"location":"pl/welcome_survey/","title":"Ankieta powitalna","text":"<p>Data utworzenia: 2024-09-22</p>"},{"location":"pl/welcome_survey/#opis-projektu","title":"Opis projektu","text":"<p>Celem projektu by\u0142o stworzenie aplikacji, kt\u00f3ra pozwoli\u0142aby na proste filtrowanie i przegl\u0105danie danych z przyk\u0142adowej ankiety powitalnej (dane zosta\u0142y odpowiednio zanonimizowane). Celem aplikacji by\u0142o utrwalenie komponent\u00f3w z biblioteki Streamlit oraz zapoznanie si\u0119 z w\u0142a\u015bciwym zarz\u0105dzaniem stanem aplikacji (<code>st.session_state</code>), tak aby wszystkie przyciski i interakcje by\u0142y wzgl\u0119dem siebie responsywne.</p>"},{"location":"pl/welcome_survey/#gowne-funkcjonalnosci","title":"G\u0142\u00f3wne funkcjonalno\u015bci","text":"<ul> <li>Mo\u017cliwo\u015b\u0107 przegl\u0105dania anonimowej ankiety w celu zapoznania si\u0119 z interfejsem Streamlit</li> <li>R\u00f3\u017cne typy filtr\u00f3w pozwalaj\u0105 na bardziej szczeg\u00f3\u0142owe poznanie analizowanych danych</li> <li>Zawarte s\u0105 r\u00f3wnie\u017c wizualizacje</li> <li>Aplikacja zawiera tak\u017ce ciekawe wizualizacje, a dla najbardziej wytrwa\u0142ych - czekaj\u0105 ciekawostki!</li> </ul>"},{"location":"pl/welcome_survey/#umiejetnosci","title":"Umiej\u0119tno\u015bci","text":"<ul> <li>Python</li> <li>Pandas</li> <li>Matplotlib</li> <li>Seaborn</li> <li>Streamlit</li> <li>Boto3</li> </ul>"},{"location":"pl/welcome_survey/#zdjecia","title":"Zdj\u0119cia","text":""}]}